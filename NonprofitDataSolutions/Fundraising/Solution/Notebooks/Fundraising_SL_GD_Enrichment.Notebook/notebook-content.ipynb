{
	"cells": [
		{
			"cell_type": "markdown",
			"id": "2d78f4f6-404e-48f2-8fb7-641fc1f22804",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"source": [
				"# Config"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "19981c05-f2c9-4fb6-8c32-b2130084899e",
			"metadata": {
				"editable": false,
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"outputs": [],
			"source": [
				"%run <Fundraising_Config>"
			]
		},
		{
			"cell_type": "markdown",
			"id": "2c471a3f-3c28-4abb-99bf-e12e9ead8c6b",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"source": [
				"# Enrichment"
			]
		},
		{
			"cell_type": "markdown",
			"id": "8bbca9ba-0797-4436-989f-226225826776",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"source": [
				"## Generic tables"
			]
		},
		{
			"cell_type": "markdown",
			"id": "c1594c36-250d-4459-a274-5d1cb54a0b92",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"source": [
				"### Build: Configuration"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "efa93e61-db61-4e9c-b6de-c32ec5073c22",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"outputs": [],
			"source": [
				"configurationTable = CdfTable(\n",
				"    source_table_name=\"Configuration\",\n",
				"    source_primary_key=\"ConfigurationId\",\n",
				"    target_table_name=\"Configuration\",\n",
				"    columns=[\n",
				"        \"ConfigurationId\", \"Name\", \"Value\", \"CreatedDate\", \"ModifiedDate\", \"SourceSystemId\", \"SourceId\"\n",
				"    ],\n",
				"    merge_sql_template=f\"\"\"\n",
				"    MERGE INTO {gold_lakehouse_name}.Configuration AS target\n",
				"    USING (\n",
				"        SELECT \n",
				"            ConfigurationId,\n",
				"            Name,\n",
				"            Value\n",
				"        FROM latestSnapshot_Configuration\n",
				"    ) AS source\n",
				"    ON target.ConfigurationId = source.ConfigurationId\n",
				"    WHEN MATCHED THEN UPDATE SET\n",
				"        Name = source.Name,\n",
				"        Value = source.Value\n",
				"    WHEN NOT MATCHED THEN INSERT (\n",
				"        ConfigurationId, Name, Value\n",
				"    ) VALUES (\n",
				"        source.ConfigurationId, source.Name, source.Value\n",
				"    )\n",
				"    \"\"\",\n",
				"    source_lakehouse=silver_lakehouse_name,\n",
				"    target_lakehouse=gold_lakehouse_name,\n",
				"    enrich_func=None\n",
				")\n",
				"\n",
				"ProcessCdfTable(configurationTable)\n",
				"\n",
				"logging.info(f\"‚úÖ Configuration processed.\")"
			]
		},
		{
			"cell_type": "markdown",
			"id": "5a6dc38b-c7af-4b4d-b7be-bdeeb137ad1c",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"source": [
				"### Build: DimDate"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "1051dc57-2732-445e-b616-80e706b10636",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"outputs": [],
			"source": [
				"from pyspark.sql.functions import (\n",
				"    sequence, explode, to_date, year, month, date_format, quarter,\n",
				"    dayofweek, dayofmonth, weekofyear, when, lit, coalesce, expr, col\n",
				")\n",
				"from pyspark.sql.types import LongType\n",
				"import holidays\n",
				"\n",
				"# Define target table using your gold lakehouse variable\n",
				"target_table = f\"{gold_lakehouse_name}.DimDate\"\n",
				"\n",
				"if table_exists(target_table) and spark.table(target_table).count() > 0:\n",
				"    logging.info(\"‚úÖ DimDate already populated ‚Äì skipping rebuild.\")\n",
				"else:\n",
				"    logging.info(\"‚è≥ Building DimDate table...\")\n",
				"\n",
				"    # Create US holidays list for years 1900‚Äì2050\n",
				"    us_holidays = list(holidays.US(years=range(1900, 2051)).keys())\n",
				"    holiday_df = spark.createDataFrame([(d,) for d in us_holidays], [\"Date\"]) \\\n",
				"                      .withColumn(\"IsHoliday\", lit(True))\n",
				"\n",
				"    # Generate and enrich date range\n",
				"    date_df = (\n",
				"        spark.range(1)  # must produce at least one row\n",
				"            .select(explode(sequence(\n",
				"                to_date(lit(\"1900-01-01\")),\n",
				"                to_date(lit(\"2050-12-31\")),\n",
				"                expr(\"interval 1 day\")\n",
				"            )).alias(\"Date\"))\n",
				"            .withColumn(\"DateKey\", date_format(\"Date\", \"yyyyMMdd\").cast(LongType()))\n",
				"            .withColumn(\"Year\", year(\"Date\"))\n",
				"            .withColumn(\"Month\", month(\"Date\"))\n",
				"            .withColumn(\"MonthName\", date_format(\"Date\", \"MMMM\"))\n",
				"            .withColumn(\"MonthNameShort\", date_format(\"Date\", \"MMM\"))\n",
				"            .withColumn(\"Day\", dayofmonth(\"Date\"))\n",
				"            .withColumn(\"DayOfWeek\", dayofweek(\"Date\"))\n",
				"            .withColumn(\"DayName\", date_format(\"Date\", \"EEEE\"))\n",
				"            .withColumn(\"WeekOfYear\", weekofyear(\"Date\"))\n",
				"            .withColumn(\"Quarter\", quarter(\"Date\"))\n",
				"            .withColumn(\"FiscalYear\", year(\"Date\"))  # Adjust if you use a fiscal calendar\n",
				"            .withColumn(\"FiscalQuarter\", quarter(\"Date\"))\n",
				"            .withColumn(\"IsWeekend\", dayofweek(\"Date\").isin(1, 7).cast(\"boolean\"))\n",
				"    )\n",
				"\n",
				"    # Join with holiday list (US)\n",
				"    final_df = (\n",
				"        date_df.join(holiday_df.hint(\"broadcast\"), on=\"Date\", how=\"left\")\n",
				"               .withColumn(\"IsHoliday\", coalesce(\"IsHoliday\", lit(False)))\n",
				"               .select(\n",
				"                   \"DateKey\", \"Date\", \"Year\", \"Month\", \"MonthName\", \"MonthNameShort\",\n",
				"                   \"Day\", \"DayOfWeek\", \"DayName\", \"WeekOfYear\", \"Quarter\",\n",
				"                   \"FiscalYear\", \"FiscalQuarter\", \"IsWeekend\", \"IsHoliday\"\n",
				"               )\n",
				"    )\n",
				"\n",
				"    # Write to Delta table (no schema overwrite)\n",
				"    final_df.write \\\n",
				"        .mode(\"overwrite\") \\\n",
				"        .format(\"delta\") \\\n",
				"        .saveAsTable(target_table)\n",
				"\n",
				"    logging.info(f\"‚úÖ DimDate written with {final_df.count()} rows.\")"
			]
		},
		{
			"cell_type": "markdown",
			"id": "6fa3f014-83d8-4a72-92d1-6e63bbae7d1f",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"source": [
				"### Build: DimSource"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "356fab03-fc95-443d-b1c6-7cf91170b18b",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"outputs": [],
			"source": [
				"from pyspark.sql.functions import col, xxhash64\n",
				"from pyspark.sql import DataFrame\n",
				"\n",
				"def EnrichDimSource(df: DataFrame) -> DataFrame:\n",
				"\n",
				"    new_df = (\n",
				"        df\n",
				"        .select(\"SourceId\", \"Name\")\n",
				"        .withColumn(\"SourceKey\", xxhash64(col(\"SourceId\")).cast(\"bigint\"))\n",
				"        .select(\n",
				"            \"SourceKey\",\n",
				"            \"SourceId\",\n",
				"            col(\"Name\").alias(\"SourceName\")\n",
				"        )\n",
				"    )\n",
				"\n",
				"    logging.info(f\"‚úÖ DimSource processing {new_df.count()} rows.\")\n",
				"    return new_df\n",
				"\n",
				"dimSourceTable = CdfTable(\n",
				"    source_table_name=\"Source\",\n",
				"    source_primary_key=\"SourceId\",\n",
				"    target_table_name=\"DimSource\",\n",
				"    columns=[\"SourceId\", \"Name\", \"CreatedDate\", \"ModifiedDate\"],\n",
				"    merge_sql_template=f\"\"\"\n",
				"    MERGE INTO {gold_lakehouse_name}.DimSource AS target\n",
				"    USING latestSnapshot_Source AS source\n",
				"    ON target.SourceId = source.SourceId\n",
				"    WHEN MATCHED THEN UPDATE SET\n",
				"        SourceName = source.SourceName\n",
				"    WHEN NOT MATCHED THEN INSERT (\n",
				"        SourceKey, SourceId, SourceName\n",
				"    ) VALUES (\n",
				"        source.SourceKey, source.SourceId, source.SourceName\n",
				"    )\n",
				"    \"\"\",\n",
				"    source_lakehouse=silver_lakehouse_name,\n",
				"    target_lakehouse=gold_lakehouse_name,\n",
				"    enrich_func=EnrichDimSource\n",
				")\n",
				"\n",
				"ProcessCdfTable(dimSourceTable)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "ac41264f-9ce7-4740-91bc-60261c91364e",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"source": [
				"### Build: DimChannel"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "2ee887c3-03df-4e8e-b4dd-9f16789fe844",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"outputs": [],
			"source": [
				"from pyspark.sql.functions import col, to_date, xxhash64\n",
				"\n",
				"def EnrichDimChannel(df: DataFrame) -> DataFrame:\n",
				"    dim_date = get_gold_table(\"DimDate\").select(\n",
				"        col(\"Date\").alias(\"DimDate\"),\n",
				"        col(\"DateKey\")\n",
				"    )\n",
				"\n",
				"    new_df = (\n",
				"        df.select(\"ChannelId\", \"Name\", \"Weight\", \"CreatedDate\", \"ModifiedDate\")\n",
				"          .withColumn(\"ChannelKey\", xxhash64(col(\"ChannelId\")).cast(\"bigint\"))\n",
				"          .join(dim_date, to_date(\"CreatedDate\") == col(\"DimDate\"), \"left\")\n",
				"          .withColumnRenamed(\"DateKey\", \"CreatedDateKey\")\n",
				"          .drop(\"DimDate\")\n",
				"          .join(dim_date, to_date(\"ModifiedDate\") == col(\"DimDate\"), \"left\")\n",
				"          .withColumnRenamed(\"DateKey\", \"ModifiedDateKey\")\n",
				"          .drop(\"DimDate\")\n",
				"          .select(\n",
				"              \"ChannelKey\",\n",
				"              \"ChannelId\",\n",
				"              col(\"Name\").alias(\"ChannelName\"),\n",
				"              \"Weight\",\n",
				"              \"CreatedDateKey\",\n",
				"              \"ModifiedDateKey\"\n",
				"          )\n",
				"    )\n",
				"\n",
				"    logging.info(f\"‚úÖ DimChannel processing {new_df.count()} rows.\")\n",
				"\n",
				"    return new_df\n",
				"\n",
				"dimChannelTable = CdfTable(\n",
				"    source_table_name=\"Channel\",\n",
				"    source_primary_key=\"ChannelId\",\n",
				"    target_table_name=\"DimChannel\",\n",
				"    columns=[\"ChannelId\", \"Name\", \"Weight\", \"CreatedDate\", \"ModifiedDate\"],\n",
				"    merge_sql_template=f\"\"\"\n",
				"    MERGE INTO {gold_lakehouse_name}.DimChannel AS target\n",
				"    USING latestSnapshot_Channel AS source\n",
				"    ON target.ChannelId = source.ChannelId\n",
				"    WHEN MATCHED THEN UPDATE SET\n",
				"        ChannelName = source.ChannelName,\n",
				"        Weight = source.Weight,\n",
				"        CreatedDateKey = source.CreatedDateKey,\n",
				"        ModifiedDateKey = source.ModifiedDateKey\n",
				"    WHEN NOT MATCHED THEN INSERT (\n",
				"        ChannelKey, ChannelId, ChannelName, Weight, CreatedDateKey, ModifiedDateKey\n",
				"    ) VALUES (\n",
				"        source.ChannelKey, source.ChannelId, source.ChannelName, source.Weight,\n",
				"        source.CreatedDateKey, source.ModifiedDateKey\n",
				"    )\n",
				"    \"\"\",\n",
				"    source_lakehouse=silver_lakehouse_name,\n",
				"    target_lakehouse=gold_lakehouse_name,\n",
				"    enrich_func=EnrichDimChannel\n",
				")\n",
				"\n",
				"ProcessCdfTable(dimChannelTable)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "c14c0a44-47e6-47e6-9d26-7cfa16db845d",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"source": [
				"### Build: CampaignType"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "a4f43a97-e125-4248-b8a6-4696bd22bc73",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"outputs": [],
			"source": [
				"from pyspark.sql.functions import col, xxhash64\n",
				"\n",
				"def EnrichDimCampaignType(df: DataFrame) -> DataFrame:\n",
				"\n",
				"    new_df = (\n",
				"        df\n",
				"        .select(\"CampaignTypeId\", col(\"Name\").alias(\"CampaignType\"))\n",
				"        .dropna(subset=[\"CampaignTypeId\"])\n",
				"        .withColumn(\n",
				"            \"CampaignTypeKey\",\n",
				"            xxhash64(col(\"CampaignTypeId\")).cast(\"bigint\")\n",
				"        )\n",
				"        .select(\"CampaignTypeKey\", \"CampaignTypeId\", \"CampaignType\")\n",
				"    )\n",
				"\n",
				"    logging.info(f\"‚úÖ DimCampaignType processing {new_df.count()} rows.\")\n",
				"    return new_df\n",
				"\n",
				"dimCampaignTypeTable = CdfTable(\n",
				"    source_table_name=\"CampaignType\",\n",
				"    source_primary_key=\"CampaignTypeId\",\n",
				"    target_table_name=\"DimCampaignType\",\n",
				"    columns=[\n",
				"        \"CampaignTypeId\", \"Name\", \"CreatedDate\", \"ModifiedDate\",\n",
				"        \"SourceId\", \"SourceSystemId\"\n",
				"    ],\n",
				"    merge_sql_template=f\"\"\"\n",
				"    MERGE INTO {gold_lakehouse_name}.DimCampaignType AS target\n",
				"    USING latestSnapshot_CampaignType AS source\n",
				"    ON target.CampaignTypeId = source.CampaignTypeId\n",
				"    WHEN MATCHED THEN UPDATE SET\n",
				"        CampaignType = source.CampaignType\n",
				"    WHEN NOT MATCHED THEN INSERT (\n",
				"        CampaignTypeKey, CampaignTypeId, CampaignType\n",
				"    ) VALUES (\n",
				"        source.CampaignTypeKey, source.CampaignTypeId, source.CampaignType\n",
				"    )\n",
				"    \"\"\",\n",
				"    source_lakehouse=silver_lakehouse_name,\n",
				"    target_lakehouse=gold_lakehouse_name,\n",
				"    enrich_func=EnrichDimCampaignType\n",
				")\n",
				"\n",
				"ProcessCdfTable(dimCampaignTypeTable)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "531d6e8d-e72b-4779-9539-652818e33e30",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"source": [
				"### Build: DimCampaign"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "9aecaf6c-29d8-45a7-82cb-bef7f5a0b4a9",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"outputs": [],
			"source": [
				"from pyspark.sql.functions import col, to_date, xxhash64\n",
				"\n",
				"def EnrichDimCampaign(df: DataFrame) -> DataFrame:\n",
				"    # Reference to DimCampaignType in Gold\n",
				"    campaign_type_df = get_gold_table(\"DimCampaignType\") \\\n",
				"        .select(\"CampaignTypeId\", \"CampaignTypeKey\") \\\n",
				"        .alias(\"ct\")\n",
				"\n",
				"    # Reference to DimDate\n",
				"    dim_date_df = get_gold_table(\"DimDate\") \\\n",
				"        .select(col(\"Date\").alias(\"DimDate\"), col(\"DateKey\"))\n",
				"\n",
				"    # Alias for base Campaign table\n",
				"    df = df.alias(\"c\")\n",
				"\n",
				"    new_df = (\n",
				"        df.join(campaign_type_df, col(\"c.CampaignTypeId\") == col(\"ct.CampaignTypeId\"), \"left\")\n",
				"          .join(dim_date_df.alias(\"start\"), to_date(col(\"c.StartDate\")) == col(\"start.DimDate\"), \"left\")\n",
				"          .join(dim_date_df.alias(\"end\"), to_date(col(\"c.EndDate\")) == col(\"end.DimDate\"), \"left\")\n",
				"          .join(dim_date_df.alias(\"created\"), to_date(col(\"c.CreatedDate\")) == col(\"created.DimDate\"), \"left\")\n",
				"          .join(dim_date_df.alias(\"modified\"), to_date(col(\"c.ModifiedDate\")) == col(\"modified.DimDate\"), \"left\")\n",
				"          .select(\n",
				"              col(\"c.CampaignId\"),\n",
				"              col(\"c.Name\").alias(\"CampaignName\"),\n",
				"              col(\"ct.CampaignTypeKey\"),\n",
				"              col(\"c.Cost\").cast(\"decimal(18,2)\"),\n",
				"              col(\"created.DateKey\").alias(\"CreatedDateKey\"),\n",
				"              col(\"end.DateKey\").alias(\"EndDateKey\"),\n",
				"              col(\"modified.DateKey\").alias(\"ModifiedDateKey\"),\n",
				"              col(\"c.SourceSystemId\").alias(\"SourceSysCampaignId\"),\n",
				"              col(\"start.DateKey\").alias(\"StartDateKey\"),\n",
				"              col(\"c.Timezone\")\n",
				"          )\n",
				"          .withColumn(\n",
				"              \"CampaignKey\",\n",
				"              xxhash64(\n",
				"                  col(\"CampaignId\"), \n",
				"                  col(\"SourceSysCampaignId\")\n",
				"              ).cast(\"bigint\")\n",
				"          )\n",
				"          .select(\n",
				"              \"CampaignKey\",\n",
				"              \"CampaignId\",\n",
				"              \"CampaignName\",\n",
				"              \"CampaignTypeKey\",\n",
				"              \"Cost\",\n",
				"              \"CreatedDateKey\",\n",
				"              \"EndDateKey\",\n",
				"              \"ModifiedDateKey\",\n",
				"              \"SourceSysCampaignId\",\n",
				"              \"StartDateKey\",\n",
				"              \"Timezone\"\n",
				"          )\n",
				"    )\n",
				"\n",
				"    logging.info(f\"‚úÖ DimCampaign processing {new_df.count()} rows.\")\n",
				"    return new_df\n",
				"\n",
				"dimCampaignTable = CdfTable(\n",
				"    source_table_name=\"Campaign\",\n",
				"    source_primary_key=\"CampaignId\",\n",
				"    target_table_name=\"DimCampaign\",\n",
				"    columns=[\n",
				"        \"CampaignId\", \"CampaignTypeId\", \"Cost\", \"CreatedDate\", \"EndDate\",\n",
				"        \"ModifiedDate\", \"Name\", \"SourceId\", \"SourceSystemId\", \"StartDate\", \"Timezone\"\n",
				"    ],\n",
				"    merge_sql_template=f\"\"\"\n",
				"    MERGE INTO {gold_lakehouse_name}.DimCampaign AS target\n",
				"    USING latestSnapshot_Campaign AS source\n",
				"    ON target.CampaignId = source.CampaignId\n",
				"    WHEN MATCHED THEN UPDATE SET\n",
				"        CampaignName = source.CampaignName,\n",
				"        CampaignTypeKey = source.CampaignTypeKey,\n",
				"        Cost = source.Cost,\n",
				"        CreatedDateKey = source.CreatedDateKey,\n",
				"        EndDateKey = source.EndDateKey,\n",
				"        ModifiedDateKey = source.ModifiedDateKey,\n",
				"        SourceSysCampaignId = source.SourceSysCampaignId,\n",
				"        StartDateKey = source.StartDateKey,\n",
				"        Timezone = source.Timezone\n",
				"    WHEN NOT MATCHED THEN INSERT (\n",
				"        CampaignKey, CampaignId, CampaignName, CampaignTypeKey, Cost,\n",
				"        CreatedDateKey, EndDateKey, ModifiedDateKey,\n",
				"        SourceSysCampaignId, StartDateKey, Timezone\n",
				"    ) VALUES (\n",
				"        source.CampaignKey, source.CampaignId, source.CampaignName, source.CampaignTypeKey,\n",
				"        source.Cost, source.CreatedDateKey, source.EndDateKey, source.ModifiedDateKey,\n",
				"        source.SourceSysCampaignId, source.StartDateKey, source.Timezone\n",
				"    )\n",
				"    \"\"\",\n",
				"    source_lakehouse=silver_lakehouse_name,\n",
				"    target_lakehouse=gold_lakehouse_name,\n",
				"    enrich_func=EnrichDimCampaign,\n",
				"    hard_delete=True\n",
				")\n",
				"\n",
				"ProcessCdfTable(dimCampaignTable)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "c466d271-f285-4a12-b2f5-e56c37c26fed",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"source": [
				"### Build: DimAddress"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "e34a9416-f5c6-4b19-b2cb-cddf6b9451f1",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"outputs": [],
			"source": [
				"from pyspark.sql.functions import col, xxhash64\n",
				"\n",
				"def EnrichDimAddress(df: DataFrame) -> DataFrame:\n",
				"    df = df.alias(\"a\")\n",
				"    dim_source = get_gold_table(\"DimSource\").select(\"SourceId\", \"SourceKey\").alias(\"ds\")\n",
				"    country_df = get_silver_table(\"Country\").select(\n",
				"        \"CountryId\", col(\"Name\").alias(\"CountryName\"), \"CountryCode\"\n",
				"    ).alias(\"c\")\n",
				"\n",
				"    new_df = (\n",
				"        df.join(dim_source, col(\"a.SourceId\") == col(\"ds.SourceId\"), \"left\")\n",
				"          .join(country_df, col(\"a.CountryId\") == col(\"c.CountryId\"), \"left\")\n",
				"          .withColumn(\n",
				"              \"AddressKey\",\n",
				"              xxhash64(\n",
				"                  col(\"a.AddressId\"),\n",
				"                  col(\"a.SourceSystemId\")\n",
				"              ).cast(\"bigint\")\n",
				"          )\n",
				"          .select(\n",
				"              \"AddressKey\",\n",
				"              col(\"a.AddressId\"),\n",
				"              col(\"a.CountryId\"),\n",
				"              col(\"a.SourceSystemId\").alias(\"SourceSysAddressId\"),\n",
				"              col(\"a.City\"),\n",
				"              col(\"a.State\"),\n",
				"              col(\"a.StateCode\"),\n",
				"              col(\"c.CountryName\"),\n",
				"              col(\"c.CountryCode\"),\n",
				"              col(\"a.Region\"),\n",
				"              col(\"a.ZipCode\"),\n",
				"              col(\"a.Latitude\"),\n",
				"              col(\"a.Longitude\"),\n",
				"              col(\"ds.SourceKey\")\n",
				"          )\n",
				"    )\n",
				"\n",
				"    logging.info(f\"‚úÖ DimAddress processing {new_df.count()} rows.\")\n",
				"\n",
				"    return new_df\n",
				"\n",
				"dimAddressTable = CdfTable(\n",
				"    source_table_name=\"Address\",\n",
				"    source_primary_key=\"AddressId\",\n",
				"    target_table_name=\"DimAddress\",\n",
				"    columns=[\n",
				"        \"AddressId\", \"CountryId\", \"SourceId\", \"SourceSystemId\",\n",
				"        \"City\", \"State\", \"StateCode\", \"Region\", \"ZipCode\",\n",
				"        \"Latitude\", \"Longitude\", \"CreatedDate\", \"ModifiedDate\"\n",
				"    ],\n",
				"    merge_sql_template=f\"\"\"\n",
				"    MERGE INTO {gold_lakehouse_name}.DimAddress AS target\n",
				"    USING latestSnapshot_Address AS source\n",
				"    ON target.AddressId = source.AddressId\n",
				"    WHEN MATCHED THEN UPDATE SET\n",
				"        CountryId          = source.CountryId,\n",
				"        SourceSysAddressId = source.SourceSysAddressId,\n",
				"        City               = source.City,\n",
				"        State              = source.State,\n",
				"        StateCode          = source.StateCode,\n",
				"        CountryName        = source.CountryName,\n",
				"        CountryCode        = source.CountryCode,\n",
				"        Region             = source.Region,\n",
				"        ZipCode            = source.ZipCode,\n",
				"        Latitude           = source.Latitude,\n",
				"        Longitude          = source.Longitude,\n",
				"        SourceKey          = source.SourceKey\n",
				"    WHEN NOT MATCHED THEN INSERT (\n",
				"        AddressKey, AddressId, CountryId, SourceSysAddressId, City, State, StateCode,\n",
				"        CountryName, CountryCode, Region, ZipCode, Latitude, Longitude, SourceKey\n",
				"    ) VALUES (\n",
				"        source.AddressKey, source.AddressId, source.CountryId, source.SourceSysAddressId,\n",
				"        source.City, source.State, source.StateCode, source.CountryName, source.CountryCode,\n",
				"        source.Region, source.ZipCode, source.Latitude, source.Longitude, source.SourceKey\n",
				"    )\n",
				"    \"\"\",\n",
				"    source_lakehouse=silver_lakehouse_name,\n",
				"    target_lakehouse=gold_lakehouse_name,\n",
				"    enrich_func=EnrichDimAddress,\n",
				"    hard_delete=True\n",
				")\n",
				"\n",
				"ProcessCdfTable(dimAddressTable)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "c2554b3b-8a6b-4f80-bff7-e811c0684ccb",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"source": [
				"### Build: DimCampaignChannelBridge"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "88b2e503-76bc-4610-a306-7d97aa5d4244",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"outputs": [],
			"source": [
				"from pyspark.sql.functions import col, xxhash64\n",
				"\n",
				"def EnrichDimCampaignChannelBridge(df: DataFrame) -> DataFrame:\n",
				"    dimCampaignDf = get_gold_table(\"DimCampaign\").select(\"CampaignId\", \"CampaignKey\")\n",
				"    dimChannelDf = get_gold_table(\"DimChannel\").select(\"ChannelId\", \"ChannelKey\")\n",
				"    dimExistingBridge = get_gold_table(\"DimCampaignChannelBridge\").select(\"CampaignChannelId\")\n",
				"\n",
				"    new_df = (\n",
				"        df\n",
				"        .join(dimCampaignDf, on=\"CampaignId\", how=\"left\")\n",
				"        .join(dimChannelDf, on=\"ChannelId\", how=\"left\")\n",
				"        .withColumn(\"CampaignChannelBridgeKey\", xxhash64(\"CampaignId\", \"ChannelId\").cast(\"bigint\"))\n",
				"        .select(\n",
				"            \"CampaignChannelBridgeKey\",\n",
				"            \"CampaignChannelId\",\n",
				"            \"CampaignKey\",\n",
				"            \"ChannelKey\"\n",
				"        )\n",
				"    )\n",
				"\n",
				"    logging.info(f\"‚úÖ DimCampaignChannelBridge processing {new_df.count()} rows.\")\n",
				"    return new_df\n",
				"\n",
				"campaignChannelBridgeTable = CdfTable(\n",
				"    source_table_name=\"CampaignChannel\",\n",
				"    source_primary_key=\"CampaignChannelId\",\n",
				"    target_table_name=\"DimCampaignChannelBridge\",\n",
				"    columns=[\n",
				"        \"CampaignChannelId\",\n",
				"        \"CampaignId\",\n",
				"        \"ChannelId\"\n",
				"        # \"ModifiedDate\"\n",
				"    ],\n",
				"    merge_sql_template=f\"\"\"\n",
				"    MERGE INTO {gold_lakehouse_name}.DimCampaignChannelBridge AS target\n",
				"    USING latestSnapshot_CampaignChannel AS source\n",
				"    ON target.CampaignChannelId = source.CampaignChannelId\n",
				"    WHEN MATCHED THEN UPDATE SET\n",
				"        CampaignKey = source.CampaignKey,\n",
				"        ChannelKey = source.ChannelKey\n",
				"    WHEN NOT MATCHED THEN INSERT (\n",
				"        CampaignChannelBridgeKey,\n",
				"        CampaignChannelId,\n",
				"        CampaignKey,\n",
				"        ChannelKey\n",
				"    ) VALUES (\n",
				"        source.CampaignChannelBridgeKey,\n",
				"        source.CampaignChannelId,\n",
				"        source.CampaignKey,\n",
				"        source.ChannelKey\n",
				"    )\n",
				"    \"\"\",\n",
				"    source_lakehouse=silver_lakehouse_name,\n",
				"    target_lakehouse=gold_lakehouse_name,\n",
				"    enrich_func=EnrichDimCampaignChannelBridge,\n",
				"    hard_delete=True\n",
				")\n",
				"\n",
				"ProcessCdfTable(campaignChannelBridgeTable)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "ff728524-ffed-4c37-8ee5-a49a02582f87",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"source": [
				"## Program"
			]
		},
		{
			"cell_type": "markdown",
			"id": "e4d69b74-4a50-4111-86eb-7f3dda65aba0",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"source": [
				"### Build: DimProgram"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "a4f9c96d-10a1-4c68-b05c-d71117bba795",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"outputs": [],
			"source": [
				"from pyspark.sql.functions import col, expr, xxhash64\n",
				"\n",
				"def EnrichDimProgram(df: DataFrame) -> DataFrame:\n",
				"    dimSourceDf = get_gold_table(\"DimSource\").select(\"SourceId\", \"SourceKey\")\n",
				"    dimDateDf = get_gold_table(\"DimDate\").select(\"Date\", \"DateKey\")\n",
				"\n",
				"    dimDateCreated = dimDateDf.select(\n",
				"        col(\"Date\").alias(\"CreatedDate_lookup\"),\n",
				"        col(\"DateKey\").alias(\"CreatedDateKey\")\n",
				"    )\n",
				"\n",
				"    dimDateModified = dimDateDf.select(\n",
				"        col(\"Date\").alias(\"ModifiedDate_lookup\"),\n",
				"        col(\"DateKey\").alias(\"ModifiedDateKey\")\n",
				"    )\n",
				"\n",
				"    # enrich\n",
				"    new_df = (\n",
				"        df\n",
				"        .join(dimSourceDf, on=\"SourceId\", how=\"left\")\n",
				"        .join(dimDateCreated, expr(\"cast(CreatedDate as date) = CreatedDate_lookup\"), \"left\")\n",
				"        .join(dimDateModified, expr(\"cast(ModifiedDate as date) = ModifiedDate_lookup\"), \"left\")\n",
				"        .withColumn(\"ProgramKey\", xxhash64(\"ProgramId\", \"SourceSystemId\").cast(\"bigint\"))\n",
				"        .select(\n",
				"            \"ProgramKey\",\n",
				"            \"ProgramId\",\n",
				"            col(\"Name\").alias(\"ProgramName\"),\n",
				"            col(\"SourceSystemId\").alias(\"SourceSysProgramId\"),\n",
				"            \"CreatedDateKey\",\n",
				"            \"ModifiedDateKey\",\n",
				"            \"SourceKey\"\n",
				"        )\n",
				"    )\n",
				"\n",
				"    logging.info(f\"‚úÖ DimProgram processing {new_df.count()} rows.\")\n",
				"\n",
				"    return new_df\n",
				"\n",
				"programTable = CdfTable(\n",
				"    source_table_name=\"Program\",\n",
				"    source_primary_key=\"ProgramId\",\n",
				"    target_table_name=\"DimProgram\",\n",
				"    columns=[\"ProgramId\", \"Name\", \"SourceSystemId\", \"SourceId\", \"CreatedDate\", \"ModifiedDate\"],\n",
				"    merge_sql_template=f\"\"\"\n",
				"    MERGE INTO {gold_lakehouse_name}.DimProgram AS target\n",
				"    USING latestSnapshot_Program AS source\n",
				"    ON target.ProgramId = source.ProgramId\n",
				"    WHEN MATCHED THEN UPDATE SET\n",
				"        ProgramName = source.ProgramName,\n",
				"        SourceSysProgramId = source.SourceSysProgramId,\n",
				"        CreatedDateKey = source.CreatedDateKey,\n",
				"        ModifiedDateKey = source.ModifiedDateKey,\n",
				"        SourceKey = source.SourceKey\n",
				"    WHEN NOT MATCHED THEN INSERT (\n",
				"        ProgramKey, ProgramId, ProgramName, SourceSysProgramId, CreatedDateKey, ModifiedDateKey, SourceKey\n",
				"    ) VALUES (\n",
				"        source.ProgramKey, source.ProgramId, source.ProgramName, source.SourceSysProgramId, source.CreatedDateKey, source.ModifiedDateKey, source.SourceKey\n",
				"    )\n",
				"    \"\"\",\n",
				"    source_lakehouse=silver_lakehouse_name,\n",
				"    target_lakehouse=gold_lakehouse_name,\n",
				"    enrich_func=EnrichDimProgram,\n",
				"    hard_delete=True\n",
				")\n",
				"\n",
				"ProcessCdfTable(programTable)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "eb1e5bcb-feb2-440c-bc8a-a270a4270448",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"source": [
				"## Activities"
			]
		},
		{
			"cell_type": "markdown",
			"id": "245b4257-61c2-4c2b-8a07-92d5bc8e66c0",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"source": [
				"### Build: DimLetter"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "6795645e-73a6-4c27-9809-bb67f42b1511",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"outputs": [],
			"source": [
				"from pyspark.sql.functions import col, expr, xxhash64\n",
				"\n",
				"def EnrichDimLetter(df: DataFrame) -> DataFrame:\n",
				"    dimSourceDf = get_gold_table(\"DimSource\").select(\"SourceId\", \"SourceKey\")\n",
				"    dimDateDf = get_gold_table(\"DimDate\")\n",
				"    dimChannelDf = get_gold_table(\"DimChannel\").select(\"ChannelId\", \"ChannelKey\")\n",
				"\n",
				"    date_created = dimDateDf.select(\n",
				"        col(\"Date\").alias(\"CreatedDate_lookup\"),\n",
				"        col(\"DateKey\").alias(\"CreatedDateKey\")\n",
				"    )\n",
				"\n",
				"    date_modified = dimDateDf.select(\n",
				"        col(\"Date\").alias(\"ModifiedDate_lookup\"),\n",
				"        col(\"DateKey\").alias(\"ModifiedDateKey\")\n",
				"    )\n",
				"\n",
				"    date_sent = dimDateDf.select(\n",
				"        col(\"Date\").alias(\"SentDate_lookup\"),\n",
				"        col(\"DateKey\").alias(\"SentDateKey\")\n",
				"    )\n",
				"\n",
				"    new_df = (\n",
				"        df\n",
				"        .join(dimSourceDf, on=\"SourceId\", how=\"left\")\n",
				"        .join(dimChannelDf, on=\"ChannelId\", how=\"left\")\n",
				"        .join(date_created, expr(\"cast(CreatedDate as date) = CreatedDate_lookup\"), \"left\")\n",
				"        .join(date_modified, expr(\"cast(ModifiedDate as date) = ModifiedDate_lookup\"), \"left\")\n",
				"        .join(date_sent, expr(\"cast(SentDate as date) = SentDate_lookup\"), \"left\")\n",
				"        .withColumn(\"LetterKey\", xxhash64(\"LetterId\", \"SourceSystemId\").cast(\"bigint\"))\n",
				"        .select(\n",
				"            \"LetterKey\",\n",
				"            \"LetterId\",\n",
				"            col(\"Subject\").alias(\"LetterSubject\"),\n",
				"            col(\"SourceSystemId\").alias(\"SourceSysLetterId\"),\n",
				"            \"CreatedDateKey\",\n",
				"            \"ModifiedDateKey\",\n",
				"            \"SentDateKey\",\n",
				"            \"SourceKey\",\n",
				"            \"ChannelKey\"\n",
				"        )\n",
				"    )\n",
				"\n",
				"    logging.info(f\"‚úÖ DimLetter processing {new_df.count()} rows.\")\n",
				"    return new_df\n",
				"\n",
				"\n",
				"letterTable = CdfTable(\n",
				"    source_table_name=\"Letter\",\n",
				"    source_primary_key=\"LetterId\",\n",
				"    target_table_name=\"DimLetter\",\n",
				"    columns=[\"LetterId\", \"Subject\", \"SourceSystemId\", \"CreatedDate\", \"ModifiedDate\", \"SentDate\", \"SourceId\", \"ChannelId\"],\n",
				"    merge_sql_template=f\"\"\"\n",
				"    MERGE INTO {gold_lakehouse_name}.DimLetter AS target\n",
				"    USING latestSnapshot_Letter AS source\n",
				"    ON target.LetterId = source.LetterId\n",
				"    WHEN MATCHED THEN UPDATE SET\n",
				"        LetterSubject = source.LetterSubject,\n",
				"        SourceSysLetterId = source.SourceSysLetterId,\n",
				"        CreatedDateKey = source.CreatedDateKey,\n",
				"        ModifiedDateKey = source.ModifiedDateKey,\n",
				"        SentDateKey = source.SentDateKey,\n",
				"        SourceKey = source.SourceKey,\n",
				"        ChannelKey = source.ChannelKey\n",
				"    WHEN NOT MATCHED THEN INSERT (\n",
				"        LetterKey, LetterId, LetterSubject, SourceSysLetterId,\n",
				"        CreatedDateKey, ModifiedDateKey, SentDateKey, SourceKey, ChannelKey\n",
				"    ) VALUES (\n",
				"        source.LetterKey, source.LetterId, source.LetterSubject, source.SourceSysLetterId,\n",
				"        source.CreatedDateKey, source.ModifiedDateKey, source.SentDateKey, source.SourceKey, source.ChannelKey\n",
				"    )\n",
				"    \"\"\",\n",
				"    source_lakehouse=silver_lakehouse_name,\n",
				"    target_lakehouse=gold_lakehouse_name,\n",
				"    enrich_func=EnrichDimLetter,\n",
				"    hard_delete=True\n",
				")\n",
				"\n",
				"ProcessCdfTable(letterTable)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "a4ba6fad-c01c-41fb-ac8a-a3b698470c32",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"source": [
				"### Build: DimPhonecall"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "ec64487d-b46d-4617-843b-686f13d0cf0c",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"outputs": [],
			"source": [
				"from pyspark.sql.functions import col, to_date, xxhash64\n",
				"\n",
				"def EnrichDimPhonecall(df: DataFrame) -> DataFrame:\n",
				"    dimDateDf = get_gold_table(\"DimDate\").select(\"Date\", \"DateKey\")   \n",
				"\n",
				"    dimDateCreated = dimDateDf.select(\n",
				"        col(\"Date\").alias(\"CreatedDate_lookup\"),\n",
				"        col(\"DateKey\").alias(\"CreatedDateKey\")\n",
				"    )\n",
				"\n",
				"    dimDateModified = dimDateDf.select(\n",
				"        col(\"Date\").alias(\"ModifiedDate_lookup\"),\n",
				"        col(\"DateKey\").alias(\"ModifiedDateKey\")\n",
				"    )\n",
				"\n",
				"    dim_source = get_gold_table(\"DimSource\").select(\"SourceId\", \"SourceKey\")\n",
				"\n",
				"    dim_channel = get_gold_table(\"DimChannel\").select(\"ChannelId\", \"ChannelKey\")\n",
				"\n",
				"    new_df = (\n",
				"        df.select(\"PhonecallId\", \"Description\", \"CreatedDate\", \"ModifiedDate\", \"SourceId\", \"SourceSystemId\", \"ChannelId\")\n",
				"          .withColumn(\"PhonecallKey\", xxhash64(\"PhonecallId\", \"SourceSystemId\").cast(\"bigint\"))\n",
				"          .join(dimDateCreated, to_date(\"CreatedDate\") == col(\"CreatedDate_lookup\"), \"left\")\n",
				"          .join(dimDateModified, to_date(\"ModifiedDate\") == col(\"ModifiedDate_lookup\"), \"left\")\n",
				"          .join(dim_source, \"SourceId\", \"left\")\n",
				"          .join(dim_channel, \"ChannelId\", \"left\")\n",
				"          .select(\n",
				"              \"PhonecallKey\",\n",
				"              \"PhonecallId\",\n",
				"              col(\"SourceSystemId\").alias(\"SourceSysPhonecallId\"),\n",
				"              col(\"Description\").alias(\"PhonecallDescription\"),\n",
				"              \"CreatedDateKey\",\n",
				"              \"ModifiedDateKey\",\n",
				"              \"SourceKey\",\n",
				"              \"ChannelKey\"\n",
				"          )\n",
				"    )\n",
				"\n",
				"    logging.info(f\"‚úÖ DimPhonecall processing {new_df.count()} rows.\")\n",
				"    return new_df\n",
				"\n",
				"\n",
				"dimPhonecallTable = CdfTable(\n",
				"    source_table_name=\"Phonecall\",\n",
				"    source_primary_key=\"PhonecallId\",\n",
				"    target_table_name=\"DimPhonecall\",\n",
				"    columns=[\"PhonecallId\", \"Description\", \"CreatedDate\", \"ModifiedDate\", \"SourceId\", \"SourceSystemId\", \"ChannelId\"], \n",
				"    merge_sql_template=f\"\"\"\n",
				"    MERGE INTO {gold_lakehouse_name}.DimPhonecall AS target\n",
				"    USING latestSnapshot_Phonecall AS source\n",
				"    ON target.PhonecallId = source.PhonecallId\n",
				"    WHEN MATCHED THEN UPDATE SET\n",
				"        PhonecallDescription = source.PhonecallDescription,\n",
				"        SourceSysPhonecallId = source.SourceSysPhonecallId,\n",
				"        CreatedDateKey = source.CreatedDateKey,\n",
				"        ModifiedDateKey = source.ModifiedDateKey,\n",
				"        SourceKey = source.SourceKey,\n",
				"        ChannelKey = source.ChannelKey\n",
				"    WHEN NOT MATCHED THEN INSERT (\n",
				"        PhonecallKey, PhonecallId, PhonecallDescription, SourceSysPhonecallId, CreatedDateKey, ModifiedDateKey, SourceKey, ChannelKey\n",
				"    ) VALUES (\n",
				"        source.PhonecallKey, source.PhonecallId, source.PhonecallDescription, source.SourceSysPhonecallId,\n",
				"        source.CreatedDateKey, source.ModifiedDateKey, source.SourceKey, source.ChannelKey\n",
				"    )\n",
				"    \"\"\",\n",
				"    source_lakehouse=silver_lakehouse_name,\n",
				"    target_lakehouse=gold_lakehouse_name,\n",
				"    enrich_func=EnrichDimPhonecall,\n",
				"    hard_delete=True\n",
				")\n",
				"\n",
				"ProcessCdfTable(dimPhonecallTable)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "f94e0592-953d-4a00-ad2c-85def1c90c66",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"source": [
				"### Build: DimEmail"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "553d839e-6596-4a95-a448-e5c93aa98b1f",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"outputs": [],
			"source": [
				"from pyspark.sql import DataFrame\n",
				"from pyspark.sql.functions import col, to_date, xxhash64\n",
				"\n",
				"def EnrichDimEmail(df: DataFrame) -> DataFrame:\n",
				"    # Load dimension tables\n",
				"    dimDate = get_gold_table(\"DimDate\").select(col(\"Date\").alias(\"DimDate\"), col(\"DateKey\"))\n",
				"    dimSource = get_gold_table(\"DimSource\").select(\"SourceId\", \"SourceKey\")\n",
				"    dimChannel = get_gold_table(\"DimChannel\").select(\"ChannelId\", \"ChannelKey\")\n",
				"\n",
				"    # Prepare date joins\n",
				"    dateCreated = dimDate.withColumnRenamed(\"DimDate\", \"CreatedDate_lookup\").withColumnRenamed(\"DateKey\", \"CreatedDateKey\")\n",
				"    dateModified = dimDate.withColumnRenamed(\"DimDate\", \"ModifiedDate_lookup\").withColumnRenamed(\"DateKey\", \"ModifiedDateKey\")\n",
				"\n",
				"    # Enrichment\n",
				"    enriched = (\n",
				"        df\n",
				"        .join(dimSource, \"SourceId\", \"left\")\n",
				"        .join(dimChannel, \"ChannelId\", \"left\")\n",
				"        .join(dateCreated, to_date(\"CreatedDate\") == col(\"CreatedDate_lookup\"), \"left\")\n",
				"        .join(dateModified, to_date(\"ModifiedDate\") == col(\"ModifiedDate_lookup\"), \"left\")\n",
				"        .withColumn(\"EmailKey\", xxhash64(\"EmailId\", \"SourceSystemId\").cast(\"bigint\"))\n",
				"        .withColumnRenamed(\"SourceSystemId\", \"SourceSystemEmailId\")\n",
				"        .select(\n",
				"            \"EmailEngagementId\",\n",
				"            \"EmailId\",\n",
				"            \"EmailKey\",\n",
				"            col(\"Subject\").alias(\"EmailSubject\"),\n",
				"            \"SourceSystemEmailId\",\n",
				"            \"ChannelKey\",\n",
				"            \"SourceKey\",\n",
				"            \"CreatedDateKey\",\n",
				"            \"ModifiedDateKey\",\n",
				"            \"VariantType\"\n",
				"        )\n",
				"    )\n",
				"\n",
				"    logging.info(f\"‚úÖ DimEmail processing {enriched.count()} rows.\")\n",
				"    return enriched\n",
				"\n",
				"\n",
				"\n",
				"dimEmailTable = CdfTable(\n",
				"    source_table_name=\"EmailEngagement\",\n",
				"    source_primary_key=\"EmailEngagementId\",\n",
				"    target_table_name=\"DimEmail\",\n",
				"    columns=[\n",
				"        \"EmailEngagementId\", \"EmailId\", \"Subject\", \"VariantType\", \"CreatedDate\", \"ModifiedDate\", \"ChannelId\",\n",
				"        \"SourceId\", \"SourceSystemId\"\n",
				"    ],\n",
				"    merge_sql_template=f\"\"\"\n",
				"MERGE INTO {gold_lakehouse_name}.DimEmail AS target\n",
				"USING latestSnapshot_EmailEngagement AS source\n",
				"ON target.EmailEngagementId = source.EmailEngagementId\n",
				"WHEN MATCHED THEN UPDATE SET\n",
				"    EmailSubject = source.EmailSubject,\n",
				"    SourceSystemEmailId = source.SourceSystemEmailId,\n",
				"    ChannelKey = source.ChannelKey,\n",
				"    SourceKey = source.SourceKey,\n",
				"    ModifiedDateKey = source.ModifiedDateKey,\n",
				"    CreatedDateKey = source.CreatedDateKey,\n",
				"    VariantType = source.VariantType\n",
				"WHEN NOT MATCHED THEN INSERT (\n",
				"    EmailEngagementId, EmailId, EmailKey, EmailSubject, SourceSystemEmailId,\n",
				"    ChannelKey, SourceKey, ModifiedDateKey, CreatedDateKey, VariantType\n",
				") VALUES (\n",
				"    source.EmailEngagementId, source.EmailId, source.EmailKey, source.EmailSubject, source.SourceSystemEmailId,\n",
				"    source.ChannelKey, source.SourceKey, source.ModifiedDateKey, source.CreatedDateKey, source.VariantType\n",
				")\n",
				"\n",
				"    \"\"\",\n",
				"    source_lakehouse=silver_lakehouse_name,\n",
				"    target_lakehouse=gold_lakehouse_name,\n",
				"    enrich_func=EnrichDimEmail,\n",
				"    hard_delete=True\n",
				")\n",
				"\n",
				"ProcessCdfTable(dimEmailTable)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "c46ed6d7-1f42-49bc-88e3-0ce2ff8eab37",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"source": [
				"## Constituent"
			]
		},
		{
			"cell_type": "markdown",
			"id": "3f16ecc3-10d7-4119-bb66-c520d296f7ec",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"source": [
				"### Build: DimConstituent"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "6d6807db-f3b9-431e-9cfc-51c1746e76db",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"outputs": [],
			"source": [
				"from pyspark.sql import DataFrame\n",
				"from pyspark.sql.functions import (\n",
				"    col, when, concat_ws, coalesce, lit, xxhash64, to_date, row_number\n",
				")\n",
				"from pyspark.sql.window import Window\n",
				"\n",
				"\n",
				"def EnrichDimConstituent(df: DataFrame) -> DataFrame:\n",
				"    # üóÇÔ∏è Load reference tables\n",
				"    dimDateDf = get_gold_table(\"DimDate\").select(\"Date\", \"DateKey\")\n",
				"    dimAddressDf = get_gold_table(\"DimAddress\").select(\"AddressId\", \"AddressKey\")\n",
				"    dimSourceDf = get_gold_table(\"DimSource\").select(\"SourceId\", \"SourceKey\")\n",
				"\n",
				"    engagementStageDf = get_table_from_lakehouse(silver_lakehouse_name, \"EngagementStage\") \\\n",
				"        .select(\"EngagementStageId\", col(\"Name\").alias(\"StageName\"))\n",
				"\n",
				"    constituentTypeDf = get_table_from_lakehouse(silver_lakehouse_name, \"ConstituentType\") \\\n",
				"        .select(\"ConstituentTypeId\", col(\"Name\").alias(\"ConstituentTypeName\"))\n",
				"\n",
				"    genderDf = get_table_from_lakehouse(silver_lakehouse_name, \"Gender\") \\\n",
				"        .select(\"GenderId\", col(\"Name\").alias(\"GenderName\"))\n",
				"\n",
				"    contactDf = get_table_from_lakehouse(silver_lakehouse_name, \"Contact\").alias(\"contact\")\n",
				"    accountDf = get_table_from_lakehouse(silver_lakehouse_name, \"Account\").alias(\"account\")\n",
				"    constituentAllDf = get_table_from_lakehouse(silver_lakehouse_name, \"Constituent\").alias(\"constituent\")\n",
				"\n",
				"    # ‚úÖ Join source\n",
				"    if \"ConstituentId\" in df.columns:\n",
				"        constituentDf = constituentAllDf.join(df, \"ConstituentId\", \"inner\")\n",
				"    elif \"AccountId\" in df.columns:\n",
				"        constituentDf = constituentAllDf.join(df, \"AccountId\", \"inner\")\n",
				"    elif \"ContactId\" in df.columns:\n",
				"        constituentDf = constituentAllDf.join(df, \"ContactId\", \"inner\")\n",
				"    else:\n",
				"        raise ValueError(\"Input DataFrame must contain one of: ConstituentId, AccountId, ContactId\")\n",
				"\n",
				"    # üîó Join enrichment\n",
				"    df_joined = (\n",
				"        constituentDf\n",
				"        .join(accountDf, \"AccountId\", \"left\")\n",
				"        .join(contactDf, \"ContactId\", \"left\")\n",
				"        .join(dimAddressDf, coalesce(col(\"contact.AddressId\"), col(\"account.AddressId\")) == dimAddressDf.AddressId, \"left\")\n",
				"        .withColumn(\"RegistrationDateCoalesced\", coalesce(col(\"contact.RegistrationDate\"), col(\"account.RegistrationDate\")))\n",
				"        .withColumn(\"CreatedDateCoalesced\", coalesce(col(\"contact.CreatedDate\"), col(\"account.CreatedDate\")))\n",
				"        .withColumn(\"ModifiedDateCoalesced\", coalesce(col(\"contact.ModifiedDate\"), col(\"account.ModifiedDate\")))\n",
				"        .join(\n",
				"            dimDateDf.withColumnRenamed(\"DateKey\", \"CreatedDateKey\").withColumnRenamed(\"Date\", \"CreatedDate_lookup\"),\n",
				"            to_date(col(\"CreatedDateCoalesced\")) == col(\"CreatedDate_lookup\"), \"left\"\n",
				"        )\n",
				"        .join(\n",
				"            dimDateDf.withColumnRenamed(\"DateKey\", \"ModifiedDateKey\").withColumnRenamed(\"Date\", \"ModifiedDate_lookup\"),\n",
				"            to_date(col(\"ModifiedDateCoalesced\")) == col(\"ModifiedDate_lookup\"), \"left\"\n",
				"        )\n",
				"        .join(\n",
				"            dimDateDf.withColumnRenamed(\"DateKey\", \"RegistrationDateKey\").withColumnRenamed(\"Date\", \"RegDate_lookup\"),\n",
				"            to_date(col(\"RegistrationDateCoalesced\")) == col(\"RegDate_lookup\"), \"left\"\n",
				"        )\n",
				"        .withColumn(\"SourceIdCoalesced\", coalesce(col(\"contact.SourceId\"), col(\"account.SourceId\")))\n",
				"        .join(dimSourceDf, col(\"SourceIdCoalesced\") == dimSourceDf.SourceId, \"left\")\n",
				"        .withColumn(\"EngagementStageIdCoalesced\", coalesce(col(\"contact.EngagementStageId\"), col(\"account.EngagementStageId\")))\n",
				"        .join(engagementStageDf, col(\"EngagementStageIdCoalesced\") == engagementStageDf.EngagementStageId, \"left\")\n",
				"        .join(constituentTypeDf, col(\"constituent.ConstituentTypeId\") == constituentTypeDf.ConstituentTypeId, \"left\")\n",
				"        .join(genderDf, col(\"contact.GenderId\") == genderDf.GenderId, \"left\")\n",
				"        .withColumn(\"ConstituentName\",\n",
				"            when(col(\"contact.FirstName\").isNotNull(),\n",
				"                concat_ws(\" \", col(\"contact.FirstName\"), col(\"contact.LastName\")))\n",
				"            .otherwise(col(\"account.Name\"))\n",
				"        )\n",
				"        .withColumn(\"FinalEmail\", when(col(\"contact.Email\").isNotNull(), col(\"contact.Email\"))\n",
				"                    .otherwise(col(\"account.Email\")))\n",
				"    )\n",
				"\n",
				"    df_joined = df_joined.withColumn(\n",
				"        \"ConstituentKey\",\n",
				"        xxhash64(\n",
				"            col(\"ConstituentId\"),\n",
				"            when(col(\"contact.SourceSystemId\").isNotNull(), col(\"contact.SourceSystemId\"))\n",
				"            .otherwise(col(\"account.SourceSystemId\"))\n",
				"        ).cast(\"bigint\")\n",
				"    )\n",
				"\n",
				"    df_joined = df_joined.withColumn(\"is_contact_preferred\", col(\"contact.ContactId\").isNotNull().cast(\"int\"))\n",
				"    window_spec = Window.partitionBy(\"ConstituentId\").orderBy(col(\"is_contact_preferred\").desc())\n",
				"\n",
				"    df_joined_deduped = df_joined.withColumn(\"rownum\", row_number().over(window_spec)) \\\n",
				"                                 .filter(col(\"rownum\") == 1) \\\n",
				"                                 .drop(\"rownum\", \"is_contact_preferred\")\n",
				"\n",
				"    # ‚úÖ Final select\n",
				"    df_joined_deduped = df_joined_deduped.select(\n",
				"        \"ConstituentKey\",\n",
				"        \"ConstituentId\",\n",
				"        when(col(\"contact.SourceSystemId\").isNotNull(), col(\"contact.SourceSystemId\"))\n",
				"            .otherwise(col(\"account.SourceSystemId\")).alias(\"SourceSysConstituentId\"),\n",
				"        \"ConstituentName\",\n",
				"        col(\"FinalEmail\").alias(\"Email\"),\n",
				"        col(\"StageName\").alias(\"EngagementStage\"),\n",
				"        col(\"ConstituentTypeName\").alias(\"ConstituentType\"),\n",
				"        col(\"GenderName\").alias(\"Gender\"),\n",
				"        \"AddressKey\",\n",
				"        \"CreatedDateKey\",\n",
				"        \"ModifiedDateKey\",\n",
				"        \"RegistrationDateKey\",\n",
				"        \"SourceKey\"\n",
				"    )\n",
				"\n",
				"    count = df_joined_deduped.count()\n",
				"    print(f\"‚úÖ DimConstituent: {count} new rows will be inserted/updated.\")\n",
				"    if count > 0:\n",
				"        print(\"üìÑ Preview of inserted/updated rows:\")\n",
				"        df_joined_deduped.show(10, truncate=False)\n",
				"\n",
				"    return df_joined_deduped\n",
				"\n",
				"\n",
				"def generate_merge_sql(target_table: str, snapshot_name: str) -> str:\n",
				"    return f\"\"\"\n",
				"    MERGE INTO {gold_lakehouse_name}.{target_table} AS target\n",
				"    USING {snapshot_name} AS source\n",
				"    ON target.ConstituentId = source.ConstituentId\n",
				"    WHEN MATCHED THEN UPDATE SET\n",
				"        target.ConstituentKey = source.ConstituentKey,\n",
				"        target.SourceSysConstituentId = source.SourceSysConstituentId,\n",
				"        target.ConstituentName = source.ConstituentName,\n",
				"        target.Email = source.Email,\n",
				"        target.EngagementStage = source.EngagementStage,\n",
				"        target.ConstituentType = source.ConstituentType,\n",
				"        target.Gender = source.Gender,\n",
				"        target.AddressKey = source.AddressKey,\n",
				"        target.CreatedDateKey = source.CreatedDateKey,\n",
				"        target.ModifiedDateKey = source.ModifiedDateKey,\n",
				"        target.RegistrationDateKey = source.RegistrationDateKey,\n",
				"        target.SourceKey = source.SourceKey\n",
				"    WHEN NOT MATCHED THEN INSERT (\n",
				"        ConstituentKey,\n",
				"        ConstituentId,\n",
				"        SourceSysConstituentId,\n",
				"        ConstituentName,\n",
				"        Email,\n",
				"        EngagementStage,\n",
				"        ConstituentType,\n",
				"        Gender,\n",
				"        AddressKey,\n",
				"        CreatedDateKey,\n",
				"        ModifiedDateKey,\n",
				"        RegistrationDateKey,\n",
				"        SourceKey\n",
				"    ) VALUES (\n",
				"        source.ConstituentKey,\n",
				"        source.ConstituentId,\n",
				"        source.SourceSysConstituentId,\n",
				"        source.ConstituentName,\n",
				"        source.Email,\n",
				"        source.EngagementStage,\n",
				"        source.ConstituentType,\n",
				"        source.Gender,\n",
				"        source.AddressKey,\n",
				"        source.CreatedDateKey,\n",
				"        source.ModifiedDateKey,\n",
				"        source.RegistrationDateKey,\n",
				"        source.SourceKey\n",
				"    )\n",
				"    \"\"\"\n",
				"\n",
				"def map_contact_to_constituent(keys_df, table):\n",
				"    # keys_df has column ContactId (built from the CDF PK of the Contact source)\n",
				"    cons = get_silver_table(\"Constituent\").select(\"ConstituentId\", \"ContactId\")\n",
				"    return (keys_df.alias(\"k\")\n",
				"            .join(cons.alias(\"c\"), col(\"k.ContactId\") == col(\"c.ContactId\"), \"inner\")\n",
				"            .select(col(\"c.ConstituentId\").alias(\"ConstituentId\"))\n",
				"            .dropDuplicates())\n",
				"\n",
				"def map_account_to_constituent(keys_df, table):\n",
				"    # keys_df has column AccountId (built from the CDF PK of the Account source)\n",
				"    cons = get_silver_table(\"Constituent\").select(\"ConstituentId\", \"AccountId\")\n",
				"    return (keys_df.alias(\"k\")\n",
				"            .join(cons.alias(\"c\"), col(\"k.AccountId\") == col(\"c.AccountId\"), \"inner\")\n",
				"            .select(col(\"c.ConstituentId\").alias(\"ConstituentId\"))\n",
				"            .dropDuplicates())\n",
				"\n",
				"\n",
				"constituentTable = CdfTable(\n",
				"    source_table_name=\"Constituent\",\n",
				"    source_primary_key=\"ConstituentId\",\n",
				"    target_table_name=\"DimConstituent\",\n",
				"    columns=[\n",
				"        \"ConstituentId\",\n",
				"        \"AccountId\",\n",
				"        \"ContactId\",\n",
				"        \"ConstituentTypeId\"\n",
				"    ],\n",
				"    merge_sql_template = generate_merge_sql(\"DimConstituent\", \"latestSnapshot_Constituent\"),\n",
				"    source_lakehouse=silver_lakehouse_name,\n",
				"    target_lakehouse=gold_lakehouse_name,\n",
				"    enrich_func=EnrichDimConstituent,\n",
				"    hard_delete=True,\n",
				"    delete_on=\"t.ConstituentId = k.ConstituentId\" \n",
				")\n",
				"\n",
				"accountTable = CdfTable(\n",
				"    source_table_name=\"Account\",\n",
				"    source_primary_key=\"AccountId\",\n",
				"    target_table_name=\"DimConstituent\",\n",
				"    columns=[\n",
				"        \"AccountId\",\n",
				"        \"Name\",\n",
				"        \"Email\",\n",
				"        \"EngagementStageId\",\n",
				"        \"AddressId\",\n",
				"        \"RegistrationDate\",\n",
				"        \"CreatedDate\",\n",
				"        \"ModifiedDate\",\n",
				"        \"SourceId\",\n",
				"        \"SourceSystemId\"\n",
				"    ],\n",
				"    merge_sql_template = generate_merge_sql(\"DimConstituent\", \"latestSnapshot_Account\"),\n",
				"    source_lakehouse=silver_lakehouse_name,\n",
				"    target_lakehouse=gold_lakehouse_name,\n",
				"    enrich_func=EnrichDimConstituent,\n",
				"    hard_delete=True,\n",
				"    delete_on=\"t.ConstituentId = k.ConstituentId\",\n",
				"    delete_key_mapper=map_account_to_constituent   \n",
				")\n",
				"\n",
				"contactTable = CdfTable(\n",
				"    source_table_name=\"Contact\",\n",
				"    source_primary_key=\"ContactId\",\n",
				"    target_table_name=\"DimConstituent\",\n",
				"    columns=[\n",
				"        \"ContactId\",\n",
				"        \"FirstName\",\n",
				"        \"LastName\",\n",
				"        \"Email\",\n",
				"        \"EngagementStageId\",\n",
				"        \"GenderId\",\n",
				"        \"AddressId\",\n",
				"        \"RegistrationDate\",\n",
				"        \"CreatedDate\",\n",
				"        \"ModifiedDate\",\n",
				"        \"SourceId\",\n",
				"        \"SourceSystemId\"\n",
				"    ],\n",
				"    merge_sql_template = generate_merge_sql(\"DimConstituent\", \"latestSnapshot_Contact\"),\n",
				"    source_lakehouse=silver_lakehouse_name,\n",
				"    target_lakehouse=gold_lakehouse_name,\n",
				"    enrich_func=EnrichDimConstituent,\n",
				"    hard_delete=True,\n",
				"    delete_on=\"t.ConstituentId = k.ConstituentId\",\n",
				"    delete_key_mapper=map_contact_to_constituent      \n",
				")\n",
				"\n",
				"ProcessCdfTable(constituentTable)\n",
				"ProcessCdfTable(accountTable)\n",
				"ProcessCdfTable(contactTable)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "c32336c5-4f93-4e75-806d-1350f12c1aaf",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"source": [
				"### Build: DimConstituentSegmentType"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "03c6e242-87f5-4c5d-b7b4-e5f098118e95",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"outputs": [],
			"source": [
				"from pyspark.sql.functions import col, xxhash64\n",
				"\n",
				"def EnrichDimConstituentSegmentType(df: DataFrame) -> DataFrame:\n",
				"    dimDf = get_gold_table(\"DimConstituentSegmentType\").select(\"ConstituentSegmentTypeId\")\n",
				"\n",
				"    new_df = (\n",
				"        df\n",
				"        .withColumn(\n",
				"            \"ConstituentSegmentTypeKey\",\n",
				"            xxhash64(col(\"ConstituentSegmentTypeId\"), col(\"Name\")).cast(\"bigint\")\n",
				"        )\n",
				"        .select(\n",
				"            \"ConstituentSegmentTypeKey\",\n",
				"            \"ConstituentSegmentTypeId\",\n",
				"            col(\"Name\").alias(\"ConstituentSegmentType\")\n",
				"        )\n",
				"    )\n",
				"\n",
				"    logging.info(f\"‚úÖ DimConstituentSegmentType processing {new_df.count()} rows.\")\n",
				"\n",
				"    return new_df\n",
				"\n",
				"constituentSegmentTypeTable = CdfTable(\n",
				"    source_table_name=\"ConstituentSegmentType\",\n",
				"    source_primary_key=\"ConstituentSegmentTypeId\",\n",
				"    target_table_name=\"DimConstituentSegmentType\",\n",
				"    columns=[\n",
				"        \"ConstituentSegmentTypeId\",\n",
				"        \"Name\"\n",
				"    ],\n",
				"    merge_sql_template=f\"\"\"\n",
				"    MERGE INTO {gold_lakehouse_name}.DimConstituentSegmentType AS target\n",
				"    USING latestSnapshot_ConstituentSegmentType AS source\n",
				"    ON target.ConstituentSegmentTypeId = source.ConstituentSegmentTypeId\n",
				"    WHEN MATCHED THEN UPDATE SET\n",
				"        ConstituentSegmentType = source.ConstituentSegmentType\n",
				"    WHEN NOT MATCHED THEN INSERT (\n",
				"        ConstituentSegmentTypeKey,\n",
				"        ConstituentSegmentTypeId,\n",
				"        ConstituentSegmentType\n",
				"    ) VALUES (\n",
				"        source.ConstituentSegmentTypeKey,\n",
				"        source.ConstituentSegmentTypeId,\n",
				"        source.ConstituentSegmentType\n",
				"    )\n",
				"    \"\"\",\n",
				"    source_lakehouse=silver_lakehouse_name,\n",
				"    target_lakehouse=gold_lakehouse_name,\n",
				"    enrich_func=EnrichDimConstituentSegmentType\n",
				")\n",
				"\n",
				"ProcessCdfTable(constituentSegmentTypeTable)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "9a1cbeeb-3abf-48be-9f44-3234d8930c29",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"source": [
				"### Build: DimConstituentSegment"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "a8ff83a8-2778-4f9b-83e9-249c27e8682a",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"outputs": [],
			"source": [
				"from pyspark.sql.functions import col, expr, xxhash64\n",
				"\n",
				"def EnrichDimConstituentSegment(df: DataFrame) -> DataFrame:\n",
				"    \n",
				"    # Lookup tables for keys\n",
				"    dimTypeDf = (\n",
				"        get_gold_table(\"DimConstituentSegmentType\")\n",
				"        .select(\n",
				"            \"ConstituentSegmentTypeId\",\n",
				"            col(\"ConstituentSegmentTypeKey\").alias(\"TypeKey\")\n",
				"        )\n",
				"    )\n",
				"    dimSourceDf = get_gold_table(\"DimSource\").select(\"SourceId\", \"SourceKey\")\n",
				"    dimDateDf = get_gold_table(\"DimDate\").select(\"Date\", \"DateKey\")\n",
				"    \n",
				"    dimDateCreated = dimDateDf.select(\n",
				"        col(\"Date\").alias(\"CreatedDate_lookup\"),\n",
				"        col(\"DateKey\").alias(\"CreatedDateKey\")\n",
				"    )\n",
				"    dimDateModified = dimDateDf.select(\n",
				"        col(\"Date\").alias(\"ModifiedDate_lookup\"),\n",
				"        col(\"DateKey\").alias(\"ModifiedDateKey\")\n",
				"    )\n",
				"\n",
				"    new_df = (\n",
				"        df\n",
				"        .join(dimTypeDf, on=\"ConstituentSegmentTypeId\", how=\"left\")\n",
				"        .join(dimSourceDf, on=\"SourceId\", how=\"left\")\n",
				"        .join(\n",
				"            dimDateCreated,\n",
				"            expr(\"cast(CreatedDate as date) = CreatedDate_lookup\"),\n",
				"            how=\"left\"\n",
				"        )\n",
				"        .join(\n",
				"            dimDateModified,\n",
				"            expr(\"cast(ModifiedDate as date) = ModifiedDate_lookup\"),\n",
				"            how=\"left\"\n",
				"        )\n",
				"        .withColumn(\n",
				"            \"ConstituentSegmentKey\",\n",
				"            xxhash64(\n",
				"                col(\"ConstituentSegmentId\"),\n",
				"                col(\"Name\"),\n",
				"                col(\"SourceSystemId\")\n",
				"            ).cast(\"bigint\")\n",
				"        )\n",
				"        .select(\n",
				"            \"ConstituentSegmentKey\",\n",
				"            \"ConstituentSegmentId\",\n",
				"            col(\"Name\").alias(\"ConstituentSegmentName\"),\n",
				"            \"TypeKey\",\n",
				"            col(\"SourceSystemId\").alias(\"SourceSysConstituentSegmentId\"),\n",
				"            \"CreatedDateKey\",\n",
				"            \"ModifiedDateKey\",\n",
				"            \"SourceKey\",\n",
				"            \"Order\"\n",
				"        )\n",
				"    )\n",
				"\n",
				"    logging.info(f\"‚úÖ DimConstituentSegment processing {new_df.count()} rows.\")\n",
				"\n",
				"    return new_df\n",
				"\n",
				"constituentSegmentTable = CdfTable(\n",
				"    source_table_name=\"ConstituentSegment\",\n",
				"    primary_key=\"ConstituentSegmentId\",\n",
				"    target_table_name=\"DimConstituentSegment\",\n",
				"    columns=[\n",
				"        \"ConstituentSegmentId\",\n",
				"        \"ConstituentSegmentTypeId\",\n",
				"        \"Name\",\n",
				"        \"SourceSystemId\",\n",
				"        \"SourceId\",\n",
				"        \"CreatedDate\",\n",
				"        \"ModifiedDate\",\n",
				"        \"Order\"\n",
				"    ],\n",
				"    merge_sql_template=f\"\"\"\n",
				"    MERGE INTO {gold_lakehouse_name}.DimConstituentSegment AS target\n",
				"    USING latestSnapshot_ConstituentSegment AS source\n",
				"    ON target.ConstituentSegmentId = source.ConstituentSegmentId\n",
				"    WHEN MATCHED THEN UPDATE SET\n",
				"        ConstituentSegmentName = source.ConstituentSegmentName,\n",
				"        TypeKey = source.TypeKey,\n",
				"        SourceSysConstituentSegmentId = source.SourceSysConstituentSegmentId,\n",
				"        CreatedDateKey = source.CreatedDateKey,\n",
				"        ModifiedDateKey = source.ModifiedDateKey,\n",
				"        SourceKey = source.SourceKey,\n",
				"        Order = source.Order\n",
				"    WHEN NOT MATCHED THEN INSERT (\n",
				"        ConstituentSegmentKey,\n",
				"        ConstituentSegmentId,\n",
				"        ConstituentSegmentName,\n",
				"        TypeKey,\n",
				"        SourceSysConstituentSegmentId,\n",
				"        CreatedDateKey,\n",
				"        ModifiedDateKey,\n",
				"        SourceKey,\n",
				"        Order\n",
				"    ) VALUES (\n",
				"        source.ConstituentSegmentKey,\n",
				"        source.ConstituentSegmentId,\n",
				"        source.ConstituentSegmentName,\n",
				"        source.TypeKey,\n",
				"        source.SourceSysConstituentSegmentId,\n",
				"        source.CreatedDateKey,\n",
				"        source.ModifiedDateKey,\n",
				"        source.SourceKey,\n",
				"        source.Order\n",
				"    )\n",
				"    \"\"\",\n",
				"    source_lakehouse=silver_lakehouse_name,\n",
				"    target_lakehouse=gold_lakehouse_name,\n",
				"    enrich_func=EnrichDimConstituentSegment,\n",
				"    hard_delete=True\n",
				")\n",
				"\n",
				"ProcessCdfTable(constituentSegmentTable)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "93d6a845-3b12-4ca6-907a-8e538928810c",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"source": [
				"### Build: DimConstituentSegmentBridge "
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "9f80772c-2514-4bae-88d9-e4ef3b20b8c5",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"outputs": [],
			"source": [
				"def EnrichDimConstituentSegmentBridge(df: DataFrame) -> DataFrame:\n",
				"    dim_constituent = get_gold_table(\"DimConstituent\").select(\"ConstituentId\", \"ConstituentKey\")\n",
				"    dim_segment = get_gold_table(\"DimConstituentSegment\").select(\"ConstituentSegmentId\", \"ConstituentSegmentKey\")\n",
				"\n",
				"    df_new = (\n",
				"        df.join(dim_constituent, on=\"ConstituentId\", how=\"left\")\n",
				"          .join(dim_segment, on=\"ConstituentSegmentId\", how=\"left\")\n",
				"          .withColumn(\n",
				"              \"ConstituentSegmentBridgeKey\",\n",
				"              xxhash64(\n",
				"                  col(\"ConstituentSegmentMappingId\"),\n",
				"                  col(\"ConstituentId\")\n",
				"              ).cast(\"bigint\")\n",
				"          )\n",
				"          .select(\n",
				"              \"ConstituentSegmentBridgeKey\",\n",
				"              \"ConstituentSegmentMappingId\",\n",
				"              \"ConstituentKey\",\n",
				"              \"ConstituentSegmentKey\"\n",
				"          )\n",
				"    )\n",
				"\n",
				"    logging.info(f\"‚úÖ DimConstituentSegmentBridge processing {df_new.count()} rows.\")\n",
				"\n",
				"    return df_new\n",
				"\n",
				"constituentSegmentBridgeTable = CdfTable(\n",
				"    source_table_name=\"ConstituentSegmentMapping\",\n",
				"    target_table_name=\"DimConstituentSegmentBridge\",\n",
				"    source_primary_key=\"ConstituentSegmentMappingId\",\n",
				"    columns=[\n",
				"        \"ConstituentSegmentMappingId\", \"ConstituentId\", \"ConstituentSegmentId\"\n",
				"    ],\n",
				"    merge_sql_template=f\"\"\"\n",
				"    MERGE INTO {gold_lakehouse_name}.DimConstituentSegmentBridge AS target\n",
				"    USING latestSnapshot_ConstituentSegmentMapping AS source\n",
				"    ON target.ConstituentSegmentMappingId = source.ConstituentSegmentMappingId\n",
				"    WHEN MATCHED THEN UPDATE SET\n",
				"        ConstituentKey = source.ConstituentKey,\n",
				"        ConstituentSegmentKey = source.ConstituentSegmentKey\n",
				"    WHEN NOT MATCHED THEN INSERT (\n",
				"        ConstituentSegmentBridgeKey,\n",
				"        ConstituentSegmentMappingId,\n",
				"        ConstituentKey,\n",
				"        ConstituentSegmentKey\n",
				"    ) VALUES (\n",
				"        source.ConstituentSegmentBridgeKey,\n",
				"        source.ConstituentSegmentMappingId,\n",
				"        source.ConstituentKey,\n",
				"        source.ConstituentSegmentKey\n",
				"    )\n",
				"    \"\"\",\n",
				"    source_lakehouse=silver_lakehouse_name,\n",
				"    target_lakehouse=gold_lakehouse_name,\n",
				"    enrich_func=EnrichDimConstituentSegmentBridge,\n",
				"    hard_delete=True\n",
				")\n",
				"\n",
				"ProcessCdfTable(constituentSegmentBridgeTable)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "3698d9c6-8022-465a-b4fa-4a279f20c794",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"source": [
				"### Build: DimEngagementPlatform"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "59df282f-50d8-4e28-816b-73b66c6aaf09",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"outputs": [],
			"source": [
				"from pyspark.sql.functions import col, expr, xxhash64\n",
				"\n",
				"def EnrichDimEngagementPlatform(df: DataFrame) -> DataFrame:\n",
				"    dimSourceDf = get_gold_table(\"DimSource\").select(\"SourceId\", \"SourceKey\")\n",
				"    dimDateDf = get_gold_table(\"DimDate\")\n",
				"\n",
				"    date_created = dimDateDf.select(\n",
				"        col(\"Date\").alias(\"CreatedDate_lookup\"),\n",
				"        col(\"DateKey\").alias(\"CreatedDateKey\")\n",
				"    )\n",
				"\n",
				"    date_modified = dimDateDf.select(\n",
				"        col(\"Date\").alias(\"ModifiedDate_lookup\"),\n",
				"        col(\"DateKey\").alias(\"ModifiedDateKey\")\n",
				"    )\n",
				"\n",
				"    new_df = (\n",
				"        df\n",
				"        .join(dimSourceDf, on=\"SourceId\", how=\"left\")\n",
				"        .join(date_created, expr(\"cast(CreatedDate as date) = CreatedDate_lookup\"), \"left\")\n",
				"        .join(date_modified, expr(\"cast(ModifiedDate as date) = ModifiedDate_lookup\"), \"left\")\n",
				"        .withColumn(\n",
				"            \"EngagementPlatformKey\",\n",
				"            xxhash64(\n",
				"                col(\"EngagementPlatformId\"),\n",
				"                col(\"SourceSystemId\"),\n",
				"                col(\"Name\")\n",
				"            ).cast(\"bigint\")\n",
				"        )\n",
				"        .select(\n",
				"            \"EngagementPlatformKey\",\n",
				"            \"EngagementPlatformId\",\n",
				"            col(\"Name\").alias(\"EngagementPlatformName\"),\n",
				"            col(\"SourceSystemId\").alias(\"SourceSysEngagementPlatformId\"),\n",
				"            \"CreatedDateKey\",\n",
				"            \"ModifiedDateKey\",\n",
				"            \"SourceKey\"\n",
				"        )\n",
				"    )\n",
				"\n",
				"    logging.info(f\"‚úÖ DimEngagementPlatform processing {new_df.count()} rows.\")\n",
				"    return new_df\n",
				"\n",
				"engagementPlatformTable = CdfTable(\n",
				"    source_table_name=\"EngagementPlatform\",\n",
				"    primary_key=\"EngagementPlatformId\",\n",
				"    target_table_name=\"DimEngagementPlatform\",\n",
				"    columns=[\"EngagementPlatformId\", \"Name\", \"SourceSystemId\", \"CreatedDate\", \"ModifiedDate\", \"SourceId\"],\n",
				"    merge_sql_template=f\"\"\"\n",
				"    MERGE INTO {gold_lakehouse_name}.DimEngagementPlatform AS target\n",
				"    USING latestSnapshot_EngagementPlatform AS source\n",
				"    ON target.EngagementPlatformId = source.EngagementPlatformId\n",
				"    WHEN MATCHED THEN UPDATE SET\n",
				"        Name = source.EngagementPlatformName,\n",
				"        SourceSysEngagementPlatformId = source.SourceSysEngagementPlatformId,\n",
				"        CreatedDateKey = source.CreatedDateKey,\n",
				"        ModifiedDateKey = source.ModifiedDateKey,\n",
				"        SourceKey = source.SourceKey\n",
				"    WHEN NOT MATCHED THEN INSERT (\n",
				"        EngagementPlatformKey, EngagementPlatformId, Name, SourceSysEngagementPlatformId,\n",
				"        CreatedDateKey, ModifiedDateKey, SourceKey\n",
				"    ) VALUES (\n",
				"        source.EngagementPlatformKey, source.EngagementPlatformId, source.EngagementPlatformName, source.SourceSysEngagementPlatformId,\n",
				"        source.CreatedDateKey, source.ModifiedDateKey, source.SourceKey\n",
				"    )\n",
				"    \"\"\",\n",
				"    source_lakehouse=silver_lakehouse_name,\n",
				"    target_lakehouse=gold_lakehouse_name,\n",
				"    enrich_func=EnrichDimEngagementPlatform\n",
				")\n",
				"\n",
				"ProcessCdfTable(engagementPlatformTable)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "a1f795d7-27c3-43ae-9f7b-e4e3e09982ab",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"source": [
				"### Build: DimEvent"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "468bb7a5-6c2d-47af-9eb4-0ba737aa2699",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"outputs": [],
			"source": [
				"from pyspark.sql.functions import col, expr, xxhash64\n",
				"\n",
				"def EnrichDimEvent(df: DataFrame) -> DataFrame:\n",
				"    dimSourceDf = get_gold_table(\"DimSource\").select(\"SourceId\", \"SourceKey\")\n",
				"    dimAddressDf = get_gold_table(\"DimAddress\").select(\"AddressId\", \"AddressKey\")\n",
				"    dimChannelDf = get_gold_table(\"DimChannel\").select(\"ChannelId\", \"ChannelKey\")\n",
				"    dimDateDf = get_gold_table(\"DimDate\")\n",
				"\n",
				"    date_start = dimDateDf.select(\n",
				"        col(\"Date\").alias(\"StartDate_lookup\"),\n",
				"        col(\"DateKey\").alias(\"EventDateKey\")\n",
				"    )\n",
				"    date_created = dimDateDf.select(\n",
				"        col(\"Date\").alias(\"CreatedDate_lookup\"),\n",
				"        col(\"DateKey\").alias(\"CreatedDateKey\")\n",
				"    )\n",
				"    date_modified = dimDateDf.select(\n",
				"        col(\"Date\").alias(\"ModifiedDate_lookup\"),\n",
				"        col(\"DateKey\").alias(\"ModifiedDateKey\")\n",
				"    )\n",
				"\n",
				"    new_df = (\n",
				"        df\n",
				"        .join(dimSourceDf, on=\"SourceId\", how=\"left\")\n",
				"        .join(dimAddressDf, on=\"AddressId\", how=\"left\")\n",
				"        .join(dimChannelDf, on=\"ChannelId\", how=\"left\")  \n",
				"        .join(date_start, expr(\"cast(StartDate as date) = StartDate_lookup\"), \"left\")\n",
				"        .join(date_created, expr(\"cast(CreatedDate as date) = CreatedDate_lookup\"), \"left\")\n",
				"        .join(date_modified, expr(\"cast(ModifiedDate as date) = ModifiedDate_lookup\"), \"left\")\n",
				"        .withColumn(\n",
				"            \"EventKey\",\n",
				"            xxhash64(col(\"EventId\"), col(\"SourceSystemId\")).cast(\"bigint\")\n",
				"        )\n",
				"        .select(\n",
				"            \"EventKey\",\n",
				"            \"EventId\",\n",
				"            col(\"SourceSystemId\").alias(\"SourceSysEventId\"),\n",
				"            \"EventDateKey\",\n",
				"            col(\"Name\").alias(\"EventName\"),\n",
				"            \"Cost\",\n",
				"            \"AddressKey\",\n",
				"            \"CreatedDateKey\",\n",
				"            \"ModifiedDateKey\",\n",
				"            \"ChannelKey\", \n",
				"            \"SourceKey\"\n",
				"        )\n",
				"    )\n",
				"\n",
				"    logging.info(f\"‚úÖ DimEvent processing {new_df.count()} rows.\")\n",
				"    return new_df\n",
				"\n",
				"\n",
				"eventTable = CdfTable(\n",
				"    source_table_name=\"Event\",\n",
				"    target_table_name=\"DimEvent\",\n",
				"    primary_key=\"EventId\",\n",
				"    columns=[\"EventId\", \"SourceSystemId\", \"StartDate\", \"Name\", \"Cost\",\n",
				"             \"AddressId\", \"CreatedDate\", \"ModifiedDate\", \"ChannelId\", \"SourceId\"],\n",
				"    merge_sql_template=f\"\"\"\n",
				"    MERGE INTO {gold_lakehouse_name}.DimEvent AS target\n",
				"    USING latestSnapshot_Event AS source\n",
				"    ON target.EventId = source.EventId\n",
				"    WHEN MATCHED THEN UPDATE SET\n",
				"        SourceSysEventId = source.SourceSysEventId,\n",
				"        EventDateKey = source.EventDateKey,\n",
				"        EventName = source.EventName,\n",
				"        Cost = source.Cost,\n",
				"        AddressKey = source.AddressKey,\n",
				"        CreatedDateKey = source.CreatedDateKey,\n",
				"        ModifiedDateKey = source.ModifiedDateKey,\n",
				"        ChannelKey = source.ChannelKey,\n",
				"        SourceKey = source.SourceKey\n",
				"    WHEN NOT MATCHED THEN INSERT (\n",
				"        EventKey, EventId, SourceSysEventId, EventDateKey, EventName,\n",
				"        Cost, AddressKey, CreatedDateKey, ModifiedDateKey, ChannelKey, SourceKey\n",
				"    ) VALUES (\n",
				"        source.EventKey, source.EventId, source.SourceSysEventId, source.EventDateKey,\n",
				"        source.EventName, source.Cost, source.AddressKey,\n",
				"        source.CreatedDateKey, source.ModifiedDateKey, source.ChannelKey, source.SourceKey\n",
				"    )\n",
				"    \"\"\",\n",
				"    source_lakehouse=silver_lakehouse_name,\n",
				"    target_lakehouse=gold_lakehouse_name,\n",
				"    enrich_func=EnrichDimEvent,\n",
				"    hard_delete=True\n",
				")\n",
				"\n",
				"ProcessCdfTable(eventTable)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "23a308cd-1477-439f-9a4d-8e4d3cd539cb",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"source": [
				"## Opportunity"
			]
		},
		{
			"cell_type": "markdown",
			"id": "cc729cda-3b43-4a22-bdde-09083ce3c58c",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"source": [
				"### Build: DimOpportunityType"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "00c8d47b-0fdf-41f4-b800-7b37d8b5ea22",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"outputs": [],
			"source": [
				"from pyspark.sql.functions import col, xxhash64\n",
				"\n",
				"def EnrichDimOpportunityType(df: DataFrame) -> DataFrame:\n",
				"\n",
				"    new_df = (\n",
				"        df\n",
				"        .select(\"OpportunityTypeId\", col(\"Name\").alias(\"OpportunityTypeName\"))\n",
				"        .dropna(subset=[\"OpportunityTypeId\"])\n",
				"        .withColumn(\n",
				"            \"OpportunityTypeKey\",\n",
				"            xxhash64(\n",
				"                col(\"OpportunityTypeId\"),\n",
				"                col(\"OpportunityTypeName\")\n",
				"            ).cast(\"bigint\")\n",
				"        )\n",
				"        .select(\"OpportunityTypeKey\", \"OpportunityTypeId\", \"OpportunityTypeName\")\n",
				"    )\n",
				"\n",
				"    logging.info(f\"‚úÖ DimOpportunityType processing {new_df.count()} rows.\")\n",
				"\n",
				"    return new_df\n",
				"\n",
				"dimOpportunityTypeTable = CdfTable(\n",
				"    source_table_name=\"OpportunityType\",\n",
				"    source_primary_key=\"OpportunityTypeId\",\n",
				"    target_table_name=\"DimOpportunityType\",\n",
				"    columns=[\n",
				"        \"OpportunityTypeId\", \"Name\", \"CreatedDate\", \"ModifiedDate\",\n",
				"        \"SourceId\", \"SourceSystemId\"\n",
				"    ],\n",
				"    merge_sql_template=f\"\"\"\n",
				"    MERGE INTO {gold_lakehouse_name}.DimOpportunityType AS target\n",
				"    USING latestSnapshot_OpportunityType AS source\n",
				"    ON target.OpportunityTypeId = source.OpportunityTypeId\n",
				"    WHEN MATCHED THEN UPDATE SET\n",
				"        OpportunityTypeName = source.OpportunityTypeName\n",
				"    WHEN NOT MATCHED THEN INSERT (\n",
				"        OpportunityTypeKey, OpportunityTypeId, OpportunityTypeName\n",
				"    ) VALUES (\n",
				"        source.OpportunityTypeKey, source.OpportunityTypeId, source.OpportunityTypeName\n",
				"    )\n",
				"    \"\"\",\n",
				"    source_lakehouse=silver_lakehouse_name,\n",
				"    target_lakehouse=gold_lakehouse_name,\n",
				"    enrich_func=EnrichDimOpportunityType,\n",
				"    hard_delete=True\n",
				")\n",
				"\n",
				"ProcessCdfTable(dimOpportunityTypeTable)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "d9f9f2a4-0e05-4635-ab1d-0ab4cfc077ae",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"source": [
				"### Build: DimOpportunityStage"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "feb981ab-78eb-49f0-84ce-1afda4dd9aeb",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"outputs": [],
			"source": [
				"from pyspark.sql.functions import col, xxhash64\n",
				"\n",
				"def EnrichDimOpportunityStage(df: DataFrame) -> DataFrame:\n",
				"    dim_type = get_gold_table(\"DimOpportunityType\").select(\n",
				"        \"OpportunityTypeId\", \"OpportunityTypeKey\"\n",
				"    ).alias(\"dot\")\n",
				"\n",
				"    df = df.alias(\"s\")\n",
				"\n",
				"    new_df = (\n",
				"        df\n",
				"        .join(dim_type, col(\"s.OpportunityTypeId\") == col(\"dot.OpportunityTypeId\"), \"left\")\n",
				"        .withColumn(\n",
				"            \"OpportunityStageKey\",\n",
				"            xxhash64(\n",
				"                col(\"s.OpportunityStageId\"),\n",
				"                col(\"s.OpportunityTypeId\"),\n",
				"                col(\"s.Name\")\n",
				"            ).cast(\"bigint\")\n",
				"        )\n",
				"        .select(\n",
				"            \"OpportunityStageKey\",\n",
				"            col(\"s.OpportunityStageId\"),\n",
				"            col(\"s.OpportunityTypeId\"),\n",
				"            col(\"dot.OpportunityTypeKey\"),\n",
				"            col(\"s.Name\").alias(\"OpportunityStage\")\n",
				"        )\n",
				"    )\n",
				"\n",
				"    logging.info(f\"‚úÖ DimOpportunityStage processing {new_df.count()} rows.\")\n",
				"\n",
				"    return new_df\n",
				"\n",
				"opportunityStageTable = CdfTable(\n",
				"    source_table_name=\"OpportunityStage\",\n",
				"    primary_key=\"OpportunityStageId\",\n",
				"    target_table_name=\"DimOpportunityStage\",\n",
				"    columns=[\n",
				"        \"OpportunityStageId\",\n",
				"        \"OpportunityTypeId\",\n",
				"        \"Name\"\n",
				"    ],\n",
				"    merge_sql_template=f\"\"\"\n",
				"    MERGE INTO {gold_lakehouse_name}.DimOpportunityStage AS target\n",
				"    USING latestSnapshot_OpportunityStage AS source\n",
				"    ON target.OpportunityStageId = source.OpportunityStageId\n",
				"    WHEN MATCHED THEN UPDATE SET\n",
				"        OpportunityTypeId = source.OpportunityTypeId,\n",
				"        OpportunityTypeKey = source.OpportunityTypeKey,\n",
				"        OpportunityStage = source.OpportunityStage\n",
				"    WHEN NOT MATCHED THEN INSERT (\n",
				"        OpportunityStageKey,\n",
				"        OpportunityStageId,\n",
				"        OpportunityTypeId,\n",
				"        OpportunityTypeKey,\n",
				"        OpportunityStage\n",
				"    ) VALUES (\n",
				"        source.OpportunityStageKey,\n",
				"        source.OpportunityStageId,\n",
				"        source.OpportunityTypeId,\n",
				"        source.OpportunityTypeKey,\n",
				"        source.OpportunityStage\n",
				"    )\n",
				"    \"\"\",\n",
				"    source_lakehouse=silver_lakehouse_name,\n",
				"    target_lakehouse=gold_lakehouse_name,\n",
				"    enrich_func=EnrichDimOpportunityStage\n",
				")\n",
				"\n",
				"ProcessCdfTable(opportunityStageTable)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "6dd3d774-479a-4123-95e5-75a4b67eef37",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"source": [
				"### Build: FactOpportunity"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "91e98550-8ba2-4017-a4b0-169627269cf3",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"outputs": [],
			"source": [
				"from pyspark.sql.functions import col, xxhash64\n",
				"\n",
				"def EnrichFactOpportunity(df: DataFrame) -> DataFrame:\n",
				"    import pyspark.sql.functions as F\n",
				"\n",
				"    df = df.alias(\"o\")\n",
				"\n",
				"    # Load dimension tables with aliases\n",
				"    dim_date = get_gold_table(\"DimDate\").select(F.col(\"Date\").alias(\"DimDate\"), F.col(\"DateKey\"))\n",
				"    dim_campaign = get_gold_table(\"DimCampaign\").select(\"CampaignId\", \"CampaignKey\").alias(\"dc\")\n",
				"    dim_channel = get_gold_table(\"DimChannel\").select(\"ChannelId\", \"ChannelKey\").alias(\"dch\")\n",
				"    dim_constituent = get_gold_table(\"DimConstituent\").select(\"ConstituentId\", \"ConstituentKey\").alias(\"dcon\")\n",
				"    dim_stage = get_gold_table(\"DimOpportunityStage\").select(\"OpportunityStageId\", \"OpportunityStageKey\", \"OpportunityStage\").alias(\"dos\")\n",
				"    dim_type = get_gold_table(\"DimOpportunityType\").select(\"OpportunityTypeId\", \"OpportunityTypeKey\").alias(\"dot\")\n",
				"    dim_source = get_gold_table(\"DimSource\").select(\"SourceId\", \"SourceKey\").alias(\"ds\")\n",
				"\n",
				"    new_df = (\n",
				"        df.join(dim_campaign, F.col(\"o.CampaignId\") == F.col(\"dc.CampaignId\"), \"left\")\n",
				"          .join(dim_channel, F.col(\"o.ChannelId\") == F.col(\"dch.ChannelId\"), \"left\")\n",
				"          .join(dim_constituent, F.col(\"o.ConstituentId\") == F.col(\"dcon.ConstituentId\"), \"left\")\n",
				"          .join(dim_stage, F.col(\"o.OpportunityStageId\") == F.col(\"dos.OpportunityStageId\"), \"left\")\n",
				"          .join(dim_type, F.col(\"o.OpportunityTypeId\") == F.col(\"dot.OpportunityTypeId\"), \"left\")\n",
				"          .join(dim_source, F.col(\"o.SourceId\") == F.col(\"ds.SourceId\"), \"left\")\n",
				"          .join(dim_date.alias(\"created\"), F.to_date(F.col(\"o.CreatedDate\")) == F.col(\"created.DimDate\"), \"left\")\n",
				"          .join(dim_date.alias(\"modified\"), F.to_date(F.col(\"o.ModifiedDate\")) == F.col(\"modified.DimDate\"), \"left\")\n",
				"          .join(dim_date.alias(\"close\"), F.to_date(F.col(\"o.CloseDate\")) == F.col(\"close.DimDate\"), \"left\")\n",
				"          .withColumn(\n",
				"              \"OpportunityKey\",\n",
				"              xxhash64(\n",
				"                  F.col(\"o.OpportunityId\"),\n",
				"                  F.col(\"o.SourceSystemId\")\n",
				"              ).cast(\"bigint\")\n",
				"          )\n",
				"          .withColumn(\n",
				"              \"IsClosed\",\n",
				"              F.when(F.col(\"dos.OpportunityStage\").isin(\"Closed Won\", \"Closed Lost\"), F.lit(True))\n",
				"               .otherwise(F.lit(False))\n",
				"          )\n",
				"          .select(\n",
				"              F.col(\"OpportunityKey\"),\n",
				"              F.col(\"o.OpportunityId\"),\n",
				"              F.col(\"o.SourceSystemId\").alias(\"SourceSysOpportunityId\"),\n",
				"              F.col(\"o.ExpectedRevenue\").cast(\"decimal(18,2)\"),\n",
				"              F.col(\"o.Timezone\"),\n",
				"              F.col(\"IsClosed\"),\n",
				"              F.col(\"dc.CampaignKey\"),\n",
				"              F.col(\"dch.ChannelKey\"),\n",
				"              F.col(\"dcon.ConstituentKey\"),\n",
				"              F.col(\"ds.SourceKey\"),\n",
				"              F.col(\"dos.OpportunityStageKey\"),\n",
				"              F.col(\"dot.OpportunityTypeKey\"),\n",
				"              F.col(\"created.DateKey\").alias(\"CreatedDateKey\"),\n",
				"              F.col(\"modified.DateKey\").alias(\"ModifiedDateKey\"),\n",
				"              F.col(\"close.DateKey\").alias(\"CloseDateKey\"),\n",
				"              F.col(\"o.OpportunityName\").alias(\"OpportunityName\")\n",
				"          )\n",
				"    )\n",
				"\n",
				"    logging.info(f\"‚úÖ FactOpportunity processing {new_df.count()} rows.\")\n",
				"\n",
				"    return new_df\n",
				"\n",
				"factOpportunityTable = CdfTable(\n",
				"    source_table_name=\"Opportunity\",\n",
				"    target_table_name= \"FactOpportunity\",\n",
				"    source_primary_key=\"OpportunityId\",\n",
				"    columns=[\n",
				"        \"OpportunityId\", \"CampaignId\", \"ChannelId\", \"CloseDate\", \"ConstituentId\",\n",
				"        \"CreatedDate\", \"ExpectedRevenue\", \"ModifiedDate\", \"OpportunityStageId\",\n",
				"        \"SourceId\", \"SourceSystemId\", \"Timezone\", \"OpportunityTypeId\", \"OpportunityName\"\n",
				"    ],\n",
				"    merge_sql_template=f\"\"\"\n",
				"    MERGE INTO {gold_lakehouse_name}.FactOpportunity AS target\n",
				"    USING latestSnapshot_Opportunity AS source\n",
				"    ON target.OpportunityId = source.OpportunityId\n",
				"    WHEN MATCHED THEN UPDATE SET\n",
				"        CampaignKey = source.CampaignKey,\n",
				"        ChannelKey = source.ChannelKey,\n",
				"        CloseDateKey = source.CloseDateKey,\n",
				"        ConstituentKey = source.ConstituentKey,\n",
				"        CreatedDateKey = source.CreatedDateKey,\n",
				"        ExpectedRevenue = source.ExpectedRevenue,\n",
				"        IsClosed = source.IsClosed,\n",
				"        ModifiedDateKey = source.ModifiedDateKey,\n",
				"        OpportunityName = source.OpportunityName,\n",
				"        OpportunityStageKey = source.OpportunityStageKey,\n",
				"        OpportunityTypeKey = source.OpportunityTypeKey,\n",
				"        SourceKey = source.SourceKey,\n",
				"        SourceSysOpportunityId = source.SourceSysOpportunityId,\n",
				"        Timezone = source.Timezone\n",
				"    WHEN NOT MATCHED THEN INSERT (\n",
				"        OpportunityKey, OpportunityId, CampaignKey, ChannelKey, CloseDateKey,\n",
				"        ConstituentKey, CreatedDateKey, ExpectedRevenue, IsClosed,\n",
				"        ModifiedDateKey, OpportunityName, OpportunityStageKey, OpportunityTypeKey,\n",
				"        SourceKey, SourceSysOpportunityId, Timezone\n",
				"    ) VALUES (\n",
				"        source.OpportunityKey, source.OpportunityId, source.CampaignKey, source.ChannelKey,\n",
				"        source.CloseDateKey, source.ConstituentKey, source.CreatedDateKey,\n",
				"        source.ExpectedRevenue, source.IsClosed, source.ModifiedDateKey, source.OpportunityName,\n",
				"        source.OpportunityStageKey, source.OpportunityTypeKey, source.SourceKey,\n",
				"        source.SourceSysOpportunityId, source.Timezone\n",
				"    )\n",
				"    \"\"\",\n",
				"    source_lakehouse=silver_lakehouse_name,\n",
				"    target_lakehouse=gold_lakehouse_name,\n",
				"    enrich_func=EnrichFactOpportunity,\n",
				"    hard_delete=True\n",
				")\n",
				"\n",
				"ProcessCdfTable(factOpportunityTable)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "bcdbfadf-8905-4ae0-a7b8-8bfcfe743a97",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"source": [
				"### Build: FactEventAttendance"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "949ad6d9-cf8c-4aa3-8abc-e34c7633b372",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"outputs": [],
			"source": [
				"from pyspark.sql.functions import col, expr, xxhash64\n",
				"\n",
				"def EnrichFactEventAttendance(df: DataFrame) -> DataFrame:\n",
				"    # Dimension lookups\n",
				"    dimConstituentDf = get_gold_table(\"DimConstituent\").select(\"ConstituentId\", \"ConstituentKey\")\n",
				"    dimEventDf = get_gold_table(\"DimEvent\").select(\"EventId\", \"EventKey\", \"ChannelKey\")\n",
				"    dimSourceDf = get_gold_table(\"DimSource\").select(\"SourceId\", \"SourceKey\")\n",
				"    dimDateDf = get_gold_table(\"DimDate\").select(\"Date\", \"DateKey\")\n",
				"\n",
				"    # DateKey lookups\n",
				"    dimDateAccepted = dimDateDf.select(col(\"Date\").alias(\"AcceptedDate_lookup\"), col(\"DateKey\").alias(\"AcceptedDateKey\"))\n",
				"    dimDateCreated = dimDateDf.select(col(\"Date\").alias(\"CreatedDate_lookup\"), col(\"DateKey\").alias(\"CreatedDateKey\"))\n",
				"    dimDateModified = dimDateDf.select(col(\"Date\").alias(\"ModifiedDate_lookup\"), col(\"DateKey\").alias(\"ModifiedDateKey\"))\n",
				"    dimDateInvitation = dimDateDf.select(col(\"Date\").alias(\"InvitationDate_lookup\"), col(\"DateKey\").alias(\"InvitationDateKey\"))\n",
				"\n",
				"    # Enrich\n",
				"    new_df = (\n",
				"        df\n",
				"        .join(dimConstituentDf, on=\"ConstituentId\", how=\"left\")\n",
				"        .join(dimEventDf, on=\"EventId\", how=\"left\")  # brings both EventKey and ChannelKey\n",
				"        .join(dimSourceDf, on=\"SourceId\", how=\"left\")\n",
				"        .join(dimDateAccepted, expr(\"cast(AcceptedDate as date) = AcceptedDate_lookup\"), \"left\")\n",
				"        .join(dimDateCreated, expr(\"cast(CreatedDate as date) = CreatedDate_lookup\"), \"left\")\n",
				"        .join(dimDateModified, expr(\"cast(ModifiedDate as date) = ModifiedDate_lookup\"), \"left\")\n",
				"        .join(dimDateInvitation, expr(\"cast(InvitationDate as date) = InvitationDate_lookup\"), \"left\")\n",
				"        .withColumn(\n",
				"            \"EventAttendanceKey\",\n",
				"            xxhash64(\n",
				"                col(\"ParticipationId\"),\n",
				"                col(\"SourceSystemId\")\n",
				"            ).cast(\"bigint\")\n",
				"        )\n",
				"        .select(\n",
				"            \"EventAttendanceKey\",\n",
				"            col(\"ParticipationId\").alias(\"EventAttendanceId\"),\n",
				"            col(\"SourceSystemId\").alias(\"SourceSysEventAttendanceId\"),\n",
				"            \"AttendedEvent\",\n",
				"            \"ConstituentKey\",\n",
				"            \"EventKey\",\n",
				"            \"ChannelKey\",  # from DimEvent\n",
				"            \"SourceKey\",\n",
				"            \"AcceptedDateKey\",\n",
				"            \"CreatedDateKey\",\n",
				"            \"ModifiedDateKey\",\n",
				"            \"InvitationDateKey\"\n",
				"        )\n",
				"    )\n",
				"\n",
				"    logging.info(f\"‚úÖ FactEventAttendance processing {new_df.count()} rows.\")\n",
				"    return new_df\n",
				"\n",
				"\n",
				"\n",
				"eventAttendanceTable = CdfTable(    \n",
				"    source_table_name=\"Participation\",\n",
				"    source_primary_key=\"ParticipationId\",\n",
				"    target_table_name=\"FactEventAttendance\",\n",
				"    columns=[\n",
				"        \"ParticipationId\", \"SourceSystemId\", \"AttendedEvent\", \"ConstituentId\", \"EventId\", \"SourceId\",\n",
				"        \"AcceptedDate\", \"CreatedDate\", \"ModifiedDate\", \"InvitationDate\"\n",
				"    ],\n",
				"    merge_sql_template=f\"\"\"\n",
				"    MERGE INTO {gold_lakehouse_name}.FactEventAttendance AS target\n",
				"    USING latestSnapshot_Participation AS source\n",
				"    ON target.EventAttendanceId = source.EventAttendanceId\n",
				"    WHEN MATCHED THEN UPDATE SET\n",
				"        SourceSysEventAttendanceId = source.SourceSysEventAttendanceId,\n",
				"        AttendedEvent = source.AttendedEvent,\n",
				"        ConstituentKey = source.ConstituentKey,\n",
				"        EventKey = source.EventKey,\n",
				"        ChannelKey = source.ChannelKey,\n",
				"        SourceKey = source.SourceKey,\n",
				"        AcceptedDateKey = source.AcceptedDateKey,\n",
				"        CreatedDateKey = source.CreatedDateKey,\n",
				"        ModifiedDateKey = source.ModifiedDateKey,\n",
				"        InvitationDateKey = source.InvitationDateKey\n",
				"    WHEN NOT MATCHED THEN INSERT (\n",
				"        EventAttendanceKey, EventAttendanceId, SourceSysEventAttendanceId, AttendedEvent,\n",
				"        ConstituentKey, EventKey, ChannelKey, SourceKey,\n",
				"        AcceptedDateKey, CreatedDateKey, ModifiedDateKey, InvitationDateKey\n",
				"    ) VALUES (\n",
				"        source.EventAttendanceKey, source.EventAttendanceId, source.SourceSysEventAttendanceId, source.AttendedEvent,\n",
				"        source.ConstituentKey, source.EventKey, source.ChannelKey, source.SourceKey,\n",
				"        source.AcceptedDateKey, source.CreatedDateKey, source.ModifiedDateKey, source.InvitationDateKey\n",
				"    )\n",
				"    \"\"\",\n",
				"    source_lakehouse=silver_lakehouse_name,\n",
				"    target_lakehouse=gold_lakehouse_name,\n",
				"    enrich_func=EnrichFactEventAttendance,\n",
				"    hard_delete=True,\n",
				"    delete_on=\"t.EventAttendanceId = k.ParticipationId\"\n",
				")\n",
				"\n",
				"ProcessCdfTable(eventAttendanceTable)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "da39e176-8747-4d0a-b20b-cb3aa1876b30",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"source": [
				"## Donation"
			]
		},
		{
			"cell_type": "markdown",
			"id": "a8e31fc9-d7d8-40e6-9915-28343fab1c53",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"source": [
				"### Build: DimDonationSource"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "a6c2a4a2-3878-416f-90e2-9bbc54da7c1c",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"outputs": [],
			"source": [
				"from pyspark.sql.functions import col, expr, xxhash64\n",
				"from functools import reduce\n",
				"\n",
				"def EnrichDimDonationSource(df: DataFrame) -> DataFrame:\n",
				"    # Load common dimension tables\n",
				"    dimSourceDf = get_gold_table(\"DimSource\").select(\"SourceId\", \"SourceKey\")\n",
				"    dimDateDf = get_gold_table(\"DimDate\").select(\"Date\", \"DateKey\")\n",
				"\n",
				"    dimDateCreated = dimDateDf.select(\n",
				"        col(\"Date\").alias(\"CreatedDate_lookup\"),\n",
				"        col(\"DateKey\").alias(\"CreatedDateKey\")\n",
				"    )\n",
				"    dimDateModified = dimDateDf.select(\n",
				"        col(\"Date\").alias(\"ModifiedDate_lookup\"),\n",
				"        col(\"DateKey\").alias(\"ModifiedDateKey\")\n",
				"    )\n",
				"\n",
				"    # Define mapping: TypeName ‚Üí (gold table, id column, surrogate key column)\n",
				"    type_to_gold = {\n",
				"        \"EmailEngagement\": (\"DimEmail\", \"EmailId\", \"EmailKey\"),\n",
				"        \"SocialEngagement\": (\"FactConstituentSocialEngagement\", \"ConstituentSocialEngagementId\", \"ConstituentSocialEngagementKey\"),\n",
				"        \"Event\": (\"DimEvent\", \"EventId\", \"EventKey\"),\n",
				"        \"Letter\": (\"DimLetter\", \"LetterId\", \"LetterKey\"),\n",
				"        \"PhoneCall\": (\"DimPhonecall\", \"PhonecallId\", \"PhonecallKey\"),\n",
				"    }\n",
				"\n",
				"    enriched_subsets = []\n",
				"\n",
				"    for type_name, (gold_table, id_col, key_col) in type_to_gold.items():\n",
				"        gold_df = get_gold_table(gold_table).select(\n",
				"            col(id_col).alias(\"RecordId\"),\n",
				"            col(key_col).alias(\"ResolvedKey\")\n",
				"        )\n",
				"\n",
				"        subset = (\n",
				"            df.filter(col(\"TypeName\") == type_name)\n",
				"            .join(gold_df, on=\"RecordId\", how=\"left\")\n",
				"            .join(dimSourceDf, on=\"SourceId\", how=\"left\")\n",
				"            .join(dimDateCreated, expr(\"cast(CreatedDate as date) = CreatedDate_lookup\"), \"left\")\n",
				"            .join(dimDateModified, expr(\"cast(ModifiedDate as date) = ModifiedDate_lookup\"), \"left\")\n",
				"            .withColumn(\n",
				"                \"DonationSourceKey\",\n",
				"                xxhash64(\n",
				"                    col(\"TransactionSourceId\"),\n",
				"                    col(\"RecordId\"),\n",
				"                    col(\"TypeName\")\n",
				"                ).cast(\"bigint\")\n",
				"            )\n",
				"            .select(\n",
				"                \"DonationSourceKey\",\n",
				"                col(\"TransactionSourceId\").alias(\"DonationSourceId\"),\n",
				"                col(\"TypeName\").alias(\"DonationSourceTypeName\"),\n",
				"                col(\"ResolvedKey\").alias(\"DonationSourceRecordKey\"),\n",
				"                \"ResolvedKey\",\n",
				"                \"SourceKey\",\n",
				"                \"CreatedDateKey\",\n",
				"                \"ModifiedDateKey\"\n",
				"            )\n",
				"        )\n",
				"\n",
				"        enriched_subsets.append(subset)\n",
				"\n",
				"    if enriched_subsets:\n",
				"        df_final = reduce(lambda a, b: a.unionByName(b), enriched_subsets)\n",
				"    else:\n",
				"        df_final = spark.createDataFrame([], StructType([]))  # fallback\n",
				"\n",
				"    logging.info(f\"‚úÖ DimDonationSource processing {df_final.count()} rows.\")\n",
				"    return df_final\n",
				"\n",
				"donationSourceTable = CdfTable(\n",
				"    source_table_name=\"TransactionSource\",\n",
				"    source_primary_key=\"TransactionSourceId\",\n",
				"    target_table_name=\"DimDonationSource\",\n",
				"    columns=[\"TransactionSourceId\", \"RecordId\", \"TypeName\", \"SourceSystemId\", \"SourceId\", \"CreatedDate\", \"ModifiedDate\"],\n",
				"    merge_sql_template=f\"\"\"\n",
				"    MERGE INTO {gold_lakehouse_name}.DimDonationSource AS target\n",
				"    USING latestSnapshot_TransactionSource AS source\n",
				"    ON target.DonationSourceId = source.DonationSourceId\n",
				"    WHEN MATCHED THEN UPDATE SET\n",
				"        DonationSourceTypeName = source.DonationSourceTypeName,\n",
				"        DonationSourceRecordKey = source.DonationSourceRecordKey,\n",
				"        SourceKey = source.SourceKey,\n",
				"        CreatedDateKey = source.CreatedDateKey,\n",
				"        ModifiedDateKey = source.ModifiedDateKey\n",
				"    WHEN NOT MATCHED THEN INSERT (\n",
				"        DonationSourceKey, DonationSourceId, DonationSourceTypeName, SourceKey, CreatedDateKey, ModifiedDateKey\n",
				"    ) VALUES (\n",
				"        source.DonationSourceKey, source.DonationSourceId, source.DonationSourceTypeName, source.SourceKey, source.CreatedDateKey, source.ModifiedDateKey\n",
				"    )\n",
				"    \"\"\",\n",
				"    source_lakehouse=silver_lakehouse_name,\n",
				"    target_lakehouse=gold_lakehouse_name,\n",
				"    enrich_func=EnrichDimDonationSource\n",
				")\n",
				"\n",
				"ProcessCdfTable(donationSourceTable)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "1e78f7e4-89ff-490c-93e7-2c6b6f8f9593",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"source": [
				"### Build: FactDonation"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "b49d8201-a33e-40cb-9756-cbf1602bdcda",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"outputs": [],
			"source": [
				"from pyspark.sql import DataFrame\n",
				"from pyspark.sql.functions import (\n",
				"    col, to_date, xxhash64, date_sub, current_date, max as max_, min as min_\n",
				")\n",
				"\n",
				"def EnrichFactDonation(df: DataFrame) -> DataFrame:\n",
				"    df = df.alias(\"t\")\n",
				"\n",
				"    dim_date = get_gold_table(\"DimDate\").select(col(\"Date\").alias(\"DimDate\"), col(\"DateKey\"))\n",
				"    dim_campaign = get_gold_table(\"DimCampaign\").select(\"CampaignId\", \"CampaignKey\").alias(\"dc\")\n",
				"    dim_channel = get_gold_table(\"DimChannel\").select(\"ChannelId\", \"ChannelKey\").alias(\"dch\")\n",
				"    dim_const = get_gold_table(\"DimConstituent\").select(\"ConstituentId\", \"ConstituentKey\").alias(\"dcon\")\n",
				"    dim_source = get_gold_table(\"DimSource\").select(\"SourceId\", \"SourceKey\").alias(\"ds\")\n",
				"    dim_don_source = get_gold_table(\"DimDonationSource\").select(\"DonationSourceId\", \"DonationSourceKey\").alias(\"dds\")\n",
				"    fact_opp = get_gold_table(\"FactOpportunity\").select(\"OpportunityId\", \"OpportunityKey\").alias(\"fo\")\n",
				"\n",
				"    one_year_ago = date_sub(current_date(), 365)\n",
				"\n",
				"    donation_flags = (\n",
				"        df.withColumn(\"TxDate\", to_date(\"TransactionDate\"))\n",
				"          .groupBy(\"ConstituentId\")\n",
				"          .agg(\n",
				"              (max_(col(\"TxDate\")) > one_year_ago).alias(\"HasRecent\"),\n",
				"              (min_(col(\"TxDate\")) <= one_year_ago).alias(\"HasOld\")\n",
				"          )\n",
				"          .withColumn(\"IsNewConstituent\", (col(\"HasRecent\") & (~col(\"HasOld\"))).cast(\"boolean\"))\n",
				"          .select(\"ConstituentId\", \"IsNewConstituent\")\n",
				"    )\n",
				"\n",
				"    new_df = (\n",
				"        df.join(donation_flags, \"ConstituentId\", \"left\")\n",
				"          .join(dim_campaign, col(\"t.CampaignId\") == col(\"dc.CampaignId\"), \"left\")\n",
				"          .join(dim_channel, col(\"t.ChannelId\") == col(\"dch.ChannelId\"), \"left\")\n",
				"          .join(dim_const.hint(\"merge\"), col(\"t.ConstituentId\") == col(\"dcon.ConstituentId\"), \"left\")\n",
				"          .join(dim_source, col(\"t.SourceId\") == col(\"ds.SourceId\"), \"left\")\n",
				"          .join(dim_don_source, col(\"t.TransactionSourceId\").cast(\"string\") == col(\"dds.DonationSourceId\").cast(\"string\"), \"left\")\n",
				"          .join(fact_opp, col(\"t.OpportunityId\") == col(\"fo.OpportunityId\"), \"left\")\n",
				"          .join(dim_date.alias(\"created\"), to_date(col(\"t.CreatedDate\")) == col(\"created.DimDate\"), \"left\")\n",
				"          .join(dim_date.alias(\"modified\"), to_date(col(\"t.ModifiedDate\")) == col(\"modified.DimDate\"), \"left\")\n",
				"          .join(dim_date.alias(\"don\"), to_date(col(\"t.TransactionDate\")) == col(\"don.DimDate\"), \"left\")\n",
				"          .withColumn(\n",
				"              \"DonationKey\",\n",
				"              xxhash64(\n",
				"                  col(\"t.TransactionId\"),\n",
				"                  col(\"t.TransactionSourceId\")\n",
				"              ).cast(\"bigint\")\n",
				"          )\n",
				"          .select(\n",
				"              col(\"DonationKey\"),\n",
				"              col(\"t.TransactionId\").alias(\"DonationId\"),\n",
				"              col(\"t.SourceSystemId\").alias(\"SourceSysDonationId\"),\n",
				"              col(\"t.Name\").alias(\"DonationName\"),\n",
				"              col(\"t.Amount\"),\n",
				"              col(\"t.IsRecurring\").alias(\"IsReccuring\"),\n",
				"              col(\"IsNewConstituent\"),\n",
				"              col(\"t.Timezone\"),\n",
				"              col(\"dc.CampaignKey\"),\n",
				"              col(\"dch.ChannelKey\"),\n",
				"              col(\"dcon.ConstituentKey\"),\n",
				"              col(\"created.DateKey\").alias(\"CreatedDateKey\"),\n",
				"              col(\"don.DateKey\").alias(\"DonationDateKey\"),\n",
				"              col(\"modified.DateKey\").alias(\"ModifiedDateKey\"),\n",
				"              col(\"fo.OpportunityKey\"),\n",
				"              col(\"ds.SourceKey\"),\n",
				"              col(\"dds.DonationSourceKey\").alias(\"DonationSourceKey\")\n",
				"          )\n",
				"    )\n",
				"\n",
				"    logging.info(f\"‚úÖ FactDonation processing {new_df.count()} rows.\")\n",
				"    return new_df\n",
				"\n",
				"factDonationTable = CdfTable(\n",
				"    source_table_name=\"Transaction\",\n",
				"    target_table_name=\"FactDonation\",\n",
				"    source_primary_key=\"TransactionId\",\n",
				"    columns=[\n",
				"        \"TransactionId\", \"CampaignId\", \"ChannelId\", \"ConstituentId\",\n",
				"        \"CreatedDate\", \"TransactionDate\", \"IsRecurring\", \"ModifiedDate\",\n",
				"        \"Name\", \"OpportunityId\", \"SourceId\", \"SourceSystemId\", \"Timezone\",\n",
				"        \"Amount\", \"TransactionSourceId\"\n",
				"    ],\n",
				"    merge_sql_template=f\"\"\"\n",
				"    MERGE INTO {gold_lakehouse_name}.FactDonation AS target\n",
				"    USING latestSnapshot_Transaction AS source\n",
				"    ON target.DonationId = source.DonationId\n",
				"    WHEN MATCHED THEN UPDATE SET\n",
				"        Amount = source.Amount,\n",
				"        CampaignKey = source.CampaignKey,\n",
				"        ChannelKey = source.ChannelKey,\n",
				"        ConstituentKey = source.ConstituentKey,\n",
				"        CreatedDateKey = source.CreatedDateKey,\n",
				"        DonationDateKey = source.DonationDateKey,\n",
				"        ModifiedDateKey = source.ModifiedDateKey,\n",
				"        OpportunityKey = source.OpportunityKey,\n",
				"        DonationSourceKey = source.DonationSourceKey,\n",
				"        SourceKey = source.SourceKey,\n",
				"        SourceSysDonationId = source.SourceSysDonationId,\n",
				"        DonationName = source.DonationName,\n",
				"        IsReccuring = source.IsReccuring,\n",
				"        IsNewConstituent = source.IsNewConstituent,\n",
				"        Timezone = source.Timezone\n",
				"    WHEN NOT MATCHED THEN INSERT (\n",
				"        DonationKey, DonationId, Amount, CampaignKey, ChannelKey, ConstituentKey,\n",
				"        CreatedDateKey, DonationDateKey, ModifiedDateKey, OpportunityKey,\n",
				"        DonationSourceKey, SourceKey, SourceSysDonationId, DonationName,\n",
				"        IsReccuring, IsNewConstituent, Timezone\n",
				"    ) VALUES (\n",
				"        source.DonationKey, source.DonationId, source.Amount, source.CampaignKey,\n",
				"        source.ChannelKey, source.ConstituentKey, source.CreatedDateKey,\n",
				"        source.DonationDateKey, source.ModifiedDateKey, source.OpportunityKey,\n",
				"        source.DonationSourceKey, source.SourceKey, source.SourceSysDonationId,\n",
				"        source.DonationName, source.IsReccuring, source.IsNewConstituent,\n",
				"        source.Timezone\n",
				"    );\n",
				"    \"\"\",\n",
				"    source_lakehouse=silver_lakehouse_name,\n",
				"    target_lakehouse=gold_lakehouse_name,\n",
				"    enrich_func=EnrichFactDonation,\n",
				"    hard_delete=True,\n",
				"    delete_on=\"t.DonationId = k.TransactionId\"\n",
				")\n",
				"\n",
				"ProcessCdfTable(factDonationTable)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "5d300c4a-cbd3-419e-8685-2b14b13e6152",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"source": [
				"### Build: DimVolunteeringType"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "7526c9a7-fc88-4772-824e-d882d51659c8",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"outputs": [],
			"source": [
				"from pyspark.sql.functions import col, expr, xxhash64\n",
				"\n",
				"def EnrichDimVolunteeringType(df: DataFrame) -> DataFrame:\n",
				"\n",
				"    # Lookup tables\n",
				"    dim_date = get_gold_table(\"DimDate\").select(\"Date\", \"DateKey\")\n",
				"    dim_source = get_gold_table(\"DimSource\").select(\"SourceId\", \"SourceKey\")\n",
				"\n",
				"    # Date key lookups\n",
				"    date_created = dim_date.select(\n",
				"        col(\"Date\").alias(\"CreatedDate_lookup\"),\n",
				"        col(\"DateKey\").alias(\"CreatedDateKey\")\n",
				"    )\n",
				"    date_modified = dim_date.select(\n",
				"        col(\"Date\").alias(\"ModifiedDate_lookup\"),\n",
				"        col(\"DateKey\").alias(\"ModifiedDateKey\")\n",
				"    )\n",
				"\n",
				"    # Enrichment logic\n",
				"    new_df = (\n",
				"        df\n",
				"        .join(dim_source, on=\"SourceId\", how=\"left\")\n",
				"        .join(date_created, expr(\"cast(CreatedDate as date) = CreatedDate_lookup\"), \"left\")\n",
				"        .join(date_modified, expr(\"cast(ModifiedDate as date) = ModifiedDate_lookup\"), \"left\")\n",
				"        .withColumn(\n",
				"            \"VolunteeringTypeKey\",\n",
				"            xxhash64(\n",
				"                col(\"ParticipationTypeId\"),\n",
				"                col(\"SourceId\"),\n",
				"                col(\"Name\")\n",
				"            ).cast(\"bigint\")\n",
				"        )\n",
				"        .select(\n",
				"            \"VolunteeringTypeKey\",\n",
				"            col(\"ParticipationTypeId\").alias(\"VolunteeringTypeId\"),\n",
				"            col(\"Name\").alias(\"VolunteeringTypeName\"),\n",
				"            \"CreatedDateKey\",\n",
				"            \"ModifiedDateKey\",\n",
				"            \"ModifiedDate\",\n",
				"            \"SourceKey\"\n",
				"        )\n",
				"    )\n",
				"\n",
				"    logging.info(f\"‚úÖ DimVolunteeringType processing {new_df.count()} rows.\")\n",
				"\n",
				"    return new_df\n",
				"\n",
				"volunteeringTypeTable = CdfTable(\n",
				"    source_table_name=\"ParticipationType\",\n",
				"    source_primary_key=\"ParticipationTypeId\",\n",
				"    target_table_name=\"DimVolunteeringType\",\n",
				"    columns=[\n",
				"        \"ParticipationTypeId\",\n",
				"        \"Name\",\n",
				"        \"CreatedDate\",\n",
				"        \"ModifiedDate\",\n",
				"        \"SourceId\"\n",
				"    ],\n",
				"    merge_sql_template=f\"\"\"\n",
				"    MERGE INTO {gold_lakehouse_name}.DimVolunteeringType AS target\n",
				"    USING latestSnapshot_ParticipationType AS source\n",
				"    ON target.VolunteeringTypeId = source.VolunteeringTypeId\n",
				"    WHEN MATCHED THEN UPDATE SET\n",
				"        VolunteeringTypeName = source.VolunteeringTypeName,\n",
				"        CreatedDateKey       = source.CreatedDateKey,\n",
				"        ModifiedDateKey      = source.ModifiedDateKey,\n",
				"        SourceKey            = source.SourceKey\n",
				"    WHEN NOT MATCHED THEN INSERT (\n",
				"        VolunteeringTypeKey,\n",
				"        VolunteeringTypeId,\n",
				"        VolunteeringTypeName,\n",
				"        CreatedDateKey,\n",
				"        ModifiedDateKey,\n",
				"        SourceKey\n",
				"    ) VALUES (\n",
				"        source.VolunteeringTypeKey,\n",
				"        source.VolunteeringTypeId,\n",
				"        source.VolunteeringTypeName,\n",
				"        source.CreatedDateKey,\n",
				"        source.ModifiedDateKey,\n",
				"        source.SourceKey\n",
				"    )\n",
				"    \"\"\",\n",
				"    source_lakehouse=silver_lakehouse_name,\n",
				"    target_lakehouse=gold_lakehouse_name,\n",
				"    enrich_func=EnrichDimVolunteeringType\n",
				")\n",
				"\n",
				"ProcessCdfTable(volunteeringTypeTable)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "695a7352-ef2f-48b5-868b-4c6a3f159597",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"source": [
				"### Build: FactVolunteerHours"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "7632dfdc-bae0-44c1-be7c-d7dd49d8332a",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"outputs": [],
			"source": [
				"from pyspark.sql.functions import col, expr, xxhash64\n",
				"from pyspark.sql import DataFrame\n",
				"\n",
				"def EnrichFactVolunteerHours(df: DataFrame) -> DataFrame:\n",
				"    dim_constituent = get_gold_table(\"DimConstituent\").select(\"ConstituentId\", \"ConstituentKey\")\n",
				"    dim_event = get_gold_table(\"DimEvent\").select(\"EventId\", \"EventKey\")\n",
				"    dim_vol_type = get_gold_table(\"DimVolunteeringType\").select(\"VolunteeringTypeId\", \"VolunteeringTypeKey\")\n",
				"    dim_source = get_gold_table(\"DimSource\").select(\"SourceId\", \"SourceKey\")\n",
				"    dim_date = get_gold_table(\"DimDate\").select(\"Date\", \"DateKey\")\n",
				"\n",
				"    volunteered_date_lkp = dim_date.select(col(\"Date\").alias(\"VolunteeredDate_lookup\"), col(\"DateKey\").alias(\"VolunteeredDateKey\"))\n",
				"    created_date_lkp = dim_date.select(col(\"Date\").alias(\"CreatedDate_lookup\"), col(\"DateKey\").alias(\"CreatedDateKey\"))\n",
				"    modified_date_lkp = dim_date.select(col(\"Date\").alias(\"ModifiedDate_lookup\"), col(\"DateKey\").alias(\"ModifiedDateKey\"))\n",
				"\n",
				"    new_df = (\n",
				"        df\n",
				"        .join(dim_constituent.hint(\"merge\"), \"ConstituentId\", \"left\")\n",
				"        .join(dim_event, \"EventId\", \"left\")\n",
				"        .join(dim_vol_type, df[\"ParticipationTypeId\"] == dim_vol_type[\"VolunteeringTypeId\"], \"left\")\n",
				"        .join(dim_source, \"SourceId\", \"left\")\n",
				"        .join(volunteered_date_lkp, expr(\"cast(StartDate as date) = VolunteeredDate_lookup\"), \"left\")\n",
				"        .join(created_date_lkp, expr(\"cast(CreatedDate as date) = CreatedDate_lookup\"), \"left\")\n",
				"        .join(modified_date_lkp, expr(\"cast(ModifiedDate as date) = ModifiedDate_lookup\"), \"left\")\n",
				"        .withColumn(\n",
				"            \"VolunteerHoursKey\",\n",
				"            xxhash64(\n",
				"                col(\"ParticipationId\"),\n",
				"                col(\"SourceSystemId\")\n",
				"            ).cast(\"bigint\")\n",
				"        )\n",
				"        .select(\n",
				"            \"VolunteerHoursKey\",\n",
				"            col(\"ParticipationId\").alias(\"VolunteerHoursId\"),\n",
				"            col(\"SourceSystemId\").alias(\"SourceSysVolunteerHoursId\"),\n",
				"            col(\"Hours\").alias(\"HoursVolunteered\"),\n",
				"            col(\"ConstituentKey\").alias(\"VolunteerKey\"),\n",
				"            \"EventKey\",\n",
				"            \"VolunteeringTypeKey\",\n",
				"            \"VolunteeredDateKey\",\n",
				"            \"CreatedDateKey\",\n",
				"            \"ModifiedDateKey\",\n",
				"            \"SourceKey\",\n",
				"            \"Timezone\"\n",
				"        )\n",
				"    )\n",
				"\n",
				"    logging.info(f\"‚úÖ FactVolunteerHours processing {new_df.count()} rows.\")\n",
				"\n",
				"    return new_df\n",
				"\n",
				"volunteerHoursTable = CdfTable(\n",
				"    source_table_name = \"Participation\",\n",
				"    target_table_name = \"FactVolunteerHours\",\n",
				"    source_primary_key = \"ParticipationId\",\n",
				"    columns = [\n",
				"        \"ParticipationId\", \"SourceSystemId\", \"ConstituentId\", \"EventId\",\n",
				"        \"ParticipationTypeId\", \"Hours\", \"Timezone\",\n",
				"        \"StartDate\", \"CreatedDate\", \"ModifiedDate\", \"SourceId\"\n",
				"    ],\n",
				"    merge_sql_template = f\"\"\"\n",
				"    MERGE INTO {gold_lakehouse_name}.FactVolunteerHours AS target\n",
				"    USING latestSnapshot_Participation AS source\n",
				"    ON target.VolunteerHoursId = source.VolunteerHoursId\n",
				"    WHEN MATCHED THEN UPDATE SET\n",
				"        SourceSysVolunteerHoursId = source.SourceSysVolunteerHoursId,\n",
				"        HoursVolunteered = source.HoursVolunteered,\n",
				"        VolunteerKey = source.VolunteerKey,\n",
				"        EventKey = source.EventKey,\n",
				"        VolunteeringTypeKey = source.VolunteeringTypeKey,\n",
				"        VolunteeredDateKey = source.VolunteeredDateKey,\n",
				"        CreatedDateKey = source.CreatedDateKey,\n",
				"        ModifiedDateKey = source.ModifiedDateKey,\n",
				"        SourceKey = source.SourceKey,\n",
				"        Timezone = source.Timezone\n",
				"    WHEN NOT MATCHED THEN INSERT (\n",
				"        VolunteerHoursKey,\n",
				"        VolunteerHoursId,\n",
				"        SourceSysVolunteerHoursId,\n",
				"        HoursVolunteered,\n",
				"        VolunteerKey,\n",
				"        EventKey,\n",
				"        VolunteeringTypeKey,\n",
				"        VolunteeredDateKey,\n",
				"        CreatedDateKey,\n",
				"        ModifiedDateKey,\n",
				"        SourceKey,\n",
				"        Timezone\n",
				"    ) VALUES (\n",
				"        source.VolunteerHoursKey,\n",
				"        source.VolunteerHoursId,\n",
				"        source.SourceSysVolunteerHoursId,\n",
				"        source.HoursVolunteered,\n",
				"        source.VolunteerKey,\n",
				"        source.EventKey,\n",
				"        source.VolunteeringTypeKey,\n",
				"        source.VolunteeredDateKey,\n",
				"        source.CreatedDateKey,\n",
				"        source.ModifiedDateKey,\n",
				"        source.SourceKey,\n",
				"        source.Timezone\n",
				"    )\n",
				"    \"\"\",\n",
				"    source_lakehouse = silver_lakehouse_name,\n",
				"    target_lakehouse = gold_lakehouse_name,\n",
				"    enrich_func      = EnrichFactVolunteerHours,\n",
				"    hard_delete=True,\n",
				"    delete_on=\"t.VolunteerHoursId = k.ParticipationId\"\n",
				")\n",
				"\n",
				"ProcessCdfTable(volunteerHoursTable)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "f3f22d21-01d8-4b5a-a8cd-e163341684cf",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"source": [
				"### Build: DimConstituentProgramBridge"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "d2f09a6a-41f5-4dda-a419-7d4eecd47e7b",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"outputs": [],
			"source": [
				"from pyspark.sql.functions import col, xxhash64\n",
				"\n",
				"def EnrichDimConstituentProgramBridge(df: DataFrame) -> DataFrame:\n",
				"    dimConstituentDf = get_gold_table(\"DimConstituent\").select(\"ConstituentId\", \"ConstituentKey\")\n",
				"    dimProgramDf = get_gold_table(\"DimProgram\").select(\"ProgramId\", \"ProgramKey\")\n",
				"\n",
				"    new_df = (\n",
				"        df\n",
				"        .join(dimConstituentDf, on=\"ConstituentId\", how=\"left\")\n",
				"        .join(dimProgramDf, on=\"ProgramId\", how=\"left\")\n",
				"        .withColumn(\n",
				"            \"ConstituentProgramBridgeKey\",\n",
				"            xxhash64(\n",
				"                col(\"ConstituentId\"),\n",
				"                col(\"ProgramId\")\n",
				"            ).cast(\"bigint\")\n",
				"        )\n",
				"        .select(\n",
				"            \"ConstituentProgramBridgeKey\",\n",
				"            col(\"ConstituentProgramId\").alias(\"ConstituentProgramBridgeId\"),\n",
				"            \"ConstituentKey\",\n",
				"            \"ProgramKey\"\n",
				"        )\n",
				"    )\n",
				"\n",
				"    logging.info(f\"‚úÖ DimConstituentProgramBridge processing {new_df.count()} rows.\")\n",
				"    return new_df\n",
				"\n",
				"constituentProgramBridgeTable = CdfTable(\n",
				"    source_table_name=\"ConstituentProgram\",\n",
				"    target_table_name=\"DimConstituentProgramBridge\",\n",
				"    source_primary_key=\"ConstituentProgramId\",\n",
				"    columns=[\"ConstituentProgramId\", \"ConstituentId\", \"ProgramId\", \"SourceId\", \"CreatedDate\", \"ModifiedDate\"],\n",
				"    merge_sql_template=f\"\"\"\n",
				"    MERGE INTO {gold_lakehouse_name}.DimConstituentProgramBridge AS target\n",
				"    USING latestSnapshot_ConstituentProgram AS source\n",
				"    ON target.ConstituentProgramBridgeId = source.ConstituentProgramBridgeId\n",
				"    WHEN MATCHED THEN UPDATE SET\n",
				"        ConstituentKey = source.ConstituentKey,\n",
				"        ProgramKey = source.ProgramKey\n",
				"    WHEN NOT MATCHED THEN INSERT (\n",
				"        ConstituentProgramBridgeKey, ConstituentProgramBridgeId, ConstituentKey, ProgramKey\n",
				"    ) VALUES (\n",
				"        source.ConstituentProgramBridgeKey, source.ConstituentProgramBridgeId, source.ConstituentKey, source.ProgramKey\n",
				"    )\n",
				"    \"\"\",\n",
				"    source_lakehouse=silver_lakehouse_name,\n",
				"    target_lakehouse=gold_lakehouse_name,\n",
				"    enrich_func=EnrichDimConstituentProgramBridge,\n",
				"    hard_delete=True,\n",
				"    delete_on=\"t.ConstituentProgramBridgeId = k.ConstituentProgramId\"\n",
				")\n",
				"\n",
				"ProcessCdfTable(constituentProgramBridgeTable)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "93b67419-26da-4831-be3f-3e9e8a9fbc98",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"source": [
				"### Build: FactSoftCredit"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "0390bddd-ab73-4bd2-9115-b53a73e03d7c",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"outputs": [],
			"source": [
				"from pyspark.sql.functions import col, expr, xxhash64\n",
				"from pyspark.sql import DataFrame\n",
				"\n",
				"def EnrichFactSoftCredit(df: DataFrame) -> DataFrame:\n",
				"    dimConstituentDf = get_gold_table(\"DimConstituent\").select(\"ConstituentId\", \"ConstituentKey\")\n",
				"    dimSourceDf = get_gold_table(\"DimSource\").select(\"SourceId\", \"SourceKey\")\n",
				"    dimDateDf = get_gold_table(\"DimDate\").select(\"Date\", \"DateKey\")\n",
				"    factDonationDf = get_gold_table(\"FactDonation\").select(\"DonationId\", \"DonationKey\")\n",
				"\n",
				"    dimDateCreated = dimDateDf.select(\n",
				"        col(\"Date\").alias(\"CreatedDate_lookup\"),\n",
				"        col(\"DateKey\").alias(\"CreatedDateKey\")\n",
				"    )\n",
				"    dimDateModified = dimDateDf.select(\n",
				"        col(\"Date\").alias(\"ModifiedDate_lookup\"),\n",
				"        col(\"DateKey\").alias(\"ModifiedDateKey\")\n",
				"    )\n",
				"\n",
				"    new_df = (\n",
				"        df\n",
				"        .join(dimConstituentDf, on=\"ConstituentId\", how=\"left\")\n",
				"        .join(dimSourceDf, on=\"SourceId\", how=\"left\")\n",
				"        .join(factDonationDf, df[\"TransactionId\"] == factDonationDf[\"DonationId\"], how=\"left\")\n",
				"        .join(dimDateCreated, expr(\"cast(CreatedDate as date) = CreatedDate_lookup\"), \"left\")\n",
				"        .join(dimDateModified, expr(\"cast(ModifiedDate as date) = ModifiedDate_lookup\"), \"left\")\n",
				"        .withColumn(\n",
				"            \"SoftCreditKey\",\n",
				"            xxhash64(\n",
				"                col(\"SoftCreditId\"),\n",
				"                col(\"SourceSystemId\")\n",
				"            ).cast(\"bigint\")\n",
				"        )\n",
				"        .select(\n",
				"            \"SoftCreditKey\",\n",
				"            col(\"SoftCreditId\"),\n",
				"            col(\"SourceSystemId\").alias(\"SourceSysSoftCreditId\"),\n",
				"            col(\"Amount\").alias(\"SoftCreditAmount\"),\n",
				"            \"ConstituentKey\",\n",
				"            \"SourceKey\",\n",
				"            \"DonationKey\",\n",
				"            \"CreatedDateKey\",\n",
				"            \"ModifiedDateKey\"\n",
				"        )\n",
				"    )\n",
				"\n",
				"    logging.info(f\"‚úÖ FactSoftCredit processing {new_df.count()} rows.\")\n",
				"    return new_df\n",
				"\n",
				"\n",
				"softCreditTable = CdfTable(\n",
				"    source_table_name=\"SoftCredit\",\n",
				"    target_table_name=\"FactSoftCredit\",\n",
				"    source_primary_key=\"SoftCreditId\",\n",
				"    columns=[\n",
				"        \"SoftCreditId\", \"SourceSystemId\", \"Amount\",\n",
				"        \"ConstituentId\", \"SourceId\", \"TransactionId\",\n",
				"        \"CreatedDate\", \"ModifiedDate\"\n",
				"    ],\n",
				"    merge_sql_template=f\"\"\"\n",
				"    MERGE INTO {gold_lakehouse_name}.FactSoftCredit AS target\n",
				"    USING latestSnapshot_SoftCredit AS source\n",
				"    ON target.SoftCreditId = source.SoftCreditId\n",
				"    WHEN MATCHED THEN UPDATE SET\n",
				"        SourceSysSoftCreditId = source.SourceSysSoftCreditId,\n",
				"        SoftCreditAmount = source.SoftCreditAmount,\n",
				"        ConstituentKey = source.ConstituentKey,\n",
				"        SourceKey = source.SourceKey,\n",
				"        DonationKey = source.DonationKey,\n",
				"        CreatedDateKey = source.CreatedDateKey,\n",
				"        ModifiedDateKey = source.ModifiedDateKey\n",
				"    WHEN NOT MATCHED THEN INSERT (\n",
				"        SoftCreditKey, SoftCreditId, SourceSysSoftCreditId,\n",
				"        SoftCreditAmount, ConstituentKey, SourceKey,\n",
				"        DonationKey, CreatedDateKey, ModifiedDateKey\n",
				"    ) VALUES (\n",
				"        source.SoftCreditKey, source.SoftCreditId, source.SourceSysSoftCreditId,\n",
				"        source.SoftCreditAmount, source.ConstituentKey, source.SourceKey,\n",
				"        source.DonationKey, source.CreatedDateKey, source.ModifiedDateKey\n",
				"    )\n",
				"    \"\"\",\n",
				"    source_lakehouse=silver_lakehouse_name,\n",
				"    target_lakehouse=gold_lakehouse_name,\n",
				"    enrich_func=EnrichFactSoftCredit,\n",
				"    hard_delete=True\n",
				")\n",
				"\n",
				"ProcessCdfTable(softCreditTable)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "38dbf93b-9360-42d2-95cd-ffeb1f443086",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"source": [
				"## Wealth screeening"
			]
		},
		{
			"cell_type": "markdown",
			"id": "e91a9ee5-2807-4186-bfaa-c946751763fb",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"source": [
				"### Build: FactWealthScreening"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "4f5f42bc-273b-4f52-9676-12cf2cf8461d",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"outputs": [],
			"source": [
				"from pyspark.sql.functions import col, to_date, xxhash64\n",
				"\n",
				"def EnrichFactWealthScreening(df: DataFrame) -> DataFrame:\n",
				"    dimDateDf = get_gold_table(\"DimDate\").select(\"Date\", \"DateKey\")\n",
				"\n",
				"    dimDateCreated = dimDateDf.select(\n",
				"        col(\"Date\").alias(\"CreatedDate_lookup\"),\n",
				"        col(\"DateKey\").alias(\"CreatedDateKey\")\n",
				"    )\n",
				"\n",
				"    dimDateModified = dimDateDf.select(\n",
				"        col(\"Date\").alias(\"ModifiedDate_lookup\"),\n",
				"        col(\"DateKey\").alias(\"ModifiedDateKey\")\n",
				"    )\n",
				"\n",
				"    dimDateLastScreening = dimDateDf.select(\n",
				"        col(\"Date\").alias(\"LastScreeningDate_lookup\"),\n",
				"        col(\"DateKey\").alias(\"LastScreeningDateKey\")\n",
				"    )\n",
				"\n",
				"    dim_source = get_gold_table(\"DimSource\").select(\n",
				"        col(\"SourceId\"),\n",
				"        col(\"SourceKey\")\n",
				"    )\n",
				"\n",
				"    capacityrangeDf = get_table_from_lakehouse(silver_lakehouse_name, \"WealthScreeningCapacityRange\")\n",
				"    constituentratingDf = get_table_from_lakehouse(silver_lakehouse_name, \"WealthScreeningConstituentRating\")\n",
				"    dimConstituent = get_gold_table(\"DimConstituent\").select(\"ConstituentId\", \"ConstituentKey\")\n",
				"\n",
				"    wealthscreeningDf = df.alias(\"ws\")  # ‚úÖ alias on WealthScreening\n",
				"\n",
				"    new_df = (\n",
				"        wealthscreeningDf\n",
				"        .join(capacityrangeDf, wealthscreeningDf.CapacityRangeId == capacityrangeDf.WealthScreeningCapacityRangeId, how=\"left\")\n",
				"        .join(constituentratingDf, wealthscreeningDf.ConstituentRatingId == constituentratingDf.WealthScreeningConstituentRatingId, how=\"left\")\n",
				"        .join(dim_source, \"SourceId\", \"left\")\n",
				"        .join(dimConstituent, \"ConstituentId\", \"left\")\n",
				"        .join(dimDateCreated, to_date(wealthscreeningDf[\"CreatedDate\"]) == col(\"CreatedDate_lookup\"), \"left\")\n",
				"        .join(dimDateModified, to_date(wealthscreeningDf[\"ModifiedDate\"]) == col(\"ModifiedDate_lookup\"), \"left\")\n",
				"        .join(dimDateLastScreening, to_date(wealthscreeningDf[\"LastScreeningDate\"]) == col(\"LastScreeningDate_lookup\"), \"left\")\n",
				"        .withColumn(\n",
				"            \"WealthScreeningKey\",\n",
				"            xxhash64(\n",
				"                col(\"ws.WealthScreeningId\"),\n",
				"                col(\"ws.SourceId\")\n",
				"            ).cast(\"bigint\")\n",
				"        )\n",
				"        .select(\n",
				"            \"WealthScreeningKey\",\n",
				"            \"WealthScreeningId\",\n",
				"            \"ConstituentKey\",\n",
				"            \"LastScreeningDateKey\",\n",
				"            constituentratingDf.Name.alias(\"ConstituentRating\"),\n",
				"            capacityrangeDf.Name.alias(\"CapacityRange\"),\n",
				"            \"CreatedDateKey\",\n",
				"            \"ModifiedDateKey\",\n",
				"            \"SourceKey\"\n",
				"        )\n",
				"    )\n",
				"\n",
				"    logging.info(f\"‚úÖ FactWealthScreening processing {new_df.count()} rows.\")\n",
				"    return new_df\n",
				"\n",
				"\n",
				"factWealthScreeningTable = CdfTable(\n",
				"    source_table_name=\"WealthScreening\",\n",
				"    target_table_name=\"FactWealthScreening\",\n",
				"    source_primary_key=\"WealthScreeningId\",\n",
				"    columns=[\n",
				"        \"WealthScreeningId\", \"ConstituentId\", \"ConstituentRatingId\",\n",
				"        \"CapacityRangeId\", \"LastScreeningDate\",\n",
				"        \"CreatedDate\", \"ModifiedDate\", \"SourceId\"\n",
				"    ],\n",
				"    merge_sql_template=f\"\"\"\n",
				"    MERGE INTO {gold_lakehouse_name}.FactWealthScreening AS target\n",
				"    USING latestSnapshot_WealthScreening AS source\n",
				"    ON target.WealthScreeningId = source.WealthScreeningId\n",
				"    WHEN MATCHED THEN UPDATE SET\n",
				"        ConstituentKey = source.ConstituentKey,\n",
				"        ConstituentRating = source.ConstituentRating,\n",
				"        CapacityRange = source.CapacityRange,\n",
				"        LastScreeningDateKey = source.LastScreeningDateKey,\n",
				"        CreatedDateKey = source.CreatedDateKey,\n",
				"        ModifiedDateKey = source.ModifiedDateKey,\n",
				"        SourceKey = source.SourceKey\n",
				"    WHEN NOT MATCHED THEN INSERT (\n",
				"        WealthScreeningKey, WealthScreeningId, ConstituentKey, ConstituentRating,\n",
				"        CapacityRange, LastScreeningDateKey, CreatedDateKey, ModifiedDateKey, SourceKey\n",
				"    ) VALUES (\n",
				"        source.WealthScreeningKey, source.WealthScreeningId, source.ConstituentKey, source.ConstituentRating,\n",
				"        source.CapacityRange, source.LastScreeningDateKey, source.CreatedDateKey, source.ModifiedDateKey, source.SourceKey\n",
				"    )\n",
				"    \"\"\",\n",
				"    source_lakehouse=silver_lakehouse_name,\n",
				"    target_lakehouse=gold_lakehouse_name,\n",
				"    enrich_func=EnrichFactWealthScreening,\n",
				"    hard_delete=True\n",
				")\n",
				"\n",
				"ProcessCdfTable(factWealthScreeningTable)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "f915c751-f729-4eea-9853-dbc18f0740b1",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"source": [
				"## Activities engagement"
			]
		},
		{
			"cell_type": "markdown",
			"id": "5f2cf32f-05ad-4aa0-b80c-6a6dd6a12809",
			"metadata": {},
			"source": [
				"### Build: FactConstituentEmailEngagement"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "14f788b1-dd8d-40d0-945b-7596672dd884",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"outputs": [],
			"source": [
				"from pyspark.sql.functions import col, expr, xxhash64, to_date\n",
				"\n",
				"def EnrichFactConstituentEmailEngagement(df: DataFrame) -> DataFrame:\n",
				"    df = df.alias(\"cee\")\n",
				"\n",
				"    dim_constituent = get_gold_table(\"DimConstituent\").select(\"ConstituentId\", \"ConstituentKey\").alias(\"dcon\")\n",
				"    \n",
				"    # üÜï Pull ChannelKey from DimEmail\n",
				"    dim_email = get_gold_table(\"DimEmail\").select(\"EmailEngagementId\", \"EmailId\", \"EmailKey\", \"ChannelKey\")\n",
				"\n",
				"    dim_campaign = get_gold_table(\"DimCampaign\").select(\"CampaignId\", \"CampaignKey\").alias(\"dc\")\n",
				"    dim_source = get_gold_table(\"DimSource\").select(\"SourceId\", \"SourceKey\").alias(\"ds\")\n",
				"    dim_date = get_gold_table(\"DimDate\").select(\"Date\", \"DateKey\").alias(\"dd\")\n",
				"    email_engagement = get_silver_table(\"EmailEngagement\").select(\"EmailEngagementId\", \"CampaignId\").alias(\"ee\")\n",
				"\n",
				"    # Date joins\n",
				"    click_lkp = dim_date.select(col(\"Date\").alias(\"ClickThroughDate_lookup\"), col(\"DateKey\").alias(\"ClickThroughDateKey\"))\n",
				"    open_lkp  = dim_date.select(col(\"Date\").alias(\"OpenedDate_lookup\"), col(\"DateKey\").alias(\"OpenedDateKey\"))\n",
				"    sent_lkp  = dim_date.select(col(\"Date\").alias(\"SendDate_lookup\"), col(\"DateKey\").alias(\"SentDateKey\"))\n",
				"    creat_lkp = dim_date.select(col(\"Date\").alias(\"CreatedDate_lookup\"), col(\"DateKey\").alias(\"CreatedDateKey\"))\n",
				"    mod_lkp   = dim_date.select(col(\"Date\").alias(\"ModifiedDate_lookup\"), col(\"DateKey\").alias(\"ModifiedDateKey\"))\n",
				"\n",
				"    new_df = (\n",
				"        df\n",
				"        .join(dim_constituent.hint(\"merge\"), \"ConstituentId\", \"left\")\n",
				"        .join(dim_email, \"EmailEngagementId\", \"left\")                         \n",
				"        .join(email_engagement, \"EmailEngagementId\", \"left\")\n",
				"        .join(dim_campaign, \"CampaignId\", \"left\")\n",
				"        .join(dim_source, \"SourceId\", \"left\")\n",
				"        .join(click_lkp, expr(\"cast(ClickThroughDate as date) = ClickThroughDate_lookup\"), \"left\")\n",
				"        .join(open_lkp, expr(\"cast(OpenedDate as date) = OpenedDate_lookup\"), \"left\")\n",
				"        .join(sent_lkp, expr(\"cast(SendDate as date) = SendDate_lookup\"), \"left\")\n",
				"        .join(creat_lkp, expr(\"cast(CreatedDate as date) = CreatedDate_lookup\"), \"left\")\n",
				"        .join(mod_lkp, expr(\"cast(ModifiedDate as date) = ModifiedDate_lookup\"), \"left\")\n",
				"        .withColumn(\n",
				"            \"ConstituentEmailEngagementKey\",\n",
				"            xxhash64(\n",
				"                col(\"cee.ConstituentEmailEngagementId\"),\n",
				"                col(\"cee.SourceSystemId\")\n",
				"            ).cast(\"bigint\")\n",
				"        )\n",
				"        .select(\n",
				"            \"ConstituentEmailEngagementKey\",\n",
				"            col(\"cee.ConstituentEmailEngagementId\"),\n",
				"            col(\"cee.EmailEngagementId\"),\n",
				"            col(\"cee.SourceSystemId\").alias(\"SourceSysConstituentEmailEngagementId\"),\n",
				"            col(\"cee.ConstituentEmail\"),\n",
				"            \"CampaignKey\",\n",
				"            \"ChannelKey\",     # ‚úÖ from DimEmail\n",
				"            \"WasOpened\",\n",
				"            \"ClickThrough\",\n",
				"            \"Timezone\",\n",
				"            \"ConstituentKey\",\n",
				"            \"EmailKey\",\n",
				"            \"SourceKey\",\n",
				"            \"ClickThroughDateKey\",\n",
				"            \"OpenedDateKey\",\n",
				"            \"SentDateKey\",\n",
				"            \"CreatedDateKey\",\n",
				"            \"ModifiedDateKey\"\n",
				"        )\n",
				"    )\n",
				"\n",
				"    logging.info(f\"‚úÖ FactConstituentEmailEngagement processing {new_df.count()} rows.\")\n",
				"    return new_df\n",
				"\n",
				"\n",
				"\n",
				"factCEE_Table = CdfTable(\n",
				"    source_table_name=\"ConstituentEmailEngagement\",\n",
				"    target_table_name=\"FactConstituentEmailEngagement\",\n",
				"    source_primary_key=\"ConstituentEmailEngagementId\",\n",
				"    columns=[\n",
				"        \"ConstituentEmailEngagementId\",\n",
				"        \"ConstituentEmail\",\n",
				"        \"ConstituentId\",\n",
				"        \"EmailId\",\n",
				"        \"EmailEngagementId\",\n",
				"        \"ClickThrough\",\n",
				"        \"ClickThroughDate\",\n",
				"        \"OpenedDate\",\n",
				"        \"SendDate\",\n",
				"        \"CreatedDate\",\n",
				"        \"ModifiedDate\",\n",
				"        \"WasOpened\",\n",
				"        \"SourceSystemId\",\n",
				"        \"SourceId\",\n",
				"        \"Timezone\"\n",
				"    ],\n",
				"    merge_sql_template=f\"\"\"\n",
				"    MERGE INTO {gold_lakehouse_name}.FactConstituentEmailEngagement AS target\n",
				"    USING latestSnapshot_ConstituentEmailEngagement AS source\n",
				"    ON target.ConstituentEmailEngagementId = source.ConstituentEmailEngagementId\n",
				"    WHEN MATCHED THEN UPDATE SET\n",
				"        ConstituentEmail = source.ConstituentEmail,\n",
				"        WasOpened = source.WasOpened,\n",
				"        ClickThrough = source.ClickThrough,\n",
				"        SourceSysConstituentEmailEngagementId = source.SourceSysConstituentEmailEngagementId,\n",
				"        ConstituentKey = source.ConstituentKey,\n",
				"        CampaignKey = source.CampaignKey,   \n",
				"        ChannelKey = source.ChannelKey,\n",
				"        EmailKey = source.EmailKey,\n",
				"        EmailEngagementId = source.EmailEngagementId,\n",
				"        SourceKey = source.SourceKey,\n",
				"        ClickThroughDateKey = source.ClickThroughDateKey,\n",
				"        OpenedDateKey = source.OpenedDateKey,\n",
				"        SentDateKey = source.SentDateKey,\n",
				"        CreatedDateKey = source.CreatedDateKey,\n",
				"        ModifiedDateKey = source.ModifiedDateKey,\n",
				"        Timezone = source.Timezone\n",
				"    WHEN NOT MATCHED THEN INSERT (\n",
				"        ConstituentEmailEngagementKey,\n",
				"        ConstituentEmailEngagementId,\n",
				"        ConstituentEmail,\n",
				"        WasOpened,\n",
				"        ClickThrough,\n",
				"        SourceSysConstituentEmailEngagementId,\n",
				"        ConstituentKey,\n",
				"        CampaignKey,\n",
				"        ChannelKey,\n",
				"        EmailKey,\n",
				"        EmailEngagementId,\n",
				"        SourceKey,\n",
				"        ClickThroughDateKey,\n",
				"        OpenedDateKey,\n",
				"        SentDateKey,\n",
				"        CreatedDateKey,\n",
				"        ModifiedDateKey,\n",
				"        Timezone\n",
				"    ) VALUES (\n",
				"        source.ConstituentEmailEngagementKey,\n",
				"        source.ConstituentEmailEngagementId,\n",
				"        source.ConstituentEmail,\n",
				"        source.WasOpened,\n",
				"        source.ClickThrough,\n",
				"        source.SourceSysConstituentEmailEngagementId,\n",
				"        source.ConstituentKey,\n",
				"        source.CampaignKey,\n",
				"        source.ChannelKey,\n",
				"        source.EmailKey,\n",
				"        source.EmailEngagementId,\n",
				"        source.SourceKey,\n",
				"        source.ClickThroughDateKey,\n",
				"        source.OpenedDateKey,\n",
				"        source.SentDateKey,\n",
				"        source.CreatedDateKey,\n",
				"        source.ModifiedDateKey,\n",
				"        source.Timezone\n",
				"    )\n",
				"    \"\"\",\n",
				"    source_lakehouse=silver_lakehouse_name,\n",
				"    target_lakehouse=gold_lakehouse_name,\n",
				"    enrich_func=EnrichFactConstituentEmailEngagement,\n",
				"    hard_delete=True\n",
				")\n",
				"\n",
				"ProcessCdfTable(factCEE_Table)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "1de9cb80-b337-4b3a-bd6b-3b2673b07a7b",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"source": [
				"### Build: FactConstituentLetterEngagement"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "034f962a-6b37-4dad-9d91-123d204595b7",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"outputs": [],
			"source": [
				"from pyspark.sql.functions import to_date, col, xxhash64\n",
				"\n",
				"def EnrichFactConstituentLetterEngagement(df: DataFrame) -> DataFrame:\n",
				"    dimDateDf = get_gold_table(\"DimDate\").select(\"Date\", \"DateKey\")\n",
				"    dimConstituentDf = get_gold_table(\"DimConstituent\").select(\"ConstituentId\", \"ConstituentKey\")\n",
				"    dimCampaignDf = get_gold_table(\"DimCampaign\").select(\"CampaignId\", \"CampaignKey\")\n",
				"    dimChannelDf = get_gold_table(\"DimChannel\").select(\"ChannelId\", \"ChannelKey\")  # NEW\n",
				"    dimLetterDf = get_gold_table(\"DimLetter\").select(\"LetterId\", \"LetterKey\")\n",
				"    \n",
				"    date_sent_df = dimDateDf.select(\n",
				"        col(\"Date\").alias(\"SentDate_lookup\"),\n",
				"        col(\"DateKey\").alias(\"DateSent\")\n",
				"    )\n",
				"\n",
				"    df = df.withColumn(\"SentDate_casted\", to_date(\"SentDate\"))\n",
				"\n",
				"    new_df = (\n",
				"        df\n",
				"        .join(dimConstituentDf, on=\"ConstituentId\", how=\"left\")\n",
				"        .join(dimCampaignDf, on=\"CampaignId\", how=\"left\")\n",
				"        .join(dimChannelDf, on=\"ChannelId\", how=\"left\")  # NEW\n",
				"        .join(dimLetterDf, on=\"LetterId\", how=\"left\")\n",
				"        .join(date_sent_df, col(\"SentDate_casted\") == col(\"SentDate_lookup\"), \"left\")\n",
				"        .withColumn(\n",
				"            \"ConstituentLetterEngagementKey\",\n",
				"            xxhash64(col(\"LetterId\"), col(\"ConstituentId\"), col(\"CampaignId\")).cast(\"bigint\")\n",
				"        )\n",
				"        .withColumn(\"ConstituentLetterEngagementId\", col(\"LetterId\"))\n",
				"        .withColumn(\"SourceSysConstituentLetterEngagementId\", col(\"LetterId\"))\n",
				"        .select(\n",
				"            \"ConstituentLetterEngagementKey\",\n",
				"            \"ConstituentLetterEngagementId\",\n",
				"            \"SourceSysConstituentLetterEngagementId\",\n",
				"            \"DateSent\",\n",
				"            \"ConstituentKey\",\n",
				"            \"CampaignKey\",\n",
				"            \"ChannelKey\",  \n",
				"            \"LetterKey\",\n",
				"            \"Timezone\"\n",
				"        )\n",
				"    )\n",
				"\n",
				"    logging.info(f\"‚úÖ FactConstituentLetterEngagement processing {new_df.count()} rows.\")\n",
				"    return new_df\n",
				"\n",
				"\n",
				"factEngagementTable = CdfTable(\n",
				"    source_table_name=\"Letter\",\n",
				"    target_table_name=\"FactConstituentLetterEngagement\",\n",
				"    source_primary_key=\"LetterId\",\n",
				"    columns=[\"LetterId\", \"SentDate\", \"ConstituentId\", \"CampaignId\", \"ChannelId\", \"Timezone\"],\n",
				"    merge_sql_template=f\"\"\"\n",
				"    MERGE INTO {gold_lakehouse_name}.FactConstituentLetterEngagement AS target\n",
				"    USING latestSnapshot_Letter AS source\n",
				"    ON target.ConstituentLetterEngagementId = source.ConstituentLetterEngagementId\n",
				"    WHEN MATCHED THEN UPDATE SET\n",
				"        SourceSysConstituentLetterEngagementId = source.SourceSysConstituentLetterEngagementId,\n",
				"        DateSent = source.DateSent,\n",
				"        ConstituentKey = source.ConstituentKey,\n",
				"        CampaignKey = source.CampaignKey,\n",
				"        ChannelKey = source.ChannelKey,\n",
				"        LetterKey = source.LetterKey,\n",
				"        Timezone = source.Timezone\n",
				"    WHEN NOT MATCHED THEN INSERT (\n",
				"        ConstituentLetterEngagementKey, ConstituentLetterEngagementId,\n",
				"        SourceSysConstituentLetterEngagementId, DateSent, ConstituentKey,\n",
				"        CampaignKey, ChannelKey, LetterKey, Timezone\n",
				"    ) VALUES (\n",
				"        source.ConstituentLetterEngagementKey, source.ConstituentLetterEngagementId,\n",
				"        source.SourceSysConstituentLetterEngagementId, source.DateSent,\n",
				"        source.ConstituentKey, source.CampaignKey, source.ChannelKey, source.LetterKey, source.Timezone\n",
				"    )\n",
				"    \"\"\",\n",
				"    source_lakehouse=silver_lakehouse_name,\n",
				"    target_lakehouse=gold_lakehouse_name,\n",
				"    enrich_func=EnrichFactConstituentLetterEngagement,\n",
				"    hard_delete=True,\n",
				"    delete_on=\"t.ConstituentLetterEngagementId = k.LetterId\"\n",
				")\n",
				"\n",
				"ProcessCdfTable(factEngagementTable)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "95a3be45-3093-4f72-8428-3f711a4d71b9",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"source": [
				"### Build: FactConstituentPhonecallEngagement"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "6ced4989-1df8-4979-8503-07a45b89d128",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"outputs": [],
			"source": [
				"from pyspark.sql.functions import col, xxhash64, expr\n",
				"from pyspark.sql import DataFrame\n",
				"\n",
				"def EnrichFactConstituentPhonecallEngagement(df: DataFrame) -> DataFrame:\n",
				"    # Load dimension tables\n",
				"    dimConstituentDf = get_gold_table(\"DimConstituent\").select(\"ConstituentId\", \"ConstituentKey\")\n",
				"    dimCampaignDf = get_gold_table(\"DimCampaign\").select(\"CampaignId\", \"CampaignKey\")\n",
				"    dimPhonecallDf = get_gold_table(\"DimPhonecall\").select(\"PhonecallId\", \"PhonecallKey\")\n",
				"    dimChannelDf = get_gold_table(\"DimChannel\").select(\"ChannelId\", \"ChannelKey\")\n",
				"    dimSourceDf = get_gold_table(\"DimSource\").select(\"SourceId\", \"SourceKey\")\n",
				"    dimDateDf = get_gold_table(\"DimDate\").select(\"Date\", \"DateKey\")\n",
				"\n",
				"    # Date lookups\n",
				"    dimCallDate = dimDateDf.select(col(\"Date\").alias(\"CallDate_lookup\"), col(\"DateKey\").alias(\"PhonecallDate\"))\n",
				"    dimCreatedDate = dimDateDf.select(col(\"Date\").alias(\"CreatedDate_lookup\"), col(\"DateKey\").alias(\"CreatedDateKey\"))\n",
				"    dimModifiedDate = dimDateDf.select(col(\"Date\").alias(\"ModifiedDate_lookup\"), col(\"DateKey\").alias(\"ModifiedDateKey\"))\n",
				"\n",
				"    # Enrichment\n",
				"    new_df = (\n",
				"        df\n",
				"        .join(dimConstituentDf, on=\"ConstituentId\", how=\"left\")\n",
				"        .join(dimCampaignDf, on=\"CampaignId\", how=\"left\")\n",
				"        .join(dimChannelDf, on=\"ChannelId\", how=\"left\")\n",
				"        .join(dimPhonecallDf, on=\"PhonecallId\", how=\"left\")\n",
				"        .join(dimSourceDf, on=\"SourceId\", how=\"left\")\n",
				"        .join(dimCallDate, expr(\"cast(CallDate as date) = CallDate_lookup\"), \"left\")\n",
				"        .join(dimCreatedDate, expr(\"cast(CreatedDate as date) = CreatedDate_lookup\"), \"left\")\n",
				"        .join(dimModifiedDate, expr(\"cast(ModifiedDate as date) = ModifiedDate_lookup\"), \"left\")\n",
				"        .withColumn(\n",
				"            \"ConstituentPhonecallEngagementKey\",\n",
				"            xxhash64(col(\"PhonecallId\"), col(\"ConstituentId\"), col(\"CampaignId\")).cast(\"bigint\")\n",
				"        )\n",
				"        .select(\n",
				"            \"ConstituentPhonecallEngagementKey\",\n",
				"            col(\"PhonecallId\").alias(\"ConstituentPhonecallEngagementId\"),\n",
				"            col(\"SourceSystemId\").alias(\"SourceSysConstituentPhonecallEngagementId\"),\n",
				"            \"ConstituentKey\",\n",
				"            \"CampaignKey\",\n",
				"            \"ChannelKey\",\n",
				"            \"PhonecallKey\",\n",
				"            \"PhonecallDate\",\n",
				"            \"CreatedDateKey\",\n",
				"            \"ModifiedDateKey\",\n",
				"            \"SourceKey\",\n",
				"            \"Timezone\"\n",
				"        )\n",
				"    )\n",
				"\n",
				"    logging.info(f\"‚úÖ FactConstituentPhonecallEngagement processing {new_df.count()} rows.\")\n",
				"\n",
				"    return new_df\n",
				"\n",
				"\n",
				"\n",
				"constituentPhonecallEngagementTable = CdfTable(\n",
				"    source_table_name=\"Phonecall\",\n",
				"    source_primary_key=\"PhonecallId\",\n",
				"    target_table_name=\"FactConstituentPhonecallEngagement\",\n",
				"    columns=[\n",
				"        \"PhonecallId\", \"SourceSystemId\", \"ConstituentId\", \"CampaignId\", \"ChannelId\", \"CallDate\",\n",
				"        \"CreatedDate\", \"ModifiedDate\", \"SourceId\", \"Timezone\"\n",
				"    ],\n",
				"    merge_sql_template=f\"\"\"\n",
				"    MERGE INTO {gold_lakehouse_name}.FactConstituentPhonecallEngagement AS target\n",
				"    USING latestSnapshot_Phonecall AS source\n",
				"    ON target.ConstituentPhonecallEngagementId = source.ConstituentPhonecallEngagementId\n",
				"    WHEN MATCHED THEN UPDATE SET\n",
				"        SourceSysConstituentPhonecallEngagementId = source.SourceSysConstituentPhonecallEngagementId,\n",
				"        ConstituentKey = source.ConstituentKey,\n",
				"        CampaignKey = source.CampaignKey,\n",
				"        ChannelKey = source.ChannelKey,\n",
				"        PhonecallKey = source.PhonecallKey,\n",
				"        PhonecallDate = source.PhonecallDate,\n",
				"        CreatedDateKey = source.CreatedDateKey,\n",
				"        ModifiedDateKey = source.ModifiedDateKey,\n",
				"        SourceKey = source.SourceKey,\n",
				"        Timezone = source.Timezone\n",
				"    WHEN NOT MATCHED THEN INSERT (\n",
				"        ConstituentPhonecallEngagementKey, ConstituentPhonecallEngagementId,\n",
				"        SourceSysConstituentPhonecallEngagementId, ConstituentKey, CampaignKey, ChannelKey,\n",
				"        PhonecallKey, PhonecallDate, CreatedDateKey, ModifiedDateKey, SourceKey, Timezone\n",
				"    ) VALUES (\n",
				"        source.ConstituentPhonecallEngagementKey, source.ConstituentPhonecallEngagementId,\n",
				"        source.SourceSysConstituentPhonecallEngagementId, source.ConstituentKey, source.CampaignKey, source.ChannelKey,\n",
				"        source.PhonecallKey, source.PhonecallDate, source.CreatedDateKey, source.ModifiedDateKey, source.SourceKey, source.Timezone\n",
				"    )\n",
				"    \"\"\",\n",
				"    source_lakehouse=silver_lakehouse_name,\n",
				"    target_lakehouse=gold_lakehouse_name,\n",
				"    enrich_func=EnrichFactConstituentPhonecallEngagement,\n",
				"    hard_delete=True,\n",
				"    delete_on=\"t.ConstituentPhonecallEngagementId = k.PhonecallId\"\n",
				")\n",
				"\n",
				"ProcessCdfTable(constituentPhonecallEngagementTable)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "b9c83470-1da1-47b3-84d4-0703c8e1f008",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"source": [
				"### Build: FactSocialEngagement"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "c95dc168-3629-4847-8ede-9b99639169a2",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"outputs": [],
			"source": [
				"from pyspark.sql.functions import col, to_date, xxhash64\n",
				"from pyspark.sql import DataFrame\n",
				"\n",
				"def EnrichFactSocialEngagement(df: DataFrame) -> DataFrame:\n",
				"    # Load dimension tables\n",
				"    dimDate = get_gold_table(\"DimDate\").select(col(\"Date\").alias(\"DimDate\"), col(\"DateKey\"))\n",
				"    dimCampaign = get_gold_table(\"DimCampaign\").select(\"CampaignId\", \"CampaignKey\")\n",
				"    dimPlatform = get_gold_table(\"DimEngagementPlatform\").select(\"EngagementPlatformId\", \"EngagementPlatformKey\")\n",
				"    dimSource = get_gold_table(\"DimSource\").select(\"SourceId\", \"SourceKey\")\n",
				"    dimChannel = get_gold_table(\"DimChannel\").select(\"ChannelId\", \"ChannelKey\")  \n",
				"\n",
				"    # Date lookups\n",
				"    dateCreated = dimDate.withColumnRenamed(\"DimDate\", \"CreatedDate_lookup\").withColumnRenamed(\"DateKey\", \"CreatedDateKey\")\n",
				"    dateModified = dimDate.withColumnRenamed(\"DimDate\", \"ModifiedDate_lookup\").withColumnRenamed(\"DateKey\", \"ModifiedDateKey\")\n",
				"    dateInteraction = dimDate.withColumnRenamed(\"DimDate\", \"InteractionDate_lookup\").withColumnRenamed(\"DateKey\", \"InteractionDateKey\")\n",
				"    dateReport = dimDate.withColumnRenamed(\"DimDate\", \"ReportDate_lookup\").withColumnRenamed(\"DateKey\", \"ReportDateKey\")\n",
				"\n",
				"    # Join and enrich\n",
				"    new_df = (\n",
				"        df\n",
				"        .withColumnRenamed(\"Platform\", \"EngagementPlatformId\")\n",
				"        .join(dimCampaign, \"CampaignId\", \"left\")\n",
				"        .join(dimPlatform, \"EngagementPlatformId\", \"left\")\n",
				"        .join(dimSource, \"SourceId\", \"left\")\n",
				"        .join(dimChannel, \"ChannelId\", \"left\") \n",
				"        .join(dateCreated, to_date(\"CreatedDate\") == col(\"CreatedDate_lookup\"), \"left\")\n",
				"        .join(dateModified, to_date(\"ModifiedDate\") == col(\"ModifiedDate_lookup\"), \"left\")\n",
				"        .join(dateInteraction, to_date(\"InteractionDate\") == col(\"InteractionDate_lookup\"), \"left\")\n",
				"        .join(dateReport, to_date(\"ReportDate\") == col(\"ReportDate_lookup\"), \"left\")\n",
				"        .withColumn(\n",
				"            \"FactSocialEngagementKey\",\n",
				"            xxhash64(col(\"SocialEngagementId\"), col(\"SourceSystemId\")).cast(\"bigint\")\n",
				"        )\n",
				"        .select(\n",
				"            \"FactSocialEngagementKey\",\n",
				"            \"SocialEngagementId\",\n",
				"            col(\"SourceSystemId\").alias(\"SourceSocialEngagementId\"),\n",
				"            \"CampaignKey\",\n",
				"            \"EngagementPlatformKey\",\n",
				"            \"ChannelKey\",\n",
				"            \"SourceKey\",\n",
				"            \"CreatedDateKey\",\n",
				"            \"ModifiedDateKey\",\n",
				"            \"InteractionDateKey\",\n",
				"            \"ReportDateKey\",\n",
				"            \"PostId\",\n",
				"            \"Clicks\",\n",
				"            \"Shares\",\n",
				"            \"Comments\",\n",
				"            \"Likes\",\n",
				"            \"Impressions\",\n",
				"            \"Reach\",\n",
				"            \"Engagements\"\n",
				"        )\n",
				"    )\n",
				"\n",
				"    logging.info(f\"‚úÖ FactSocialEngagement processing {new_df.count()} rows.\")\n",
				"    return new_df\n",
				"\n",
				"\n",
				"factSocialEngagementTable = CdfTable(\n",
				"    source_table_name=\"SocialEngagement\",\n",
				"    source_primary_key=\"SocialEngagementId\",\n",
				"    target_table_name=\"FactSocialEngagement\",\n",
				"    columns=[\n",
				"        \"SocialEngagementId\", \"CampaignId\", \"SourceSystemId\", \"SourceId\", \"Platform\", \"PostId\", \"ChannelId\",\n",
				"        \"Clicks\", \"Shares\", \"Comments\", \"Likes\", \"Impressions\", \"Reach\", \"Engagements\",\n",
				"        \"CreatedDate\", \"ModifiedDate\", \"InteractionDate\", \"ReportDate\"\n",
				"    ],\n",
				"    merge_sql_template=f\"\"\"\n",
				"    MERGE INTO {gold_lakehouse_name}.FactSocialEngagement AS target\n",
				"    USING latestSnapshot_SocialEngagement AS source\n",
				"    ON target.SocialEngagementId = source.SocialEngagementId\n",
				"    WHEN MATCHED THEN UPDATE SET\n",
				"        CampaignKey = source.CampaignKey,\n",
				"        EngagementPlatformKey = source.EngagementPlatformKey,\n",
				"        ChannelKey = source.ChannelKey,\n",
				"        SourceKey = source.SourceKey,\n",
				"        CreatedDateKey = source.CreatedDateKey,\n",
				"        ModifiedDateKey = source.ModifiedDateKey,\n",
				"        InteractionDateKey = source.InteractionDateKey,\n",
				"        ReportDateKey = source.ReportDateKey,\n",
				"        PostId = source.PostId,\n",
				"        Clicks = source.Clicks,\n",
				"        Shares = source.Shares,\n",
				"        Comments = source.Comments,\n",
				"        Likes = source.Likes,\n",
				"        Impressions = source.Impressions,\n",
				"        Reach = source.Reach,\n",
				"        Engagements = source.Engagements\n",
				"    WHEN NOT MATCHED THEN INSERT (\n",
				"        FactSocialEngagementKey, SocialEngagementId, SourceSocialEngagementId,\n",
				"        CampaignKey, EngagementPlatformKey, ChannelKey, SourceKey,\n",
				"        CreatedDateKey, ModifiedDateKey, InteractionDateKey, ReportDateKey,\n",
				"        PostId, Clicks, Shares, Comments, Likes, Impressions, Reach, Engagements\n",
				"    ) VALUES (\n",
				"        source.FactSocialEngagementKey, source.SocialEngagementId, source.SourceSocialEngagementId,\n",
				"        source.CampaignKey, source.EngagementPlatformKey, source.ChannelKey, source.SourceKey,\n",
				"        source.CreatedDateKey, source.ModifiedDateKey, source.InteractionDateKey, source.ReportDateKey,\n",
				"        source.PostId, source.Clicks, source.Shares, source.Comments, source.Likes,\n",
				"        source.Impressions, source.Reach, source.Engagements\n",
				"    )\n",
				"    \"\"\",\n",
				"    source_lakehouse=silver_lakehouse_name,\n",
				"    target_lakehouse=gold_lakehouse_name,\n",
				"    enrich_func=EnrichFactSocialEngagement,\n",
				"    hard_delete=True\n",
				")\n",
				"\n",
				"ProcessCdfTable(factSocialEngagementTable)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "f46a6b91-6cd1-4cd6-8c5b-391ceae494d1",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"source": [
				"### Build: FactConstituentSocialEngagement"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "f1de382a-20fd-4da5-ab5f-ceb690d046e6",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"outputs": [],
			"source": [
				"from pyspark.sql.functions import col, expr, xxhash64\n",
				"\n",
				"def EnrichConstituentSocialEngagement(df: DataFrame) -> DataFrame:\n",
				"    # Gold lookups\n",
				"    dim_const = get_gold_table(\"DimConstituent\").select(\"ConstituentId\", \"ConstituentKey\")\n",
				"    dim_source = get_gold_table(\"DimSource\").select(\"SourceId\", \"SourceKey\")\n",
				"    dim_date = get_gold_table(\"DimDate\").select(\"Date\", \"DateKey\")\n",
				"\n",
				"    # üÜï Join to FactSocialEngagement to get ChannelKey\n",
				"    fact_social = get_gold_table(\"FactSocialEngagement\").select(\n",
				"        \"SocialEngagementId\", \"ChannelKey\"\n",
				"    )\n",
				"\n",
				"    # Date lookups\n",
				"    date_lkp     = dim_date.select(col(\"Date\").alias(\"Date_lookup\"),     col(\"DateKey\").alias(\"DateKey\"))\n",
				"    created_lkp  = dim_date.select(col(\"Date\").alias(\"Created_lookup\"),  col(\"DateKey\").alias(\"CreatedDateKey\"))\n",
				"    modified_lkp = dim_date.select(col(\"Date\").alias(\"Modified_lookup\"), col(\"DateKey\").alias(\"ModifiedDateKey\"))\n",
				"\n",
				"    # Join and enrich\n",
				"    new_df = (\n",
				"        df.join(dim_const, \"ConstituentId\", \"left\")\n",
				"          .join(dim_source, \"SourceId\", \"left\")\n",
				"          .join(fact_social, \"SocialEngagementId\", \"left\")  \n",
				"          .join(date_lkp,     expr(\"cast(Date as date) = Date_lookup\"), \"left\")\n",
				"          .join(created_lkp,  expr(\"cast(CreatedDate as date) = Created_lookup\"), \"left\")\n",
				"          .join(modified_lkp, expr(\"cast(ModifiedDate as date) = Modified_lookup\"), \"left\")\n",
				"          .withColumn(\n",
				"              \"ConstituentSocialEngagementKey\",\n",
				"              xxhash64(\n",
				"                  col(\"ConstituentSocialEngagementId\"),\n",
				"                  col(\"SourceSystemId\")\n",
				"              ).cast(\"bigint\")\n",
				"          )\n",
				"          .withColumn(\"SourceSysConstituentSocialEngagementId\", col(\"SourceSystemId\"))\n",
				"          .select(\n",
				"              \"ConstituentSocialEngagementKey\",\n",
				"              \"ConstituentSocialEngagementId\",\n",
				"              \"SocialEngagementId\",\n",
				"              \"SourceSysConstituentSocialEngagementId\",\n",
				"              \"ConstituentKey\",\n",
				"              \"ChannelKey\",  \n",
				"              \"DateKey\",\n",
				"              \"Impression\",\n",
				"              \"Share\",\n",
				"              \"Comment\",\n",
				"              \"Like\",\n",
				"              \"CreatedDateKey\",\n",
				"              \"ModifiedDateKey\",\n",
				"              \"SourceKey\",\n",
				"              \"Timezone\"\n",
				"          )\n",
				"    )\n",
				"\n",
				"    logging.info(f\"‚úÖ FactConstituentSocialEngagement processing {new_df.count()} rows.\")\n",
				"    return new_df\n",
				"\n",
				"\n",
				"\n",
				"constituentSocialEngagementTable = CdfTable(\n",
				"    source_table_name=\"ConstituentSocialEngagement\",\n",
				"    source_primary_key=\"ConstituentSocialEngagementId\",\n",
				"    target_table_name=\"FactConstituentSocialEngagement\",\n",
				"    columns=[\n",
				"        \"ConstituentSocialEngagementId\",\"SocialEngagementId\",\"ConstituentId\",\n",
				"        \"Date\",\"Impression\",\"Share\",\"Comment\",\"Like\",\n",
				"        \"CreatedDate\",\"ModifiedDate\",\"SourceId\",\"SourceSystemId\",\"Timezone\"\n",
				"    ],\n",
				"    merge_sql_template=f\"\"\"\n",
				"    MERGE INTO {gold_lakehouse_name}.FactConstituentSocialEngagement AS target\n",
				"    USING latestSnapshot_ConstituentSocialEngagement AS source\n",
				"    ON target.ConstituentSocialEngagementId = source.ConstituentSocialEngagementId\n",
				"    WHEN MATCHED THEN UPDATE SET\n",
				"        SourceSysConstituentSocialEngagementId = source.SourceSysConstituentSocialEngagementId,\n",
				"        ConstituentKey = source.ConstituentKey,\n",
				"        ChannelKey = source.ChannelKey,\n",
				"        DateKey = source.DateKey,\n",
				"        Impression = source.Impression,\n",
				"        Share = source.Share,\n",
				"        Comment = source.Comment,\n",
				"        Like = source.Like,\n",
				"        CreatedDateKey = source.CreatedDateKey,\n",
				"        ModifiedDateKey = source.ModifiedDateKey,\n",
				"        SourceKey = source.SourceKey,\n",
				"        Timezone = source.Timezone\n",
				"    WHEN NOT MATCHED THEN INSERT (\n",
				"        ConstituentSocialEngagementKey,\n",
				"        ConstituentSocialEngagementId,\n",
				"        SocialEngagementId,\n",
				"        SourceSysConstituentSocialEngagementId,\n",
				"        ConstituentKey,\n",
				"        ChannelKey,\n",
				"        DateKey,\n",
				"        Impression,\n",
				"        Share,\n",
				"        Comment,\n",
				"        Like,\n",
				"        CreatedDateKey,\n",
				"        ModifiedDateKey,\n",
				"        SourceKey,\n",
				"        Timezone\n",
				"    ) VALUES (\n",
				"        source.ConstituentSocialEngagementKey,\n",
				"        source.ConstituentSocialEngagementId,\n",
				"        source.SocialEngagementId,\n",
				"        source.SourceSysConstituentSocialEngagementId,\n",
				"        source.ConstituentKey,\n",
				"        source.ChannelKey,\n",
				"        source.DateKey,\n",
				"        source.Impression,\n",
				"        source.Share,\n",
				"        source.Comment,\n",
				"        source.Like,\n",
				"        source.CreatedDateKey,\n",
				"        source.ModifiedDateKey,\n",
				"        source.SourceKey,\n",
				"        source.Timezone\n",
				"    )\n",
				"    \"\"\",\n",
				"    source_lakehouse=silver_lakehouse_name,\n",
				"    target_lakehouse=gold_lakehouse_name,\n",
				"    enrich_func=EnrichConstituentSocialEngagement,\n",
				"    hard_delete=True\n",
				")\n",
				"\n",
				"ProcessCdfTable(constituentSocialEngagementTable)"
			]
		},
		{
			"cell_type": "markdown",
			"id": "9012c1a4-e090-4580-a080-17368ce81dc1",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"source": [
				"## Datamart tables"
			]
		},
		{
			"cell_type": "markdown",
			"id": "cbe7f103-8bdf-4c4b-8192-6ada0effc8f9",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"source": [
				"### Build: dm_Constituent"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "de06eb45-55e1-484c-9da6-e9d0ffc8d4af",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"outputs": [],
			"source": [
				"df_constituent = spark.sql(f\"\"\"\n",
				"    WITH DonationStats AS (\n",
				"        SELECT \n",
				"            ConstituentKey,\n",
				"            CAST(SUM(Amount) AS DECIMAL(18,4)) AS LifetimeDonationAmount,\n",
				"            MIN(DonationDateKey) AS FirstDonationDateKey,\n",
				"            MAX(DonationDateKey) AS LastDonationDateKey\n",
				"        FROM {gold_lakehouse_name}.FactDonation\n",
				"        GROUP BY ConstituentKey\n",
				"    ),\n",
				"    EventStats AS (\n",
				"        SELECT \n",
				"            ConstituentKey,\n",
				"            COUNT(*) AS AttendedEventsCount\n",
				"        FROM {gold_lakehouse_name}.FactEventAttendance\n",
				"        WHERE AttendedEvent = true\n",
				"        GROUP BY ConstituentKey\n",
				"    ),\n",
				"    EngagementStats AS (\n",
				"        SELECT ConstituentKey, MIN(EngagementDate) AS FirstEngagementDateKey\n",
				"        FROM (\n",
				"            SELECT ea.ConstituentKey, MIN(e.EventDateKey) AS EngagementDate\n",
				"            FROM {gold_lakehouse_name}.FactEventAttendance ea\n",
				"            JOIN {gold_lakehouse_name}.DimEvent e ON e.EventKey = ea.EventKey\n",
				"            GROUP BY ea.ConstituentKey\n",
				"\n",
				"            UNION ALL\n",
				"\n",
				"            SELECT VolunteerKey AS ConstituentKey, MIN(VolunteeredDateKey)\n",
				"            FROM {gold_lakehouse_name}.FactVolunteerHours\n",
				"            GROUP BY VolunteerKey\n",
				"\n",
				"            UNION ALL\n",
				"\n",
				"            SELECT ConstituentKey, MIN(DonationDateKey)\n",
				"            FROM {gold_lakehouse_name}.FactDonation\n",
				"            GROUP BY ConstituentKey\n",
				"\n",
				"            UNION ALL\n",
				"\n",
				"            SELECT ConstituentKey, MIN(DateKey)\n",
				"            FROM {gold_lakehouse_name}.FactConstituentSocialEngagement\n",
				"            GROUP BY ConstituentKey\n",
				"\n",
				"            UNION ALL\n",
				"\n",
				"            SELECT ConstituentKey, MIN(SentDateKey)\n",
				"            FROM {gold_lakehouse_name}.FactConstituentEmailEngagement\n",
				"            GROUP BY ConstituentKey\n",
				"        ) AS EngagementUnion\n",
				"        GROUP BY ConstituentKey\n",
				"    ),\n",
				"    OpportunityStats AS (\n",
				"        SELECT ConstituentKey\n",
				"        FROM {gold_lakehouse_name}.FactOpportunity fo\n",
				"        LEFT JOIN {gold_lakehouse_name}.DimOpportunityType do\n",
				"            ON fo.OpportunityTypeKey = do.OpportunityTypeKey\n",
				"        WHERE OpportunityTypeName = 'Pledge' AND CloseDateKey IS NOT NULL\n",
				"        GROUP BY ConstituentKey\n",
				"    ),\n",
				"    ContactInfo AS (\n",
				"        SELECT\n",
				"            g.ConstituentKey,\n",
				"            c.BirthDate,\n",
				"            CAST(FLOOR(DATEDIFF(CURRENT_DATE(), c.BirthDate) / 365.25) AS BIGINT) AS Age\n",
				"        FROM {gold_lakehouse_name}.DimConstituent g\n",
				"        JOIN {silver_lakehouse_name}.Constituent s ON g.ConstituentId = s.ConstituentId\n",
				"        JOIN {silver_lakehouse_name}.Contact c ON s.ContactId = c.ContactId\n",
				"    ),\n",
				"    FirstEngagementChannel AS (\n",
				"    SELECT ConstituentKey, ChannelName AS AcquisitionChannel\n",
				"    FROM (\n",
				"        SELECT \n",
				"            ce.ConstituentKey,\n",
				"            ce.ChannelName,\n",
				"            dd.Date,\n",
				"            ROW_NUMBER() OVER (PARTITION BY ce.ConstituentKey ORDER BY dd.Date ASC) AS rn\n",
				"        FROM (\n",
				"            SELECT ConstituentKey, SentDateKey AS DateKey, 'Email' AS ChannelName FROM {gold_lakehouse_name}.FactConstituentEmailEngagement\n",
				"            UNION ALL\n",
				"            SELECT ConstituentKey, DateKey, 'Social Media' AS ChannelName FROM {gold_lakehouse_name}.FactConstituentSocialEngagement\n",
				"            UNION ALL\n",
				"            SELECT ConstituentKey, DateSentKey AS DateKey, 'Direct Mail' AS ChannelName FROM {gold_lakehouse_name}.FactConstituentLetterEngagement\n",
				"            UNION ALL\n",
				"            SELECT ConstituentKey, PhonecallDate AS DateKey, 'Phone Call' AS ChannelName FROM {gold_lakehouse_name}.FactConstituentPhonecallEngagement\n",
				"            UNION ALL\n",
				"            SELECT fa.ConstituentKey, e.EventDateKey AS DateKey, 'Events' AS ChannelName\n",
				"            FROM {gold_lakehouse_name}.FactEventAttendance fa\n",
				"            JOIN {gold_lakehouse_name}.DimEvent e ON fa.EventKey = e.EventKey\n",
				"        ) ce\n",
				"        JOIN {gold_lakehouse_name}.DimDate dd ON ce.DateKey = dd.DateKey\n",
				"    ) ranked\n",
				"    WHERE rn = 1\n",
				")\n",
				"\n",
				"    SELECT\n",
				"        dc.ConstituentKey,\n",
				"        dc.ConstituentId,\n",
				"        dc.ConstituentName,\n",
				"        dc.Email,\n",
				"        ci.Age,\n",
				"        fc.AcquisitionChannel,\n",
				"\n",
				"        CAST(ds.LifetimeDonationAmount AS DECIMAL(18,4)) AS LifetimeDonationAmount,\n",
				"        ds.FirstDonationDateKey,\n",
				"        ds.LastDonationDateKey,\n",
				"\n",
				"        es.AttendedEventsCount,\n",
				"        eg.FirstEngagementDateKey,\n",
				"\n",
				"        CAST(\n",
				"            CASE \n",
				"                WHEN dd_fd.Date >= DATEADD(month, -12, CURRENT_DATE())\n",
				"                    AND dd_fd.Date IS NOT NULL THEN 1 \n",
				"                ELSE 0 \n",
				"            END AS BOOLEAN\n",
				"        ) AS IsNewDonor,\n",
				"\n",
				"        CASE \n",
				"            WHEN ds.LifetimeDonationAmount IS NOT NULL OR o.ConstituentKey IS NOT NULL THEN 'Conversion'\n",
				"            WHEN eg.FirstEngagementDateKey IS NOT NULL THEN 'Engagement'\n",
				"            WHEN EXISTS (\n",
				"                SELECT 1 FROM {gold_lakehouse_name}.FactConstituentEmailEngagement e \n",
				"                WHERE e.ConstituentKey = dc.ConstituentKey\n",
				"            ) OR EXISTS (\n",
				"                SELECT 1 FROM {gold_lakehouse_name}.FactConstituentSocialEngagement s \n",
				"                WHERE s.ConstituentKey = dc.ConstituentKey\n",
				"            ) THEN 'Awareness'\n",
				"            ELSE 'Unengaged'\n",
				"        END AS EngagementStage\n",
				"\n",
				"    FROM {gold_lakehouse_name}.DimConstituent dc\n",
				"    LEFT JOIN DonationStats ds ON ds.ConstituentKey = dc.ConstituentKey\n",
				"    LEFT JOIN EventStats es ON es.ConstituentKey = dc.ConstituentKey\n",
				"    LEFT JOIN EngagementStats eg ON eg.ConstituentKey = dc.ConstituentKey\n",
				"    LEFT JOIN OpportunityStats o ON o.ConstituentKey = dc.ConstituentKey\n",
				"    LEFT JOIN {gold_lakehouse_name}.DimDate dd_fd ON dd_fd.DateKey = ds.FirstDonationDateKey\n",
				"    LEFT JOIN ContactInfo ci ON dc.ConstituentKey = ci.ConstituentKey\n",
				"    LEFT JOIN FirstEngagementChannel fc ON dc.ConstituentKey = fc.ConstituentKey\n",
				"\"\"\")\n",
				"\n",
				"df_constituent.write.mode(\"overwrite\").format(\"delta\").saveAsTable(f\"{gold_lakehouse_name}.dm_Constituent\")\n"
			]
		},
		{
			"cell_type": "markdown",
			"id": "b2b74ea9-47f6-44a1-a9da-b6bbb3919b3a",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"source": [
				"### Build: dm_EngagementTimeline"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "194d1d6e-0955-41a0-88f4-dc98e8129b57",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"outputs": [],
			"source": [
				"df_engagementtimeline = spark.sql(f\"\"\"\n",
				"WITH engagement_union AS (\n",
				"    SELECT\n",
				"        cee.ConstituentKey,\n",
				"        cee.SentDateKey AS EngagementDate,\n",
				"        ch.ChannelKey,\n",
				"        cee.CampaignKey,\n",
				"        CASE \n",
				"            WHEN cee.ClickThrough = 1 THEN 'Email Click'\n",
				"            WHEN cee.WasOpened = 1 THEN 'Email Open'\n",
				"            ELSE 'Email Sent'\n",
				"        END AS EngagementType,\n",
				"        dc.EngagementStage,\n",
				"        de.EmailId AS InteractionId,\n",
				"        CASE\n",
				"            WHEN dcc.FirstDonationDateKey IS NOT NULL\n",
				"             AND dcc.FirstDonationDateKey >= cee.SentDateKey THEN TRUE\n",
				"            ELSE FALSE\n",
				"        END AS WasConverted\n",
				"    FROM {gold_lakehouse_name}.FactConstituentEmailEngagement cee\n",
				"    JOIN {gold_lakehouse_name}.DimChannel ch ON ch.ChannelName = 'Email'\n",
				"    JOIN {gold_lakehouse_name}.DimConstituent dc ON cee.ConstituentKey = dc.ConstituentKey\n",
				"    JOIN {gold_lakehouse_name}.DimEmail de ON cee.EmailKey = de.EmailKey\n",
				"    JOIN {gold_lakehouse_name}.dm_Constituent dcc ON cee.ConstituentKey = dcc.ConstituentKey\n",
				"\n",
				"   UNION ALL\n",
				"\n",
				"   SELECT\n",
				"       cse.ConstituentKey,\n",
				"       cse.DateKey AS EngagementDate,\n",
				"       ch.ChannelKey,\n",
				"       NULL AS CampaignKey,\n",
				"       CASE \n",
				"           WHEN cse.`Like` THEN 'Social Like'\n",
				"           WHEN cse.Share THEN 'Social Share'\n",
				"           WHEN cse.`Comment` THEN 'Social Comment'\n",
				"           WHEN cse.Impression THEN 'Social Impression'\n",
				"           ELSE 'Social View'\n",
				"       END AS EngagementType,\n",
				"       dc.EngagementStage,\n",
				"       cse.SocialEngagementId AS InteractionId,\n",
				"       CASE\n",
				"           WHEN dcc.FirstDonationDateKey IS NOT NULL\n",
				"            AND dcc.FirstDonationDateKey >= cse.DateKey THEN TRUE\n",
				"           ELSE FALSE\n",
				"       END AS WasConverted\n",
				"   FROM {gold_lakehouse_name}.FactConstituentSocialEngagement cse\n",
				"   JOIN {gold_lakehouse_name}.DimChannel ch ON ch.ChannelName = 'Social Media'\n",
				"   JOIN {gold_lakehouse_name}.DimConstituent dc ON cse.ConstituentKey = dc.ConstituentKey\n",
				"   JOIN {gold_lakehouse_name}.dm_Constituent dcc ON cse.ConstituentKey = dcc.ConstituentKey\n",
				"    UNION ALL\n",
				"\n",
				"    SELECT\n",
				"        ea.ConstituentKey,\n",
				"        e.EventDateKey AS EngagementDate,\n",
				"        ch.ChannelKey,\n",
				"        NULL AS CampaignKey,\n",
				"        CASE \n",
				"            WHEN ea.AttendedEvent = 1 THEN 'Event Attended'\n",
				"            WHEN ea.AcceptedDateKey IS NOT NULL THEN 'Event Accepted'\n",
				"            WHEN ea.InvitationDateKey IS NOT NULL THEN 'Event Invited'\n",
				"            ELSE 'Event Registered'\n",
				"        END AS EngagementType,\n",
				"        dc.EngagementStage,\n",
				"        e.EventId AS InteractionId,\n",
				"        CASE\n",
				"            WHEN dcc.FirstDonationDateKey IS NOT NULL\n",
				"             AND dcc.FirstDonationDateKey >= e.EventDateKey THEN TRUE\n",
				"            ELSE FALSE\n",
				"        END AS WasConverted\n",
				"    FROM {gold_lakehouse_name}.FactEventAttendance ea\n",
				"    JOIN {gold_lakehouse_name}.DimEvent e ON ea.EventKey = e.EventKey\n",
				"    JOIN {gold_lakehouse_name}.DimChannel ch ON ch.ChannelName = 'Events'\n",
				"    JOIN {gold_lakehouse_name}.DimConstituent dc ON ea.ConstituentKey = dc.ConstituentKey\n",
				"    JOIN {gold_lakehouse_name}.dm_Constituent dcc ON ea.ConstituentKey = dcc.ConstituentKey\n",
				"\n",
				"    UNION ALL\n",
				"\n",
				"    SELECT\n",
				"        cle.ConstituentKey,\n",
				"        cle.DateSent AS EngagementDate,\n",
				"        ch.ChannelKey,\n",
				"        cle.CampaignKey,\n",
				"        'Letter Sent' AS EngagementType,\n",
				"        dc.EngagementStage,\n",
				"        dl.LetterId AS InteractionId,\n",
				"        CASE\n",
				"            WHEN dcc.FirstDonationDateKey IS NOT NULL\n",
				"             AND dcc.FirstDonationDateKey >= cle.DateSent THEN TRUE\n",
				"            ELSE FALSE\n",
				"        END AS WasConverted\n",
				"    FROM {gold_lakehouse_name}.FactConstituentLetterEngagement cle\n",
				"    JOIN {gold_lakehouse_name}.DimChannel ch ON ch.ChannelName = 'Direct Mail'\n",
				"    JOIN {gold_lakehouse_name}.DimConstituent dc ON cle.ConstituentKey = dc.ConstituentKey\n",
				"    JOIN {gold_lakehouse_name}.DimLetter dl ON cle.LetterKey = dl.LetterKey\n",
				"    JOIN {gold_lakehouse_name}.dm_Constituent dcc ON cle.ConstituentKey = dcc.ConstituentKey\n",
				"\n",
				"    UNION ALL\n",
				"\n",
				"    SELECT\n",
				"        pc.ConstituentKey,\n",
				"        pc.PhonecallDate AS EngagementDate,\n",
				"        ch.ChannelKey,\n",
				"        pc.CampaignKey,\n",
				"        'Phone Call' AS EngagementType,\n",
				"        dc.EngagementStage,\n",
				"        dp.PhonecallId AS InteractionId,\n",
				"        CASE\n",
				"            WHEN dcc.FirstDonationDateKey IS NOT NULL\n",
				"             AND dcc.FirstDonationDateKey >= pc.PhonecallDate THEN TRUE\n",
				"            ELSE FALSE\n",
				"        END AS WasConverted\n",
				"    FROM {gold_lakehouse_name}.FactConstituentPhonecallEngagement pc\n",
				"    JOIN {gold_lakehouse_name}.DimPhonecall dp ON pc.PhonecallKey = dp.PhonecallKey\n",
				"    JOIN {gold_lakehouse_name}.DimChannel ch ON ch.ChannelName = 'Phone Call'\n",
				"    JOIN {gold_lakehouse_name}.DimConstituent dc ON pc.ConstituentKey = dc.ConstituentKey\n",
				"    JOIN {gold_lakehouse_name}.dm_Constituent dcc ON pc.ConstituentKey = dcc.ConstituentKey\n",
				"),\n",
				"counts AS (\n",
				"    SELECT ConstituentKey, COUNT(*) AS EngagementsBeforeDonation\n",
				"    FROM engagement_union\n",
				"    WHERE WasConverted = TRUE\n",
				"    GROUP BY ConstituentKey\n",
				")\n",
				"SELECT e.*, c.EngagementsBeforeDonation\n",
				"FROM engagement_union e\n",
				"LEFT JOIN counts c\n",
				"    ON e.ConstituentKey = c.ConstituentKey\n",
				"\"\"\")\n",
				"\n",
				"df_engagementtimeline.write.mode(\"overwrite\").format(\"delta\").saveAsTable(f\"{gold_lakehouse_name}.dm_EngagementTimeline\")\n"
			]
		},
		{
			"cell_type": "markdown",
			"id": "fe3da66e-16b3-4726-8919-c0c584c765ce",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"source": [
				"### Build: dm_CampaignAttribution"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "70087003-7c03-4525-a537-80434ddeb138",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"outputs": [],
			"source": [
				"df_campaignattribution = spark.sql(f\"\"\"\n",
				"    -- EMAIL ENGAGEMENTS\n",
				"    SELECT /*+ MERGE(d, e, dd_d, dd_e, ch) */\n",
				"        d.DonationKey,\n",
				"        e.ConstituentKey,\n",
				"        d.DonationDateKey,\n",
				"        e.SentDateKey AS EngagementDateKey,\n",
				"        CASE \n",
				"            WHEN e.WasOpened = 1 THEN 'Email Open'\n",
				"            WHEN e.ClickThroughDateKey IS NOT NULL THEN 'Email Click'\n",
				"            ELSE 'Email Sent'\n",
				"        END AS EngagementType,\n",
				"        ch.ChannelKey,\n",
				"        e.CampaignKey\n",
				"    FROM {gold_lakehouse_name}.FactDonation d\n",
				"    JOIN {gold_lakehouse_name}.FactConstituentEmailEngagement e ON d.ConstituentKey = e.ConstituentKey\n",
				"    JOIN {gold_lakehouse_name}.DimDate dd_d ON dd_d.DateKey = d.DonationDateKey\n",
				"    JOIN {gold_lakehouse_name}.DimDate dd_e ON dd_e.DateKey = e.SentDateKey\n",
				"    JOIN {gold_lakehouse_name}.DimChannel ch ON ch.ChannelName = 'Email'\n",
				"    WHERE dd_e.Date <= dd_d.Date\n",
				"\n",
				"    UNION ALL\n",
				"\n",
				"    -- SOCIAL ENGAGEMENTS\n",
				"    SELECT /*+ MERGE(d, s, dd_d, dd_s, ch) */\n",
				"        d.DonationKey,\n",
				"        s.ConstituentKey,\n",
				"        d.DonationDateKey,\n",
				"        s.DateKey AS EngagementDateKey,\n",
				"        CASE \n",
				"            WHEN s.`Like` THEN 'Social Like'\n",
				"            WHEN s.Share THEN 'Social Share'\n",
				"            WHEN s.`Comment` THEN 'Social Comment'\n",
				"            WHEN s.Impression THEN 'Social Impression'\n",
				"            ELSE 'Social View'\n",
				"        END AS EngagementType,\n",
				"        ch.ChannelKey,\n",
				"        NULL AS CampaignKey\n",
				"    FROM {gold_lakehouse_name}.FactDonation d\n",
				"    JOIN {gold_lakehouse_name}.FactConstituentSocialEngagement s ON d.ConstituentKey = s.ConstituentKey\n",
				"    JOIN {gold_lakehouse_name}.DimDate dd_d ON dd_d.DateKey = d.DonationDateKey\n",
				"    JOIN {gold_lakehouse_name}.DimDate dd_s ON dd_s.DateKey = s.DateKey\n",
				"    JOIN {gold_lakehouse_name}.DimChannel ch ON ch.ChannelName = 'Social Media'\n",
				"    WHERE dd_s.Date <= dd_d.Date\n",
				"\n",
				"    UNION ALL\n",
				"\n",
				"    -- LETTER ENGAGEMENTS\n",
				"    SELECT /*+ MERGE(d, l, dd_d, dd_l, ch) */\n",
				"        d.DonationKey,\n",
				"        l.ConstituentKey,\n",
				"        d.DonationDateKey,\n",
				"        l.DateSent AS EngagementDateKey,\n",
				"        'Letter Sent' AS EngagementType,\n",
				"        ch.ChannelKey,\n",
				"        l.CampaignKey\n",
				"    FROM {gold_lakehouse_name}.FactDonation d\n",
				"    JOIN {gold_lakehouse_name}.FactConstituentLetterEngagement l ON d.ConstituentKey = l.ConstituentKey\n",
				"    JOIN {gold_lakehouse_name}.DimDate dd_d ON dd_d.DateKey = d.DonationDateKey\n",
				"    JOIN {gold_lakehouse_name}.DimDate dd_l ON dd_l.DateKey = l.DateSent\n",
				"    JOIN {gold_lakehouse_name}.DimChannel ch ON ch.ChannelName = 'Direct Mail'\n",
				"    WHERE dd_l.Date <= dd_d.Date\n",
				"\n",
				"    UNION ALL\n",
				"\n",
				"    -- PHONE CALL ENGAGEMENTS\n",
				"    SELECT /*+ MERGE(d, p, dd_d, dd_p, ch) */\n",
				"        d.DonationKey,\n",
				"        p.ConstituentKey,\n",
				"        d.DonationDateKey,\n",
				"        p.PhonecallDate AS EngagementDateKey,\n",
				"        'Phone Call' AS EngagementType,\n",
				"        ch.ChannelKey,\n",
				"        p.CampaignKey\n",
				"    FROM {gold_lakehouse_name}.FactDonation d\n",
				"    JOIN {gold_lakehouse_name}.FactConstituentPhonecallEngagement p ON d.ConstituentKey = p.ConstituentKey\n",
				"    JOIN {gold_lakehouse_name}.DimDate dd_d ON dd_d.DateKey = d.DonationDateKey\n",
				"    JOIN {gold_lakehouse_name}.DimDate dd_p ON dd_p.DateKey = p.PhonecallDate\n",
				"    JOIN {gold_lakehouse_name}.DimChannel ch ON ch.ChannelName = 'Phone Call'\n",
				"    WHERE dd_p.Date <= dd_d.Date\n",
				"\n",
				"    UNION ALL\n",
				"\n",
				"    -- EVENT ATTENDANCE ENGAGEMENTS\n",
				"    SELECT /*+ MERGE(d, ea, e, dd_d, dd_e, ch) */\n",
				"        d.DonationKey,\n",
				"        ea.ConstituentKey,\n",
				"        d.DonationDateKey,\n",
				"        e.EventDateKey AS EngagementDateKey,\n",
				"        CASE \n",
				"            WHEN ea.AttendedEvent = 1 THEN 'Event Attended'\n",
				"            WHEN ea.AcceptedDateKey IS NOT NULL THEN 'Event Accepted'\n",
				"            WHEN ea.InvitationDateKey IS NOT NULL THEN 'Event Invited'\n",
				"            ELSE 'Event Registered'\n",
				"        END AS EngagementType,\n",
				"        ch.ChannelKey,\n",
				"        NULL AS CampaignKey\n",
				"    FROM {gold_lakehouse_name}.FactDonation d\n",
				"    JOIN {gold_lakehouse_name}.FactEventAttendance ea ON d.ConstituentKey = ea.ConstituentKey\n",
				"    JOIN {gold_lakehouse_name}.DimEvent e ON ea.EventKey = e.EventKey\n",
				"    JOIN {gold_lakehouse_name}.DimDate dd_d ON dd_d.DateKey = d.DonationDateKey\n",
				"    JOIN {gold_lakehouse_name}.DimDate dd_e ON dd_e.DateKey = e.EventDateKey\n",
				"    JOIN {gold_lakehouse_name}.DimChannel ch ON ch.ChannelName = 'Events'\n",
				"    WHERE dd_e.Date <= dd_d.Date\n",
				"\"\"\")\n",
				"\n",
				"df_campaignattribution.write.mode(\"overwrite\").format(\"delta\").saveAsTable(f\"{gold_lakehouse_name}.dm_CampaignAttribution\")"
			]
		},
		{
			"cell_type": "markdown",
			"id": "b1c37d80-e684-4ec0-bdd6-cc034ff0e826",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"source": [
				"# Validation"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "e9682299-faf9-42ec-8500-f6fd7a638a4d",
			"metadata": {
				"microsoft": {
					"language": "python",
					"language_group": "synapse_pyspark"
				}
			},
			"outputs": [],
			"source": [
				"tables = [\n",
				"    \"Configuration\",\n",
				"    \"DimAddress\",\n",
				"    \"DimCampaign\",\n",
				"    \"DimCampaignChannelBridge\",\n",
				"    \"DimCampaignType\",\n",
				"    \"DimChannel\",\n",
				"    \"DimConstituent\",\n",
				"    \"DimConstituentProgramBridge\",\n",
				"    \"DimConstituentSegment\",\n",
				"    \"DimConstituentSegmentBridge\",\n",
				"    \"DimConstituentSegmentType\",\n",
				"    \"DimDate\",\n",
				"    \"DimDonationSource\",\n",
				"    \"DimEmail\",\n",
				"    \"DimEngagementPlatform\",\n",
				"    \"DimEvent\",\n",
				"    \"DimLetter\",\n",
				"    \"DimOpportunityStage\",\n",
				"    \"DimOpportunityType\",\n",
				"    \"DimPhonecall\",\n",
				"    \"DimProgram\",\n",
				"    \"DimSource\",\n",
				"    \"DimVolunteeringType\",\n",
				"    \"FactConstituentEmailEngagement\",\n",
				"    \"FactConstituentLetterEngagement\",\n",
				"    \"FactConstituentPhonecallEngagement\",\n",
				"    \"FactConstituentSocialEngagement\",\n",
				"    \"FactDonation\",\n",
				"    \"FactEventAttendance\",\n",
				"    \"FactOpportunity\",\n",
				"    \"FactSocialEngagement\",\n",
				"    \"FactSoftCredit\",\n",
				"    \"FactVolunteerHours\",\n",
				"    \"FactWealthScreening\",\n",
				"    \"dm_CampaignAttribution\",\n",
				"    \"dm_Constituent\",\n",
				"    \"dm_EngagementTimeline\",\n",
				"]\n",
				"\n",
				"df = get_lakehouse_table_counts(gold_lakehouse_name, tables)\n",
				"display(df)"
			]
		}
	],
	"metadata": {
		"a365ComputeOptions": null,
		"dependencies": {
			"lakehouse": {
				"default_lakehouse": "{SILVER_LAKEHOUSE_ID}",
				"default_lakehouse_name": "{SILVER_LAKEHOUSE_NAME}",
				"default_lakehouse_workspace_id": "{WORKSPACE_ID}",
				"known_lakehouses": [
					{
						"id": "{SILVER_LAKEHOUSE_ID}"
					}
				]
			}
		},
		"kernel_info": {
			"name": "synapse_pyspark"
		},
		"kernelspec": {
			"display_name": "synapse_pyspark",
			"language": null,
			"name": "synapse_pyspark"
		},
		"language_info": {
			"name": "python"
		},
		"layout": "standard",
		"microsoft": {
			"language": "python",
			"language_group": "synapse_pyspark",
			"ms_spell_check": {
				"ms_spell_check_language": "en"
			}
		},
		"nteract": {
			"version": "nteract-front-end@1.0.0"
		},
		"sessionKeepAliveTimeout": 0,
		"spark_compute": {
			"compute_id": "/trident/default",
			"session_options": {
				"conf": {
					"spark.synapse.nbs.session.timeout": "1200000"
				}
			}
		}
	},
	"nbformat": 4,
	"nbformat_minor": 5
}
